\section{Program State Convolution}\label{psc:s:program-state-convolution}
In \cref{psc:sec:motivation}, we discussed how \aflpp relies on edge coverage instrumentation to guide the fuzzing process.
We also identified one of the blind spots of compiler-based code coverage instrumentation: indirect calls.
A closer examination reveals that this specific blind spot is an instance of a more general issue.

Data dependencies that do not manifest as explicit control flow transitions are invisible to the fuzzer.
A critical variable might determine which implementation of a function is executed, but if that variable resides solely in data memory, the coverage bitmap remains unchanged.
Previous work augmented code coverage with additional data dependency~\cite{Mantovani2022} or dataflow coverage~\cite{herrera2022}.
\fbetodo{expand a little what they did}

Here we present an alternative solution to the problem, which we call \emph{Program State Convolution} or \glsshortkey{PSC} for short.
The core idea of \gls{PSC} is to project parts of the program's hidden data state onto the explicit control-flow graph.
By transforming data dependencies into control dependencies, we force the previously invisible variations in program state to trigger new edges in the coverage instrumentation.
This allows the fuzzer to distinguish between states that were previously conflated, providing the necessary stepping stones to explore deeper into the state space.
In the following sections, we present two concrete instantiations of this principle.
First, we discuss \emph{Dynamic Call Unfolding}, which exposes the hidden targets of indirect calls.
Second, we introduce \emph{Value Range Partitioning}, which projects possible partitions of a variable's value range onto the control flow.

\section{Unfolding Dynamic Calls}
Our first application of \gls{PSC} addresses the information loss occurring at indirect call sites.
As discussed in \cref{psc:sec:motivation}, \aflpp's compiler instrumentation for code coverage loses information at indirect call sites because it cannot differentiate the dynamic edges of an indirect call.
An analysis called \emph{points-to} analysis can, however, determine these edges at compile time.
Compilers use this analysis for both security and performance transformations.
Various \gls{CFI} variants, for example, use static points-to analysis to determine the possible target set for indirect calls (see \cref{ch:code-reuse-coevolution} for a discussion of \gls{CFI}).
Likewise, when a compiler can statically prove that in a given program an indirect call site can only ever have a single target, the compiler can transform the indirect call into a direct call.
Such a conversion enables additional optimizations later in the optimization pipeline, such as inlining.

\glspl{JITcomp} perform a similar optimization called \emph{polymorphic inlining} (see \cref{psc:ss:polymorphic-inlining}), typically based on profiling information.
For \gls{AOT} compilers, this transformation is more challenging because of the lack of runtime profiling information.
Nonetheless, \gls{AOT} compilers can apply the transformation either heuristically or because they can prove based on dataflow that only certain types can reach a polymorphic call site.
The fallback option that performs an indirect call guarantees that the program remains correct even if the analysis or the profiling information is incomplete.

The afforded performance improvement depends on the quality of the heuristics or the available profiling information.
SafeDispatch, a defense against vtable hijacking, uses the same technique to harden \cpp programs~\cite{jang2014}.
Performance aside, we observe that this type of transformation has another important property: it projects a data dependency---which concrete object reaches a call site---onto the control-flow graph.
In other words, possible variations in data, at least some of them, are now represented in the \gls{CFG}.
A representation as control-flow allows \aflpp's coverage instrumentation to instrument the previously invisible dynamic edges.
We call this principle \emph{Program State Convolution}, or \glsshortkey{PSC} for short, because it combines control flow with parts of the program's hidden state.

\begin{listing}
    \begin{minted}[escapeinside=||]{cpp}
#include <iostream>
#include <vector>
#include <fstream>

class Shape { public: virtual void draw(int scale) = 0; };
class ShapeParser { public: virtual Shape *parse(std::string pattern) = 0; };

class Rectangle : public Shape {
public:
  void draw(int scale) override {
    std::cout << "[Rectangle] scaled size: " << 10 / (scale + 1) << std::endl;
  }
};

class Circle : public Shape {
public:
  void draw(int scale) override {
    // BUG when scale == 0
    std::cout << "[Circle] scaled size: " << 10 / scale << std::endl;
  }
};

class CircleParser : public ShapeParser {
public:
  Shape *parse(std::string pattern) override {
    return pattern == "circle" ? new Circle() : nullptr;
  }
};

class RectangleParser : public ShapeParser {
public:
  Shape *parse(std::string pattern) override {
    return pattern == "rectangle" ? new Rectangle() : nullptr;
  }
};

int main(int argc, char *argv[]) {
  std::vector<ShapeParser *> shapeParsers = {new RectangleParser(), new CircleParser()};
  std::vector<Shape *> parsedShapes;
  std::string filename1 = argv[1];
  std::ifstream stream(filename);
  for (std::string line; std::getline(stream, line);)
    for (auto parser : shapeParsers)
      if (Shape *parsed = parser->parse(line)) parsedShapes.push_back(parsed);

  for (auto shape : parsedShapes) shape->draw(5);

  // filter parsedShapes somehow

  for (auto shape : parsedShapes) shape->draw(0); |\label{psc:line:broken-draw-call}|
}
    \end{minted}
    \caption{Polymorphic call site where a bug in \code{Circle::draw} is masked by prior coverage of both implementations.}
    \label{psc:lst:vcall-dependence}
\end{listing}

\cref{psc:lst:vcall-dependence} shows a simple polymorphic call example in \cpp.
The code consists of parser objects that populate a list of shapes based on strings found in an input file.
After initially drawing the shapes with a scale of $5$, the code filters the list of shapes.
In a second loop, the code draws the shapes with a scale of $0$; this works for rectangles but causes a crash for circles.
Whether the bug is triggered depends on the filtering logic and whether circle objects reach the call site at line~\ref{psc:line:broken-draw-call}.
Since the first loop might have already called the \code{draw} method of both types, compiler-based code coverage considers both methods as covered.

In contrast, \gls{PSC} would conceptually transform line~\ref{psc:line:broken-draw-call} as shown in \cref{psc:lst:broken-draw-call-unfolded}.
\begin{listing}
    \begin{minted}{cpp}
if (dynamic_cast<Rectangle *>(*iter))
  // call Rectangle::draw without dynamic dispatch
if (dynamic_cast<Circle *>(*iter))
  // call Circle::draw without dynamic dispatch
(*iter)->draw(5);
    \end{minted}
    \caption{Conceptual transformation of an indirect call to expose dynamic call targets to coverage instrumentation.}
    \label{psc:lst:broken-draw-call-unfolded}
\end{listing}
Each added control-flow branch provides the fuzzer with a potential stepping stone to build a new seed.

\section{Value-Range Partitioning}\label{psc:s:value-range-partitioning}
Control flow in programs typically depends on variable values.
An \code{if} statement might check whether a variable \code{x} exceeds a certain bound, or a loop might iterate until an index variable reaches a limit.
Conventional edge coverage already covers these types of control-flow decisions.
From the perspective of edge coverage, each control-flow point partitions the value range of the compared variable according to the comparison operator.
For example, consider the C condition in \cref{psc:lst:c-value-range}.
\begin{listing}
    \begin{minted}{C}
void target(int16_t param) {
  if (param < 0) {
    deal_with_negative(param);
  } else {
    deal_with_positive(param);
  }
}
    \end{minted}
    \caption{A simple branch partitions the value range into negative and non-negative values.}
    \label{psc:lst:c-value-range}
\end{listing}
The function \code{target} executes different logic depending on whether \code{param} is positive or negative.
An \code{int16\_t}, however, has a value in the range $[-32768, 32767]$, meaning that from the perspective of edge coverage, all values in the ranges $[-32768, -1]$ and $[0, 32767]$ are treated uniformly.
Whichever value the fuzzer explores within one of those ranges, it will not trigger new coverage in \code{target}.
This blind spot can lead to cases where a fuzzer struggles to find certain interesting data points because there is no direct control dependency on them.

Similar to the case of indirect call unfolding, we observe that a compiler already contains elaborate analyses to reason about such value ranges.
For example, compilers use such analyses to eliminate redundant conditions, as seen in line~\ref{psc:line:redundant-condition} of \cref{psc:lst:redundant-condition}.
\begin{listing}
    \begin{minted}[mathescape,escapeinside=||]{C}
void target(int16_t param) {
  if (param < 0) {

    // redundant condition
    if (param == 0) { |\label{psc:line:redundant-condition}|
      // deal with zero param
    }
    deal_with_negative(param);
  } else {
    deal_with_positive(param);
  }
}
    \end{minted}
    \caption{A redundant condition that compilers can eliminate using value range analysis.}
    \label{psc:lst:redundant-condition}
\end{listing}
Assuming that \code{param} is not, \eg \code{volatile}, the compiler can prove that at the time control flow reaches the condition at line~\ref{psc:line:redundant-condition}, \code{param} can never be $0$.

We can use this compiler knowledge to map these hidden data-space boundaries onto the control flow, again making them available for edge-coverage instrumentation.
For example, a simple compiler transformation can convert \cref{psc:lst:c-value-range} into \cref{psc:lst:c-value-range-transformed}.
We call this technique \gls{VRP}.
From the perspective of edge coverage, the transformation effectively divides the data space into four partitions instead of two.
The semantics of the program remain unchanged because the bodies in the artificially introduced control-flow split are identical.
\begin{listing}
    \begin{minted}{C}
void target(int16_t param) {
  if (param < 0) {
    if (param > -16384) {
        deal_with_negative(param);
    } else {
        deal_with_negative(param);
    }
  } else {
    if (param < 16384) {
        deal_with_positive(param);
    } else {
        deal_with_positive(param);
    }
  }
}
    \end{minted}
    \caption{Transformed version of \cref{psc:lst:c-value-range} with artificial branches subdividing each value range.}
    \label{psc:lst:c-value-range-transformed}
\end{listing}
It is possible that some of these value ranges are in fact unreachable due to constraints not known at compile time.

The technique shown above naturally raises two questions:
\begin{inline}
    \item How to split the value ranges?
    \item Where to insert the artificial control-flow?
\end{inline}

Consider the first question.
A variable of type \code{int32\_t} has over four billion possible values.
Partitioning this range into individual values is infeasible, so any practical approach must choose a subset of \emph{split points}.
A split point is the value on which the artificially inserted control-flow branches.
The first question, therefore, is really about finding good split points that provide valuable stepping stones for the fuzzer.
In the example in \cref{psc:lst:c-value-range-transformed} $-16384$ and $16384$ are split points.
A naive strategy might split the range at its midpoint, but such a simplistic approach ignores the program's semantics.
For example, if the variable is used as a divisor, the value zero is far more interesting than an arbitrary midpoint.
Similarly, if the variable feeds into an addition, the values near the overflow boundary matter most.
The \enquote{right} split points thus depend on what the program does with the variable.

To address the first question, we propose three straightforward split point heuristics.
However, it is worth noting that the broad \gls{VRP} framework offers a vast design space for further investigation.
\begin{description}
    \item[midpoint] This heuristic, as used in the examples above, simply splits value ranges in the middle, creating two roughly equal-sized partitions.
    This heuristic is suitable if nothing is known about the value range in question.
    \item[boundaries] This heuristic splits at values that form possible boundaries for later value usages.
    For example, typical boundaries for an array usage are $0$ and $\mathrm{arraylength}$\footnote{Negative indices are possible, but rare.}.
    Buffer operations form another example, such as \code{memcpy} or \code{memmove}, where the boundaries are $0$ and $\mathrm{buffersize}$.
    \Cref{psc:fig:boundaries-example} shows an example where the \propername{boundaries} heuristic can help.
    The function copies user-controlled data into a fixed-size buffer.
    The heuristic identifies thresholds at $0$ (empty copy) and $100$ (buffer size).
    Since the heuristic is usage-based, it requires an analysis to determine the usages of the value in question.
    Additionally it needs analyses to determine \eg buffer and array sizes, if possible.
    \item[arithmetic] Another class of sensitive variables are those that can contribute to an arithmetic underflow or overflow.
    If not properly handled, such underflows or overflows can lead to crashes and security-critical bugs.
    Similar to the \propername{boundaries} heuristic, the \propername{arithmetic} heuristic is usage-based.
    Depending on how later arithmetic operations use the variable, the heuristic splits the value range at values that cause an under- or overflow.
    \Cref{psc:fig:arithmetic-example} shows an example of the \propername{arithmetic} heuristic.
\end{description}

\begin{figure}[t]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize]{C}
void process_request(size_t len) {
  char buf[100];
  if (len > 0) {
    // len used as memcpy size
    memcpy(buf, user_data, len);
    process(buf);
  }
}
        \end{minted}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize]{C}
void process_request(size_t len) {
  char buf[100];
  if (len > 0) {
    if (len >= 100) {
      memcpy(buf, user_data, len);
      process(buf);  // overflow
    } else {
      memcpy(buf, user_data, len);
      process(buf);  // safe
    }
  }
}
        \end{minted}
    \end{minipage}

    \begin{minipage}[t]{0.48\textwidth}
        \subcaption{Original code.}
        \label{psc:lst:boundaries-example}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \subcaption{After transformation.}
        \label{psc:lst:boundaries-example-transformed}
    \end{minipage}
    \caption{The \propername{boundaries} heuristic splits at the buffer size boundary (100).}
    \label{psc:fig:boundaries-example}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize]{C}
void process_data(uint8_t x) {
  if (x < 250) {
    // If x > 235, (x + 20)
    // overflows uint8_t (255).
    uint8_t result = x + 20;

    if (result < 5) {
      // Bug triggered by overflow
      crash_program();
    }
  }
}
        \end{minted}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize]{C}
void process_data(uint8_t x) {
  if (x < 250) {
    if (x > 235) {
      // Overflow path: x+20 wraps
      uint8_t result = x + 20;
      if (result < 5) crash_program();
    } else {
      // Safe path: no overflow
      uint8_t result = x + 20;
      if (result < 5) crash_program();
    }
  }
}
        \end{minted}
    \end{minipage}

    \begin{minipage}[t]{0.48\textwidth}
        \subcaption{Original code.}
        \label{psc:lst:arithmetic-example}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \subcaption{After transformation.}
        \label{psc:lst:arithmetic-example-transformed}
    \end{minipage}
    \caption{The \propername{arithmetic} heuristic splits at the overflow boundary (236).}
    \label{psc:fig:arithmetic-example}
\end{figure}


For the second question, we note that in principle, artificial control-flow splitting can happen at any point of the variable's live range.
Since we must duplicate the code in both branches (cf. \cref{psc:fig:arithmetic-example}), however, larger branches mean more code bloat.
Moreover, not every program point is equally useful: a partition is only valuable if it leads to observably different behavior downstream.
For instance, partitioning a variable just before it is overwritten provides no benefit.

We propose a simple placement heuristic based on existing comparisons.
The heuristic subdivides each branch of an \emph{existing} comparison based on the previously determined split points.
For example, the heuristic transforms code patterns like \cref{psc:lst:c-value-range}, but would not transform patterns like \cref{psc:lst:psc-no-transform} due to the lack of existing comparisons.
This choice is a tradeoff, as functions such as the one in \cref{psc:lst:psc-no-transform} with a flat control-flow and purely value-based bugs are possible and would be missed by the heuristic.
Apart from a relatively simple implementation, choosing existing comparisons as an insertion-point has advantages as well, however.
First, if the program's control-flow depends on the value, it is likely not completely irrelevant to the program's computation.
Second, existing comparisons pre-constraint the value range, making splitting into manageable partitions easier.

\begin{listing}[t]
    \begin{minted}{C}
void target(int16_t param) {
  // other code
  // some function that fails on e.g. the last value in the range
  deal_with_value(param);
}
    \end{minted}
    \caption{A function without comparisons: our heuristic cannot partition \code{param} here.}
    \label{psc:lst:psc-no-transform}
\end{listing}

An alternative to our comparison-based heuristic would be to trace backwards from possibly interesting dataflow sinks, such as calls.
Such an approach to identifying instrumentation points is similar to the usage-based heuristics \propername{boundaries} and \propername{arithmetic}.
In the example in \cref{psc:lst:psc-no-transform}, we could reason that because the param value flows into a function call, it is relevant to the program.
A potential splitting point would then have to include as many of these potentially interesting dataflow sinks as possible.

The downside of all these transformations is code duplication and, as a result, potential runtime performance degradation.
Thus, the heuristics need to strike a balance between code size bloat and utility for the fuzzer.
