\section{Implementation}\label{sec:lool:implementation}

\subsection{Code Coverage Instrumentation in Java}
Fuzzers like \aflpp are designed to test binary programs, \ie programs that were previously compiled by a compiler to machine code.
Coverage instrumentation is realized by inserting additional instructions into the subject's machine code.
\aflpp supports this instrumentation step either during compilation of the test subject or, with certain tradeoffs, also after compilation.
The most efficient coverage instrumentation in \aflpp is based on \gls{LTO}, which gives the instrumentation pass a holistic view of the entire instrumented program.
\gls{LTO} instrumentation allows \aflpp to assign a \emph{unique} edge id to every edge, as the total number of edges is known at compile time.

In the case of GraalVM and more generally in case of Java test subjects, the subject is not compiled to machine code, but to Java bytecode.
Consequently, code coverage instrumentation needs to happen at the bytecode level.
In principle, \gls{LTO} style instrumentation would be possible by instrumenting \emph{all} Java classes, \ie classes belonging to the subject or to any possible library (including the JDK itself).
In practice, such an all-encompassing instrumentation is infeasible because classes are loaded dynamically, potentially even from locations only known at runtime.
While the GraalVM compiler's classpath is known at (Java) compile time, instrumenting all classes, including JDK classes, upfront is still difficult.

Instead, we use the \gls{JVM}'s agent facility to transform classes on the fly.
Java agents belong to the instrumentation API and allow to alter an application's bytecode dynamically.
The \gls{JVM} informs an agent whenever a class is loaded and allows the agent to modify the class bytecode.
Our coverage agent checks whether a loaded class should be instrumented based on a preconfigured filter.
For our experiments, we limited the filter to classes belonging to the GraalVM compiler project.
The agent also keeps a cache to avoid paying the overhead of instrumentation for the same class multiple times.

The code coverage instrumentation is based on \jacoco's instrumentation infrastructure and inserts a static method call at each instrumentation point.
The static call increases the counter of the given edge identifier in a global byte buffer.
\cref{lst:lool:java-if-cascade} shows a simple Java \code{if} cascade that checks the values in a byte array.
\cref{lool:lst:code-coverage-instrumentation} shows the corresponding uninstrumented bytecode (left) and the inserted coverage instrumentation (right).

Our coverage agent assigns a range of unique edge identifiers to each class.
As we want to compare the coverage of different runs (from the same or different configurations), the id assignment must be deterministic and reproducible.
A deterministic and reproducible assignment is challenging because classes are loaded not necessarily in the same order in different runs.
Unlike \aflpp with \gls{LTO}, our coverage agent never has a holistic view of the entire program, as new classes could be loaded at any time.
To guarantee consistent ids across runs, the agent relies on an id synchronization file containing the class id ranges assigned in previous runs.
Before assigning a new range to a class, the agent checks whether a previous run has already assigned a range to the class.

\definecolor{lightyellow}{rgb}{1,1,0.85}

\begin{listing}
    \begin{minted}{Java}
if (bytes[0] == 'b') {
    if (bytes[1] == 'u') {
        if (bytes[2] == 'g') {
            Assert.fail("Expected");
        }
    }
}
    \end{minted}
    \caption{Java \code{if} cascade to demonstrate coverage instrumentation}
    \label{lst:lool:java-if-cascade}
\end{listing}


\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize]{javabytecode}
aload         6
iconst_0
baload
bipush        98
if_icmpne     126




aload         6
iconst_1
baload
bipush        117
if_icmpne     126




aload         6
iconst_2
baload
bipush        103
if_icmpne     126




// String Expected
ldc           #58
// Assert.fail
invokestatic  #60
        \end{minted}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \begin{minted}[fontsize=\footnotesize,highlightlines={5-9,14-18,23-27},highlightcolor=lightyellow]{javabytecode}
aload         6
iconst_0
baload
bipush        98
if_icmpeq     163
sipush        585
// CoverageMap.incrementCounter
invokestatic  #105
goto          234
aload         6
iconst_1
baload
bipush        117
if_icmpeq     181
sipush        586
// CoverageMap.incrementCounter
invokestatic  #105
goto          234
aload         6
iconst_2
baload
bipush        103
if_icmpeq     199
sipush        587
// CoverageMap.incrementCounter
invokestatic  #105
goto          234
// String Expected
ldc           #58
// Assert.fail
invokestatic  #60
        \end{minted}
    \end{subfigure}
    \caption{Bytecode from \cref{lst:lool:java-if-cascade} instrumented for code coverage.}
    \label{lool:lst:code-coverage-instrumentation}
\end{figure}

\subsection{\aflpp-compatible Counter Coverage}
\begin{figure}[t]
    \centering
    \begin{minipage}[t]{0.50\textwidth}
        \centering
        \vspace{0pt}
        \textbf{Optimization Log}\strut\par\smallskip
        \begin{minted}[escapeinside=@@,fontsize=\footnotesize]{json}
{
  @...@
  "Deduplication": @\tikzmarknode[draw,inner sep=1pt]{num1}{9}@,
  "ConstantReassociation": @\tikzmarknode[draw,inner sep=1pt]{num2}{27}@,
  "ArithmeticWithMulReplacement": @\tikzmarknode[draw,inner sep=1pt]{num3}{125}@,
  "IfElimination": @\tikzmarknode[draw,inner sep=1pt]{num4}{1519}@
  @...@
}
        \end{minted}
    \end{minipage}%
    \hfill
    \tikzset{
        stackcell/.style={draw,thick,minimum width=1.2cm,minimum height=0.5cm,fill=gray!20},
        stackellipsis/.style={stackcell,fill=white},
        overlayarrow/.style={->,thick,gray},
    }
    \begin{minipage}[t]{0.22\textwidth}
        \centering
        \vspace{0pt}
        \textbf{Run Coverage}\strut\par\smallskip
        \renewcommand{\arraystretch}{0}%
        \setlength{\tabcolsep}{0pt}%
        \begin{tabular}{c}
            \tikzmarknode[stackellipsis]{ellipT}{$\cdots$}    \\
            \tikzmarknode[stackcell]{box1}{\footnotesize 9}   \\
            \tikzmarknode[stackcell]{box2}{\footnotesize 27}  \\
            \tikzmarknode[stackcell]{box3}{\footnotesize 125} \\
            \tikzmarknode[stackcell]{box4}{\footnotesize 255} \\
            \tikzmarknode[stackellipsis]{ellipB}{$\cdots$}    \\
        \end{tabular}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.22\textwidth}
        \centering
        \vspace{0pt}
        \textbf{Bucketed Map}\strut\par\smallskip
        \renewcommand{\arraystretch}{0}%
        \setlength{\tabcolsep}{0pt}%
        \begin{tabular}{c}
            \tikzmarknode[stackellipsis]{ellipTr}{$\cdots$}    \\
            \tikzmarknode[stackcell]{box1r}{\footnotesize 16}  \\
            \tikzmarknode[stackcell]{box2r}{\footnotesize 32}  \\
            \tikzmarknode[stackcell]{box3r}{\footnotesize 64}  \\
            \tikzmarknode[stackcell]{box4r}{\footnotesize 128} \\
            \tikzmarknode[stackellipsis]{ellipBr}{$\cdots$}    \\
        \end{tabular}
    \end{minipage}

    % Draw arrows using overlay
    \begin{tikzpicture}[remember picture,overlay,>=Latex,shorten >=0pt]
        \draw[overlayarrow] let \p1=(num1.north), \p2=(box1.west),
        \n1={0.55*(\x1+\x2) + 40pt} in
        (\p1) -- ++(0,0.15) -- (\n1,\y1+0.15cm) -- (\n1,\y2) -- (box1.west);
        \draw[overlayarrow] let \p1=(num2.north), \p2=(box2.west),
        \n1={0.55*(\x1+\x2) + 15pt} in
        (\p1) -- ++(0,0.25) -- (\n1,\y1+0.25cm) -- (\n1,\y2) -- (box2.west);
        \draw[overlayarrow] let \p1=(num3.north), \p2=(box3.west),
        \n1={0.55*(\x1+\x2) - 15pt} in
        (\p1) -- ++(0,0.35) -- (\n1,\y1+0.35cm) -- (\n1,\y2) -- (box3.west);
        \draw[overlayarrow] let \p1=(num4.south), \p2=(box4.west),
        \n1={0.55*(\x1+\x2) - 40pt} in
        (\p1) -- ++(0,-0.45) -- (\n1,\y1-0.45cm) -- (\n1,\y2) -- (box4.west);
        \draw[overlayarrow] (box1.east) -- (box1r.west);
        \draw[overlayarrow] (box2.east) -- (box2r.west);
        \draw[overlayarrow] (box3.east) -- (box3r.west);
        \draw[overlayarrow] (box4.east) -- (box4r.west);
    \end{tikzpicture}
    \caption{Mapping from optimization counters to bytes of the per-run coverage bitmap and to the global bucketed coverage map.}
    \label{fig:lool:counter-mapping}
\end{figure}


In our evaluation (see \cref{lool:s:evaluation}) we evaluate various configurations that use \aflpp as the mutation engine.
\aflpp expects a byte buffer as coverage in which each byte represents a unique counter from 0 to 255.
In a standard \aflpp setup, this coverage map is provided by a binary instrumented for code coverage, and each byte represents the execution count of a specific control-flow edge.
In experiments where we use \aflpp for mutation but use coverage information that does not directly represent code coverage, we need to map our coverage onto such a byte buffer.

In the case of context-blind coverage (global optimization counters), the number of optimization counters is known a priori.
We assign each optimization counter a unique and consistent position in the coverage map and use a saturating counter to count the frequency of the optimization.
This mapping allows \aflpp to treat optimization-counter information like execution counts.
\aflpp sorts execution counts into differently sized buckets.
For example, the execution counts 1, 2 and 3 each have their own bucket, whereas counts 32--127 are grouped into a single bucket.
The idea behind this principle is that small changes in execution-count frequency are more interesting for smaller execution counts than for larger ones.
The same applies to optimization frequencies.
Whether an optimization was applied once, twice or three times likely makes a bigger difference than whether it was applied 100 or 120 times.
Note that this bucketization in \aflpp occurs not during the test run, but when \aflpp integrates the run's coverage into its global coverage map.
\cref{fig:lool:counter-mapping} shows an example of this mapping process.

In the case of context-aware coverage (per-method optimization counters), only the number of optimization counters \emph{per method} is known a priori, but the total number of methods is not.
Thus, the total number of optimization counters depends on the number of compiled methods and varies from test to test.
Ideally, we want the transformation that converts optimization-log data into \aflpp compatible coverage to
\begin{enumerate}
    \item \label{lool:enum:stable} be stable.
    The same optimization-log data should lead to the same \aflpp style coverage every time;
    \item \label{lool:enum:non-chaotic} map identical optimization-log data to identical code coverage.
    Counter \propername{O} of a program's method \propername{M} should map to the same position regardless of whether the rest of the program changes;
    \item \label{lool:enum:injective} be injective.
    A non-injective mapping means there are coverage collisions.
\end{enumerate}
Condition \ref{lool:enum:stable} is satisfied as long as there is no non-determinism involved in the mapping.
To satisfy condition \ref{lool:enum:non-chaotic}, we assign an index range to each compiled method, starting at an index based on the method name's hash code.
Within each method's index range, we use the same optimization-to-index mapping as for the context-blind coverage mapping.
For example, consider two tests with methods \propername{A}, \propername{B}, \propername{C} and \propername{A}, \propername{B}, \propername{D}, respectively.
The counter positions for methods \propername{A} and \propername{B} will be the same in both cases, whereas the ones for \propername{C} and \propername{D} differ.
Condition \ref{lool:enum:injective} is hard to fulfill in practice.
The problem is similar to the problem \aflpp faces without \gls{LTO}.
Without knowing a priori how many method indices there will be over the course of the entire fuzzing campaign, the method index assignment is only best effort.
As the method index is based on the method name's hash code, this approach likely leads to coverage collisions.
Specifically, the index range assigned to a method is likely to overlap with another method's index range.
We note, however, that the problem of hash collisions is not specific to using optimization-counter coverage, but also occurs \eg when using \aflpp code coverage instrumentation without \gls{LTO}.

\subsection{Parameter Mutation by \aflpp}\label{lool:ss:afl-parameter-mutation}
In our evaluation (see \cref{lool:s:evaluation}), various configurations use \aflpp as the mutation engine.
In these configurations the program generator needs to generate test cases based on an input provided by \aflpp.
The exact composition of a generated program depends on two factors: the generation parameters and the concrete random decisions at various points during generation.
Both ultimately influence the program generator's behavior, but at different levels of abstraction.
Generation parameters bias random decisions in a certain direction, but do not determine their exact outcome (except in extreme cases where, \eg a probability is 0).
An example for a generation parameter is the probability distribution of different statement types (see \cref{lool:tbl:generation-parameters} for more examples).
Concrete random decisions, on the other hand, are all the concrete decisions the program generator has to make.
For example, while generating a program the generator might have to decide whether a \emph{particular} statement should be an \code{If} statement or a \code{While} statement.
Even if the statement distribution dictates a 90\% probability for \code{If} statements, the concrete random outcome at this particular point might still be a \code{While} statement.
We have implemented and evaluated two ways in the program generator to derive generation parameters and concrete random decisions from \aflpp generated input files.

\subsubsection{Fully Parametric}\label{lool:sss:afl-fully-parametric}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/lool/fully-parametric}%
    \caption{When configured to be fully parametric, the program generator reads generation parameters and values driving concrete random decisions from the input.}
    \label{lool:fig:fully-parametric}
\end{figure}


The program generator reads \emph{both} the generation parameters and the values driving concrete random decisions directly from the input file.
The header of the seed file determines the generation parameters, and each concrete random decision is based on a certain byte sequence in the seed file.
\cref{lool:fig:fully-parametric} illustrates this principle.
In the example, the first bytes in the input file define the statement distribution and later bytes (after the header) decide concrete random generation decisions.
If the generator runs out of randomness, \ie the input is too short to generate a valid live program, it tries again with reduced structural parameters.
Structural parameters determine the size of the generated program and, therefore, directly influence the amount of randomness needed to generate them.
For example, the maximum number of statements in a method is a structural parameter.
The generator contains a manual list of such structural parameters for reduction, together with meaningful minimums.
On each retry, the generator reduces structural parameters by 50\%.
If all structural parameters have reached their limit, the generator signals an error and skips the seed.
How often such a reduction is possible depends on the initial generation parameters.

Unlike an unconstrained generator, the liveness generator cannot stop generating code at arbitrary points, as it needs to guarantee the liveness property throughout generation.
Another issue is that the generator occasionally needs to perform backtracking as it cannot decide upfront whether producing, \eg an expression of a certain type is possible with a given set of live variables.
During these futile generation attempts, the generator uses large amounts of randomness that do not, however, result in concrete program elements.
Although we optimized the random consumption during backtracking to use only 4 bytes of randomness in case of a failed attempt, multiple failed attempts can use up the available randomness quickly.

In principle, the generator could just skip too short seeds entirely, but skipping seeds gives \aflpp only a coarse signal.
A skipped seed does not produce any coverage feedback but tells \aflpp only that the seed is invalid.
In contrast, a smaller program generated from a smaller seed does produce coverage, although less than a larger program generated from a larger seed would.
We discuss the problems with the fully parametric mutation approach in \cref{lool:ss:aflpp-vs-genetic}.

\subsubsection{Generation Parameters Only}\label{lool:sss:afl-hyperonly}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/lool/parameters-only}%
    \caption{When reading only generation parameters from the input, the program generator treats 4 bytes after the header as a seed for an internal random number generator.}
    \label{lool:fig:parameters-only}
\end{figure}

The program generator reads only the generation parameters and a single integer directly from the file.
All later bytes in the seed file are ignored.
\cref{lool:fig:parameters-only} illustrates this use of input bytes, again with the statement distribution as an example of a generation parameter.
The integer serves as a random seed for a new, in-memory random instance that drives the concrete random decisions.
This approach allows \aflpp to mutate the generation parameters in a more targeted way.
Reading the seed for the in-memory random instance from the input file is important to guarantee the same generated program (and thus the same coverage feedback) given the same input file.
