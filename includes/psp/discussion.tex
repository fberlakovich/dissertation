\section{Discussion}\label{psp:s:discussion}

\input{generated/psp/defines-fuzzbench}
\input{generated/psp/defines-magma}

The median final edge coverage for \gls{VRP} configurations in \cref{psp:tab:coverage-fuzzbench} shows a mixed picture.
Only two benchmarks have a meaningfully large effect size, and among these two, the negative result (\propername{sqlite3\_ossfuzz}) dominates.
For the Magma benchmarks in \cref{psp:tab:coverage-magma}, the edge coverage disadvantage is more pronounced with six negatively affected benchmarks.
These results admit only a rejection of our first hypothesis.
\begin{infobox}
    \textbf{\ref{psp:hpt:vrp-coverage}}\hspace{0.8em}\ding{55}\\
    \gls{VRP} does \emph{not} improve the fuzzer's ability to discover new edges.
    In fact, \gls{VRP} leads to a disadvantage with respect to edge coverage for certain benchmarks.
\end{infobox}

For Call Unfolding, only two benchmarks show a statistically significant difference in \cref{psp:tab:coverage-fuzzbench}, but their effect size is too small to be meaningful.
In the Magma suite, Call Unfolding shows no statistically significant difference to the baseline at all.
The lack of differences leads us to reject also the second hypothesis.
\begin{infobox}
    \textbf{\ref{psp:hpt:unfold-coverage}}\hspace{0.8em}\ding{55}\\
    Call Unfolding does \emph{not} improve the fuzzer's ability to discover new edges.
    We observed no statistically significant differences to the baseline.
\end{infobox}

Finally, the bug triggering statistics in \cref{app:tab:magma-benchmarks} show no statistically significant difference except for two bugs, \propername{SND006} and \propername{TIF002}.
In both cases, \gls{VRP} leads to a measurable deterioration of bug triggering.
Based on these results we also have to reject the third hypothesis.
\begin{infobox}
    \textbf{\ref{psp:hpt:bugs}}\hspace{0.8em}\ding{55}\\
    \gls{PSP} transformations do \emph{not} improve bug-finding capability.
    In two cases, \gls{VRP} impeded the fuzzer's ability to trigger a bug.
\end{infobox}

The negative results naturally raise the question of \emph{why} \gls{PSP} fails to improve fuzzer performance and in some cases even hurts a fuzzer's progress.
The following subsections discuss possible root causes of the negative results.

\subsection{Execution Speed and Bitmap Size}

\begin{listing}[t]
    \begin{minted}{C}

// Missing in buggy version
// if ((tmsize_t)sp->stream.avail_out > sp->tbuf_size)
// {
//   TIFFErrorExt(tif->tif_clientdata, module,
//        "sp->stream.avail_out > sp->tbuf_size");
//   return (0);
// }

do {
  int state = inflate(&sp->stream, Z_PARTIAL_FLUSH);
  if (state == Z_STREAM_END) {
    break;            /* XXX */
  }
// rest of loop
} while (sp->stream.avail_out > 0);

    \end{minted}
    \caption{Heap overflow bug \propername{TIF002} in \propername{libtiff}.}
    \label{psp:lst:libtiff-bug}
\end{listing}

Both \gls{PSP} transformations insert additional instructions and with them additional edges.
\gls{VRP} causes a mean slowdown of 19\% and in the case of Magma's \propername{libsndfile} even 55\%.
In the case of Call Unfolding, the mean slowdown is around 0, with the worst benchmark at -24\%, but with \propername{sqlite3\_ossfuzz} showing an improvement of 30\%.
To test whether these observed slowdowns could possibly be a cause of the observed deterioration, we ranked the fuzzers by execution speed delta and by coverage change and computed the Pearson correlation between the two rankings.
For both \gls{VRP} and Call Unfolding the correlation coefficients were small, and the $p$ values (\num{0.495} and \num{0.161}) too large for statistical significance.
In other words, based on the data we have we cannot conclude that execution speed differences cause the differences in edge coverage.

To investigate whether the additional \gls{PSP} edges overflow the fuzzer's coverage bitmap, we measured the bitmap utilization across benchmarks.
We found that only 5 out of 43 benchmarks (FuzzBench and Magma) use more than 50\% of their bitmap, with \propername{openh264\_decoder\_fuzzer} reaching the most at 71\%.
This utilization suggests that an overflowing coverage bitmap is not the cause of \gls{PSP}'s negative results.

\subsection{Missing Initial Control-Flow}


Our current implementation of \gls{VRP} requires existing comparisons as starting points for further instrumentation.
Certain bugs, such as \propername{TIF002} in \propername{libtiff} of the Magma benchmark suite, lack such a comparison.
\cref{psp:lst:libtiff-bug} shows the relevant code snippet.
The heap overflow caused by \code{inflate} is only triggered when \code{sp->stream.avail\_out} is bigger than \code{sp->tbuf\_size}.
The relation between the two fields is entirely implicit, however.
In such cases \gls{VRP} does not instrument the affected code.
\gls{VRP} would need another mechanism, such as invariant inference to surface this relation, \eg in the form of an assertion.
Once the relation is materialized into control flow, \gls{VRP} could provide stepping stones for the fuzzer to eventually violate the invariant.
\citeauthor{fioraldi2021} already explored the use of likely invariants as coverage feedback for fuzzers and \gls{VRP} might help fuzzers \enquote{approach} these invariants more easily.

\subsection{Edge Entanglement}

A core assumption behind \gls{PSP} is that the additional edges give a value signal about a hitherto unknown program state to the fuzzer.
If, on the other hand, a newly discovered \gls{PSP} edge is a direct consequence of a simultaneously discovered non-\gls{PSP} edge, the fuzzer gains no new information.
To distinguish \gls{PSP} from non-\gls{PSP} edges, we record the IDs of \gls{PSP} edges in a dedicated ELF section in the \gls{PSP}-instrumented binary.
We then replay each \gls{PSP} configuration's corpus on its respective binary and classify every coverage-discovering input into one of three categories:
\begin{enumerate}
    \item The input discovers \emph{only} non-\gls{PSP} edges.
    The baseline binary would have detected these edges as well.
    An exception are non-\gls{PSP} edges the fuzzer could only reach \emph{because} of a \gls{PSP} edge.
    Since our edge coverage data suggests that \gls{PSP} configurations hardly ever find more edges than the baseline, we ignore this case.
    \item The input discovers \emph{only} \gls{PSP} edges.
    \gls{PSP} has surfaced a program state that would otherwise have been invisible to the fuzzer.
    \item The input discovers at least one \gls{PSP} edge \emph{and} at least one non-\gls{PSP} edge simultaneously.
    We call these inputs \emph{entangled}.
\end{enumerate}
From this classification we calculate the entanglement rate~$\mathcal{E}$ over all inputs that discover at least one \gls{PSP} edge (categories 2 and~3):
\begin{equation}
    \mathcal{E} = \frac{n_{\text{both}}}{n_{\text{both}} + n_{\text{PSP}}}
\end{equation}
where $n_{\text{both}}$ is the number of entangled inputs and $n_{\text{PSP}}$ is the number of inputs that discover exclusively \gls{PSP} edges.
An entanglement rate of \num{100}\,\% means that every \gls{PSP}-edge-discovering input also discovers a non-\gls{PSP} edge, rendering the \gls{PSP} edges redundant as a coverage signal.

\Cref{psp:tab:entanglement-fuzzbench,psp:tab:entanglement-magma} show the median (across all 30 runs) per-benchmark fraction of inputs falling into each category for FuzzBench and Magma, respectively.
The \enquote{Non-PSP}, \enquote{PSP} and \enquote{Both} columns show the percentage of inputs in each category.
The consistently high entanglement rate $\mathcal{E}$  means that the vast majority of \gls{PSP} edge discoveries coincide with non-\gls{PSP} edge discoveries, rendering the \gls{PSP} edges redundant as a coverage signal.
This data suggests that for \gls{PSP} to be effective, more powerful heuristics are needed, which better surface program states that are independent of any existing coverage edges.

\begin{table}[t]
    \centering
    \caption{Per-input edge entanglement on FuzzBench: median across \num{30} instances. $\mathcal{E}$~is the entanglement rate; the three category columns show the fraction~(\%) of all coverage-discovering inputs per category.}
    \label{psp:tab:entanglement-fuzzbench}
    \scriptsize
    \setlength{\extrarowheight}{1pt}
    \begin{tabular}{>{\nextrow}E S[table-format=2.1] S[table-format=3.1] S[table-format=2.1] S[table-format=2.1] S[table-format=2.1] S[table-format=3.1] S[table-format=2.1] S[table-format=2.1]}
        \toprule
        & \multicolumn{4}{c}{\gls{VRP}} & \multicolumn{4}{c}{Call Unfolding} \\
        \cmidrule(lr){2-5} \cmidrule(lr){6-9}
        {Benchmark} & {$\mathcal{E}$} & {$\lnot$PSP} & {PSP} & {Both} & {$\mathcal{E}$} & {$\lnot$PSP} & {PSP} & {Both} \\
        \midrule
        \startdatarows
        \fileInput{generated/psp/entanglement-fuzzbench}
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[t]
    \centering
    \caption{Per-input edge entanglement on Magma: median across \num{30} instances. $\mathcal{E}$~is the entanglement rate; the three category columns show the fraction~(\%) of all coverage-discovering inputs per category.}
    \label{psp:tab:entanglement-magma}
    \scriptsize
    \setlength{\extrarowheight}{1pt}
    \begin{tabular}{>{\nextrow}E S[table-format=3.1] S[table-format=2.1] S[table-format=2.1] S[table-format=2.1] S[table-format=3.1] S[table-format=2.1] S[table-format=2.1] S[table-format=2.1]}
        \toprule
        & \multicolumn{4}{c}{\gls{VRP}} & \multicolumn{4}{c}{Call Unfolding} \\
        \cmidrule(lr){2-5} \cmidrule(lr){6-9}
        {Benchmark} & {$\mathcal{E}$} & {$\lnot$PSP} & {PSP} & {Both} & {$\mathcal{E}$} & {$\lnot$PSP} & {PSP} & {Both} \\
        \midrule
        \startdatarows
        \fileInput{generated/psp/entanglement-magma}
        \bottomrule
    \end{tabular}
\end{table}

