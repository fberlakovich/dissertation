@incollection{Abadi2005,
  title         = {{A Theory of Secure Control Flow}},
  author        = {Abadi, Mart{\'{i}}n and Budiu, Mihai and Erlingsson, {\'{U}}lfar and Ligatti, Jay},
  year          = 2005,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume        = {3785 LNCS},
  pages         = {111--124},
  doi           = {10.1007/11576280_9},
  isbn          = 3540297979,
  issn          = {03029743},
  abstract      = {Control-Flow Integrity (CFI) means that the execution of a program dynamically follows only certain paths, in accordance with a static policy. CFI can prevent attacks that, by exploiting buffer over-flows and other vulnerabilities, attempt to control program behavior. This paper develops the basic theory that underlies two practical techniques for CFI enforcement, with precise formulations of hypotheses and guarantees. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.}
}
@article{Abadi2009,
  title         = {{Control-flow integrity principles, implementations, and applications}},
  author        = {Abadi, Mart{\'{i}}n and Budiu, Mihai and Erlingsson, {\'{U}}lfar and Ligatti, Jay},
  year          = 2009,
  month         = oct,
  journal       = {ACM Transactions on Information and System Security},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  volume        = 13,
  number        = 1,
  pages         = {1--40},
  doi           = {10.1145/1609956.1609960},
  isbn          = 1595932267,
  issn          = {1094-9224},
  abstract      = {Current software attacks often build on exploits that subvert machine-code execution. The enforcement of a basic safety property, Control-Flow Integrity (CFI), can prevent such attacks from arbitrarily controlling program behavior. CFI enforcement is simple, and its guarantees can be established formally, even with respect to powerful adver- saries. Moreover, CFI enforcement is practical: it is compatible with existing software and can be efficiently implemented using software rewriting in commodity systems. Fi- nally, CFI provides a useful foundation for enforcing further security policies, such as policies that constrain the use of data memory}
}
@inproceedings{Aga2019,
  title         = {{Smokestack: Thwarting DOP Attacks with Runtime Stack Layout Randomization}},
  author        = {Aga, Misiker Tadesse and Austin, Todd},
  year          = 2019,
  month         = feb,
  booktitle     = {2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  publisher     = {IEEE},
  pages         = {26--36},
  doi           = {10.1109/CGO.2019.8661202},
  isbn          = {978-1-7281-1436-1},
  abstract      = {Memory corruption vulnerabilities in type-unsafe languages are often exploited to perform a control-flow hijacking attack, in which an attacker uses vulnerabilities to corrupt control data in the program to eventually gain control over the execution of the program. However, widespread adoption of control-flow attack defenses such as Control-flow Integrity (CFI) has led attackers to exploit memory errors to corrupt non-control data that can not be detected by these defenses. Non-control data attacks can be used to corrupt security critical data or leak sensitive information. Moreover, recent attacks such as data-oriented programming (DOP) have generalized non-control data attacks to achieve Turing-complete computation capabilities within the programmer-specified control-flow graph, leaving previously proposed control-flow protections unable to stop these attacks.In this paper, we present a stack-layout randomization scheme that can effectively thwart DOP attacks. Our approach, called Smokestack, provides each function invocation with a randomly permuted ordering of the local stack organization. In addition, we utilize true-random value sources combined with disclosure-resistant pseudo-random number generation to ensure that an adversary cannot anticipate a function-s invocation permutation of automatic variables. Our evaluation on SPEC benchmarks and various real-world applications shows that Smokestack can stop DOP attacks with minimal overhead.}
}
@inproceedings{Akritidis2008,
  title         = {Preventing Memory Error Exploits with {{WIT}}},
  author        = {Akritidis, Periklis and Cadar, Cristian and Raiciu, Costin and Costa, Manuel and Castro, Miguel},
  booktitle     = {Proceedings - {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  publisher     = {IEEE},
  pages         = {263--277},
  doi           = {10.1109/SP.2008.30},
  isbn          = {978-0-7695-3168-7},
  issn          = 10816011,
  date          = {2008-05},
  abstract      = {Attacks often exploit memory errors to gain control over the execution of vulnerable programs. These attacks remain a serious problem despite previous research on techniques to prevent them. We present write integrity testing (WIT), a new technique that provides practical protection from these attacks. WIT uses points-to analysis at compile time to compute the control-flow graph and the set of objects that can be written by each instruction in the program. Then it generates code instrumented to prevent instructions from modifying objects that are not in the set computed by the static analysis, and to ensure that indirect control transfers are allowed by the control-flow graph. To improve coverage where the analysis is not precise enough, WIT inserts small guards between the original program objects. We describe an efficient implementation with optimizations to reduce space and time overhead. This implementation can be used in practice because it compiles C and C++ programs without modifications, it has high coverage with no false positives, and it has low overhead. WIT's average runtime overhead is only 7\% across a set of CPU intensive benchmarks and it is negligible when IO is the bottleneck.}
}
@inproceedings{Alipour2016,
  title         = {Generating Focused Random Tests Using Directed Swarm Testing},
  author        = {Alipour, Mohammad Amin and Groce, Alex and Gopinath, Rahul and Christi, Arpit},
  year          = 2016,
  month         = jul,
  booktitle     = {Proceedings of the 25th {{International Symposium}} on {{Software Testing}} and {{Analysis}}},
  publisher     = {ACM},
  address       = {Saarbr{\"u}cken Germany},
  pages         = {70--81},
  doi           = {10.1145/2931037.2931056},
  isbn          = {978-1-4503-4390-9}
}
@inproceedings{Almakhdhub2020,
  title         = {{{$\mu$}RAI: Securing Embedded Systems with Return Address Integrity}},
  author        = {Almakhdhub, Naif Saleh and Clements, Abraham A and Bagchi, Saurabh and Payer, Mathias},
  year          = 2020,
  booktitle     = {Proceedings 2020 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  number        = {February},
  doi           = {10.14722/ndss.2020.24016},
  isbn          = {1-891562-61-4},
  abstract      = {Embedded systems are deployed in security critical environments and have become a prominent target for remote attacks. Microcontroller-based systems (MCUS) are particularly vulnerable due to a combination of limited resources and low level programming which leads to bugs. Since MCUS are often a part of larger systems, vulnerabilities may jeopardize not just the security of the device itself but that of other systems as well. For example, exploiting a WiFi System on Chip (SoC) allows an attacker to hijack the smart phone's application processor. Control-flow hijacking targeting the backward edge (e.g., Return-Oriented Programming-ROP) remains a threat for MCUS. Current defenses are either susceptible to ROP-style attacks or require special hardware such as a Trusted Execution Environment (TEE) that is not commonly available on MCUS. We present \mathrm{\mu}RAI 1 , a compiler-based mitigation to prevent control-flow hijacking attacks targeting backward edges by enforcing the Return Address Integrity (RAI) property on MCUS. \mathrm{\mu}RAI does not require any additional hardware such as TEE, making it applicable to the wide majority of MCUS. To achieve this, \mathrm{\mu}RAI introduces a technique that moves return addresses from writable memory, to readable and executable memory. It re-purposes a single general purpose register that is never spilled, and uses it to resolve the correct return location. We evaluate against the different control-flow hijacking attacks scenarios targeting return addresses (e.g., arbitrary write), and demonstrate how \mathrm{\mu}RAI prevents them all. Moreover, our evaluation shows that \mathrm{\mu}RAI enforces its protection with negligible overhead.}
}
@phdthesis{Andersen1994,
  title         = {Program Analysis and Specialization for the C Programming Language},
  author        = {Lars Ole Andersen},
  year          = 1994,
  school        = {University of Copenhagen (DIKU)},
  type          = {PhD thesis}
}
@online{anthropic2026zerodays,
  title         = {Zero-days},
  author        = {Anthropic},
  year          = 2026,
  url           = {https://red.anthropic.com/2026/zero-days/},
  urldate       = {2026-02-06}
}
@inproceedings{aschermann2020a,
  title         = {Ijon: {{Exploring Deep State Spaces}} via {{Fuzzing}}},
  author        = {Aschermann, Cornelius and Schumilo, Sergej and Abbasi, Ali and Holz, Thorsten},
  booktitle     = {2020 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  publisher     = {IEEE},
  volume        = {2020-May},
  pages         = {1597--1612},
  doi           = {10.1109/SP40000.2020.00117},
  isbn          = {978-1-7281-3497-0},
  date          = {2020-05-01},
  abstract      = {Although current fuzz testing (fuzzing) methods are highly effective, there are still many situations such as complex state machines where fully automated approaches fail. State-of-the-art fuzzing methods offer very limited ability for a human to interact and aid the fuzzer in such cases. More specifically, most current approaches are limited to adding a dictionary or new seed inputs to guide the fuzzer. When dealing with complex programs, these mechanisms are unable to uncover new parts of the code base.In this paper, we propose Ijon, an annotation mechanism that a human analyst can use to guide the fuzzer. In contrast to the two aforementioned techniques, this approach allows a more systematic exploration of the program's behavior based on the data representing the internal state of the program. As a consequence, using only a small (usually one line) annotation, a user can help the fuzzer to solve previously unsolvable challenges. We extended various AFL-based fuzzers with the ability to annotate the source code of the target application with guidance hints. Our evaluation demonstrates that such simple annotations are able to solve problems that - to the best of our knowledge - no other current fuzzer or symbolic execution based tool can overcome. For example, with our extension, a fuzzer is able to play and solve games such as Super Mario Bros. or resolve more complex patterns such as hash map lookups. To further demonstrate the capabilities of our annotations, we use AFL combined with Ijon to uncover both novel security issues and issues that previously required a custom and comprehensive grammar to be uncovered. Lastly, we show that using Ijon and AFL, one can solve many challenges from the CGC data set that resisted all fully automated and human guided attempts so far.}
}
@inproceedings{Backes2013,
  title         = {Execute-no-Read: Preventing Code Disclosure in Userspace},
  author        = {Backes, Michael and Holz, Thorsten and Kollenda, Benjamin and Koppe, Philipp and N{\"{u}}rnberger, Stefan and Pewny, Jannik},
  year          = 2013,
  booktitle     = {Proceedings of the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security (ASIACCS)},
  pages         = {223--234}
}
@inproceedings{Backes2014b,
  title         = {{You Can Run but You Can't Read}},
  author        = {Backes, Michael and Holz, Thorsten and Kollenda, Benjamin and Koppe, Philipp and N{\"{u}}rnberger, Stefan and Pewny, Jannik},
  year          = 2014,
  booktitle     = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security - CCS '14},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {1342--1353},
  doi           = {10.1145/2660267.2660378},
  isbn          = 9781450329576,
  issn          = 15437221,
  abstract      = {Code reuse attacks allow an adversary to impose malicious behavior on an otherwise benign program. To mitigate such attacks, a common approach is to disguise the address or content of code snippets bymeans of randomization or rewrit- ing, leaving the adversary with no choice but guessing. How- ever, disclosure attacks allow an adversary to scan a process-- even remotely--and enable her to read executable memory on-the-fly, thereby allowing the just-in-time assembly of ex- ploits on the target site. In this paper, we propose an approach that fundamentally thwarts the root cause of memory disclosure exploits by pre- venting the inadvertent reading of code while the code itself can still be executed. We introduce a new primitive we call Execute-no-Read (XnR) which ensures that code can still be executed by the processor, but at the same time code cannot be read as data. This ultimately forfeits the self-disassembly which is necessary for just-in-time code reuse attacks (JIT- ROP) to work. To the best of our knowledge, XnR is the first approach to prevent memory disclosure attacks of exe- cutable code and JIT-ROP attacks in general. Despite the lack of hardware support for XnR in contemporary Intel x86 and ARMprocessors, our software emulations for Linux and Windows have a run-time overhead of only 2.2{\%} and 3.4{\%}, respectively.}
}
@inproceedings{Backes2014f,
  title         = {{Oxymoron: Making Fine-Grained Memory Randomization Practical by Allowing Code Sharing}},
  author        = {Backes, Michael and N{\"{u}}rnberger, Stefan},
  year          = 2014,
  booktitle     = {Proceedings of the 23rd {USENIX} Conference on Security Symposium},
  publisher     = {{USENIX} Association},
  address       = {USA},
  series        = {SEC'14},
  pages         = {433--447},
  isbn          = {978-1-931971-15-7},
  abstract      = {The latest effective defense against code reuse attacks is fine-grained, per-process memory randomization. However, such process randomization prevents code sharing since there is no longer any identical code to share between processes. Without shared libraries, however, tremendous memory savings are forfeit. This drawback may hinder the adoption of fine-grained memory randomization.We present Oxymoron, a secure fine-grained memory randomization technique on a per-process level that does not interfere with code sharing. Executables and libraries built with Oxymoron feature 'memory-layout-agnostic code', which runs on a commodity Linux. Our theoretical and practical evaluations show that Oxymoron is the first solution to be secure against just-in-time code reuse attacks and demonstrate that fine-grained memory randomization is feasible without forfeiting the enormous memory savings of shared libraries.}
}
@inproceedings{barany2017livenessdriven,
  title         = {Liveness-Driven Random Program Generation},
  author        = {Gerg{\"{o}} Barany},
  year          = 2017,
  booktitle     = {Logic-Based Program Synthesis and Transformation - 27th International Symposium, {LOPSTR} 2017, Namur, Belgium, October 10-12, 2017, Revised Selected Papers},
  publisher     = {Springer},
  series        = {Lecture Notes in Computer Science},
  volume        = 10855,
  pages         = {112--127},
  doi           = {10.1007/978-3-319-94460-9\_7},
  editor        = {Fabio Fioravanti and John P. Gallagher},
  timestamp     = {Wed, 25 Sep 2019 18:04:28 +0200},
  biburl        = {https://dblp.org/rec/conf/lopstr/Barany17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Berger2006,
  title         = {{DieHard: Probabilistic Memory Safety for Unsafe Languages}},
  author        = {Berger, Emery D and Zorn, Benjamin G},
  year          = 2006,
  booktitle     = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {PLDI '06},
  pages         = {158--168},
  doi           = {10.1145/1133981.1134000},
  isbn          = 1595933204
}
@inproceedings{berlakovich2022a,
  title         = {Look {{Ma}}, No Constants: Practical Constant Blinding in {{GraalVM}}},
  shorttitle    = {Look {{Ma}}, No Constants},
  author        = {Berlakovich, Felix and Neugschwandtner, Matthias and Barany, Gerg\"{o}},
  booktitle     = {Proceedings of the 15th {{European Workshop}} on {{Systems Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSec}} '22},
  pages         = {36--42},
  doi           = {10.1145/3517208.3523751},
  isbn          = {978-1-4503-9255-6},
  date          = {2022-04-05},
  abstract      = {With the advent of JIT compilers, code-injection attacks have seen a revival in the form of JIT spraying. JIT spraying enables an attacker to inject gadgets into executable memory, effectively sidestepping W\oplus{}X and ASLR.In response to JIT spraying, constant blinding has emerged as a conceptually straightforward and performance friendly defense. Unfortunately, increasingly sophisticated attacks have pinpointed the shortcomings of existing constant blinding implementations.In this paper we present our constant blinding implementation in the GraalVM compiler, enabling constant blinding across a wide range of languages. Our implementation takes insights from the last decade of research on the security of constant blinding into account. We discuss important design decisions and trade-offs as well as the practical implementation issues encountered when implementing constant blinding for GraalVM. We evaluate the performance impact of our implementation with different configurations and demonstrate its effectiveness by fuzzing for unblinded constants.}
}
@inproceedings{berlakovich2023,
  title         = {{{R2C}}: {{AOCR-Resilient Diversity}} with {{Reactive}} and {{Reflective Camouflage}}},
  shorttitle    = {{R2C}},
  author        = {Berlakovich, Felix and Brunthaler, Stefan},
  booktitle     = {Proceedings of the {{Eighteenth European Conference}} on {{Computer Systems}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSys}} '23},
  pages         = {488--504},
  doi           = {10.1145/3552326.3587439},
  isbn          = {978-1-4503-9487-1},
  date          = {2023-05-08},
  abstract      = {Address-oblivious code reuse, AOCR for short, poses a substantial security risk, as it remains unchallenged. If neglected, adversaries have a reliable way to attack systems, offering an operational and profitable strategy. AOCR's authors conclude that software diversity cannot mitigate AOCR, because it exposes fundamental limits to diversification.Reactive and reflective camouflage, or R2C for short, is a full-fledged, LLVM-based defense that thwarts AOCR by combining code and data diversification with reactive capabilities through booby traps. R2C includes optimizations using AVX2 SIMD instructions, compiles complex real-world software, such as browsers, and offers full support of C++. R2C thus proves that AOCR poses no fundamental limits to software diversification, but merely indicates that code diversification without data diversification is a dead end.An extensive evaluation along multiple dimensions proves the practicality of R2C. We evaluate the impact of our defense on performance, and find that R2C shows low performance impacts on compute-intensive benchmarks (6.6 -- 8.5\% geometric mean on SPEC CPU 2017). A security evaluation indicates R2C's resistance against different types of code-reuse attacks.}
}
@inproceedings{berlakovich2024,
  title         = {Cross {{Module Quickening}} - {{The Curious Case}} of {{C Extensions}}},
  author        = {Berlakovich, Felix and Brunthaler, Stefan},
  booktitle     = {38th {{European Conference}} on {{Object-Oriented Programming}} ({{ECOOP}} 2024)},
  location      = {Dagstuhl, Germany},
  publisher     = {Schloss Dagstuhl --- Leibniz-Zentrum f{\"u}r Informatik},
  series        = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume        = 313,
  pages         = {6:1--6:29},
  doi           = {10.4230/LIPIcs.ECOOP.2024.6},
  isbn          = {978-3-95977-341-6},
  issn          = {1868-8969},
  editor        = {Aldrich, Jonathan and Salvaneschi, Guido},
  date          = 2024
}
@article{berlakovich2026,
  title         = {{{LOOL}}: {{Low-Overhead}}, {{Optimization-Log-Guided Compiler Fuzzing}}},
  shorttitle    = {{LOOL}},
  author        = {Berlakovich, Felix and Schwarcz, Florian and Barany, Gerg\"{o} and M\"{o}ssenb\"{o}ck, Hanspeter and Brunthaler, Stefan},
  year          = 2026,
  journal       = {ACM Transactions on Software Engineering and Methodology},
  note          = {To appear}
}
@inproceedings{Bernhard2022,
  title         = {{{JIT-Picking}}: {{Differential Fuzzing}} of {{JavaScript Engines}}},
  shorttitle    = {{JIT-Picking}},
  author        = {Bernhard, Lukas and Scharnowski, Tobias and Schloegel, Moritz and Blazytko, Tim and Holz, Thorsten},
  year          = 2022,
  month         = nov,
  booktitle     = {Proceedings of the 2022 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  publisher     = {ACM},
  address       = {Los Angeles CA USA},
  pages         = {351--364},
  doi           = {10.1145/3548606.3560624},
  isbn          = {978-1-4503-9450-5}
}
@inproceedings{Bhattacharyya2020,
  title         = {{SpecROP: Speculative Exploitation of ROP Chains}},
  author        = {Bhattacharyya, Atri and S{\'{a}}nchez, Andr{\'{e}}s and Koruyeh, Esmaeil M and Abu-Ghazaleh, Nael and Song, Chengyu and Payer, Mathias},
  year          = 2020,
  booktitle     = {RAID},
  abstract      = {Speculative execution attacks, such as Spectre, reuse code from the victim's binary to access and leak secret information during speculative execution. Every variant of the attack requires very particular code sequences, necessitating elaborate gadget-search campaigns. Often, victim programs contain few, or even zero, usable gadgets. Consequently, speculative attacks are sometimes demonstrated by injecting usable code sequences into the victim. So far, attacks search for mono-lithic gadgets, a single sequence of code which performs all the attack steps. We introduce SpecROP, a novel speculative execution attack technique, inspired by classic code reuse attacks like Return-Oriented Programming to tackle the rarity of code gadgets. The SpecROP attacker uses multiple, small gadgets chained by poisoning multiple control-flow instructions to perform the same computation as a monolithic gadget. A key difference to classic code reuse attacks is that control-flow transfers between gadgets use speculative targets compared to targets in memory or registers. We categorize SpecROP gadgets into generic classes and demonstrate the abundance of such gadgets in victim libraries. Further, we explore the practicality of influencing multiple control-flow instructions on modern processors, and demonstrate an attack which uses gadget chaining to increase the leakage potential of a Spectre variant, SMoTherSpectre.}
}
@inproceedings{Bialek2018,
  title         = {The Evolution of CFI Attacks and Defenses},
  author        = {Bialek, Joe},
  year          = 2018,
  booktitle     = {OffensiveCon 2018}
}
@inproceedings{bigelow2015,
  title         = {Timely {{Rerandomization}} for {{Mitigating Memory Disclosures}}},
  author        = {Bigelow, David and Hobson, Thomas and Rudd, Robert and Streilein, William and Okhravi, Hamed},
  booktitle     = {Proceedings of the 22nd {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}} - {{CCS}} '15},
  location      = {New York, New York, USA},
  publisher     = {ACM Press},
  volume        = {2015-Octob},
  pages         = {268--279},
  doi           = {10.1145/2810103.2813691},
  isbn          = {978-1-4503-3832-5},
  issn          = 15437221,
  date          = 2015,
  abstract      = {Address Space Layout Randomization (ASLR) can increase the cost of exploiting memory corruption vulnerabilities. One major weakness of ASLR is that it assumes the secrecy of memory addresses and is thus ineffective in the face of memory disclosure vulnerabilities. Even fine-grained variants of ASLR are shown to be ineffective against memory disclosures. In this paper we present an approach that synchronizes randomization with potential runtime disclosure. By applying rerandomization to the memory layout of a process every time it generates an output, our approach renders disclosures stale by the time they can be used by attackers to hijack control flow. We have developed a fully functioning prototype for x86 64 C programs by extending the Linux kernel, GCC, and the libc dynamic linker. The prototype operates on C source code and recompiles programs with a set of augmented information required to track pointer locations and support runtime rerandomization. Using this augmented information we dynamically relocate code segments and update code pointer values during runtime. Our evaluation on the SPEC CPU2006 benchmark, along with other applications, show that our technique incurs a very low performance overhead (2.1\% on average).}
}
@inproceedings{binosi2024,
  title         = {The {{Illusion}} of {{Randomness}}: {{An Empirical Analysis}} of {{Address Space Layout Randomization Implementations}}},
  shorttitle    = {The {{Illusion}} of {{Randomness}}},
  author        = {Binosi, Lorenzo and Barzasi, Gregorio and Carminati, Michele and Zanero, Stefano and Polino, Mario},
  booktitle     = {Proceedings of the 2024 on {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '24},
  pages         = {1360--1374},
  doi           = {10.1145/3658644.3690239},
  isbn          = {979-8-4007-0636-3},
  date          = {2024-12-09},
  abstract      = {Address Space Layout Randomization (ASLR) is a crucial defense mechanism employed by modern operating systems to mitigate exploitation by randomizing processes? memory layouts. However, the stark reality is that real-world implementations of ASLR are imperfect and subject to weaknesses that attackers can exploit. This work evaluates the effectiveness of ASLR on major desktop platforms, including Linux, MacOS, and Windows, by examining the variability in the placement of memory objects across various processes, threads, and system restarts. In particular, we collect samples of memory object locations, conduct statistical analyses to measure the randomness of these placements and examine the memory layout to find any patterns among objects that could decrease this randomness. The results show that while some systems, like Linux distributions, provide robust randomization, others, like Windows and MacOS, often fail to adequately randomize key areas like executable code and libraries. Moreover, we find a significant entropy reduction in the entropy of libraries after the Linux 5.18 version and identify correlation paths that an attacker could leverage to reduce exploitation complexity significantly. Ultimately, we rank the identified weaknesses based on severity and validate our entropy estimates with a proof-of-concept attack. In brief, this paper provides the first comprehensive evaluation of ASLR effectiveness across different operating systems and highlights opportunities for Operating System (OS) vendors to strengthen ASLR implementations.}
}
@article{biondo2018,
  title         = {Back {{To The Epilogue}}: {{Evading Control Flow Guard}} via {{Unaligned Targets}}},
  author        = {Biondo, Andrea and Conti, Mauro and Lain, Daniele},
  doi           = {10.14722/ndss.2018.23318},
  isbn          = 1891562495,
  date          = 2018,
  abstract      = {--Attackers use memory corruption vulnerabilities to compromise systems by hijacking control flow towards attacker-controlled code. Over time, researchers proposed sev-eral countermeasures, such as Address Space Layout Random-ization, Write XOR Execute and Control Flow Integrity (CFI). CFI is one of the most promising solutions, enforcing control flow to adhere to statically determined valid execution paths. To trade with the execution and storage overhead, practical CFI implementations enforce coarser version of CFI. One of the most widely deployed implementations of CFI is the one proposed by Microsoft, named Control Flow Guard (CFG). CFG is currently in place on all Windows operating systems, from Windows 8.1 to the most recent update of Windows 10 (at the time of writing), accounting for more than 500 million machines. In this paper, we show a significant design vulnerability in Windows CFG and propose a specific attack to exploit it: the Back to The Epilogue (BATE) attack. We show that with BATE an attacker can completely evade from CFG and transfer control to any location, thus obtaining arbitrary code execution. BATE leverages the tradeoff of CFG between precision, performance, and backwards compatibility; in particular, the latter one motivates 16-byte address granularity in some circumstances. This vulnerability, inherent to the CFG design, allows us to call portions of code (gadgets) that should not be allowed, and that we can chain together to escape CFG. These gadgets are very common: we ran a thorough evaluation of Windows system libraries, and found many high value targets â€“ exploitable gadgets in code loaded by almost all the applications on 32-bit systems and by web browsers on 64-bit. We also demonstrate the real-world feasibility of our attack by using it to build a remote code execution exploit against the Microsoft Edge web browser running on 64-bit Windows 10. Finally, we discuss possible countermeasures to BATE.}
}
@inproceedings{Bittau2014a,
  title         = {{Hacking Blind}},
  author        = {Bittau, Andrea and Belay, Adam and Mashtizadeh, Ali and Mazi{\`{e}}res, David and Boneh, Dan},
  year          = 2014,
  month         = may,
  booktitle     = {2014 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  pages         = {227--242},
  doi           = {10.1109/SP.2014.22},
  isbn          = {978-1-4799-4686-0},
  issn          = 10816011,
  abstract      = {We show that it is possible to write remote stack buffer overflow exploits without possessing a copy of the target binary or source code, against services that restart after a crash. This makes it possible to hack proprietary closed-binary services, or open-source servers manually compiled and installed from source where the binary remains unknown to the attacker. Traditional techniques are usually paired against a particular binary and distribution where the hacker knows the location of useful gadgets for Return Oriented Programming (ROP). Our Blind ROP (BROP) attack instead remotely finds enough ROP gadgets to perform a write system call and transfers the vulnerable binary over the network, after which an exploit can be completed using known techniques. This is accomplished by leaking a single bit of information based on whether a process crashed or not when given a particular input string. BROP requires a stack vulnerability and a service that restarts after a crash. We implemented Braille, a fully automated exploit that yielded a shell in under 4,000 requests (20 minutes) against a contemporary nginx vulnerability, yaSSL + MySQL, and a toy proprietary server written by a colleague. The attack works against modern 64-bit Linux with address space layout randomization (ASLR), no-execute page protection (NX) and stack canaries.}
}
@inproceedings{Bletsch2011a,
  title         = {Jump-Oriented Programming},
  author        = {Bletsch, Tyler and Jiang, Xuxian and Freeh, Vince W. and Liang, Zhenkai},
  booktitle     = {Proceedings of the 6th {{ACM Symposium}} on {{Information}}, {{Computer}} and {{Communications Security}} - {{ASIACCS}} '11},
  location      = {New York, New York, USA},
  publisher     = {ACM Press},
  pages         = 30,
  doi           = {10.1145/1966913.1966919},
  isbn          = {978-1-4503-0564-8},
  date          = 2011,
  abstract      = {8. Detection Techniques Techniques used for detecting malware can be categorized broadly into three categories: i) Signature-based detection ii) Behaviour-based detection iii) Anomaly-based detection Signature-based detection uses its characterization of what is known to be malicious to decide the maliciousness of a program under inspection. As one may imagine this [...]}
}
@inproceedings{Bletsch2011b,
  title         = {Mitigating code-reuse attacks with control-flow locking},
  author        = {Tyler Bletsch and Xuxian Jiang and Vince W. Freeh},
  year          = 2011,
  booktitle     = {Proceedings of the 27th Annual Computer Security Applications Conference (ACSAC)},
  pages         = {353--362}
}
@inproceedings{Bohme2022,
  title         = {On the Reliability of Coverage-Based Fuzzer Benchmarking},
  author        = {B{\"o}hme, Marcel and Szekeres, L{\'a}szl{\'o} and Metzman, Jonathan},
  year          = 2022,
  month         = may,
  booktitle     = {Proceedings of the 44th {{International Conference}} on {{Software Engineering}}},
  publisher     = {ACM},
  address       = {Pittsburgh Pennsylvania},
  pages         = {1621--1633},
  doi           = {10.1145/3510003.3510230},
  isbn          = {978-1-4503-9221-1}
}
@inproceedings{Bonnaventure2021,
  title         = {Confuzzion: {{A Java Virtual Machine Fuzzer}} for {{Type Confusion Vulnerabilities}}},
  shorttitle    = {Confuzzion},
  author        = {Bonnaventure, William and Khanfir, Ahmed and Bartel, Alexandre and Papadakis, Mike and Traon, Yves Le},
  year          = 2021,
  month         = dec,
  booktitle     = {2021 {{IEEE}} 21st {{International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  pages         = {586--597},
  doi           = {10.1109/QRS54544.2021.00069},
  issn          = {2693-9177},
  abstract      = {Current Java Virtual Machine (JVM) fuzzers aim at generating syntactically valid Java programs, without targeting any particular use of the standard Java library. While effective, such fuzzers fail to discover specific kinds of bugs or vulnerabilities, such as type confusion, that are related to the standard API usage. To deal with this issue, we introduce a mutation-based feedback-guided black-box JVM fuzzer, called Confuzzion. Confuzzion, as the name suggests, targets security-relevant object-oriented flaws with a particular focus on type confusion vulnerabilities. We show that in less than 4 hours, on commodity hardware and without any predefined initialization seed, Confuzzion automatically generates Java programs that reveal JVM vulnerabilities, i.e., the Common Vulnerabilities and Exposures CVE-2017-3272. We also show that state-of-the-art fuzzers or even traditional automatic testing techniques are not capable of detecting such faults, even after 48 hours of execution in the same environment. To the best of our knowledge, Confuzzion is the first fuzzer able to detect JVM type confusion vulnerabilities.}
}
@inproceedings{bosman2014,
  title         = {Framing {{Signals}} - {{A Return}} to {{Portable Shellcode}}},
  author        = {Bosman, Erik and Bos, Herbert},
  booktitle     = {2014 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  pages         = {243--258},
  doi           = {10.1109/SP.2014.23},
  issn          = {2375-1207},
  date          = {2014-05},
  abstract      = {Signal handling has been an integral part of UNIX systems since the earliest implementation in the 1970s. Nowadays, we find signals in all common flavors of UNIX systems, including BSD, Linux, Solaris, Android, and Mac OS. While each flavor handles signals in slightly different ways, the implementations are very similar. In this paper, we show that signal handling can be used as an attack method in exploits and backdoors. The problem has been a part of UNIX from the beginning, and now that advanced security measures like ASLR, DEP and stack cookies have made simple exploitation much harder, our technique is among the lowest hanging fruit available to an attacker. Specifically, we describe Sigreturn Oriented Programming (SROP), a novel technique for exploits and backdoors in UNIX-like systems. Like return-oriented programming (ROP), sigreturn oriented programming constructs what is known as a 'weird machine' that can be programmed by attackers to change the behavior of a process. To program the machine, attackers set up fake signal frames and initiate returns from signals that the kernel never really delivered. This is possible, because UNIX stores signal frames on the process' stack. Sigreturn oriented programming is interesting for attackers, OS developers and academics. For attackers, the technique is very versatile, with pre-conditions that are different from those of existing exploitation techniques like ROP. Moreover, unlike ROP, sigreturn oriented programming programs are portable. For OS developers, the technique presents a problem that has been present in one of the two main operating system families from its inception, while the fixes (which we also present) are non-trivial. From a more academic viewpoint, it is also interesting because we show that sigreturn oriented programming is Turing complete. We demonstrate the usefulness of the technique in three applications. First, we describe the exploitation of a vulnerable web server on different Linux distributions. Second, we build a very stealthy proof-of-concept backdoor. Third, we use SROP to bypass Apple's code signing and security vetting process by building an app that can execute arbitrary system calls. Finally, we discuss mitigation techniques.},
  eventtitle    = {2014 {{IEEE Symposium}} on {{Security}} and {{Privacy}}}
}
@article{boyd2010,
  title         = {On the {{General Applicability}} of {{Instruction-Set Randomization}}},
  author        = {Boyd, Stephen W. and Kc, Gaurav S. and Locasto, Michael E. and Keromytis, Angelos D. and Prevelakis, Vassilis},
  volume        = 7,
  number        = 3,
  pages         = {255--270},
  doi           = {10.1109/TDSC.2008.58},
  issn          = {1941-0018},
  date          = {2010-07},
  journaltitle  = {IEEE Transactions on Dependable and Secure Computing},
  abstract      = {We describe Instruction-Set Randomization (ISR), a general approach for safeguarding systems against any type of code-injection attack. We apply Kerckhoffs' principle to create OS process-specific randomized instruction sets (e.g., machine instructions) of the system executing potentially vulnerable software. An attacker who does not know the key to the randomization algorithm will inject code that is invalid for that (randomized) environment, causing a runtime exception. Our approach is applicable to machine-language programs and scripting and interpreted languages. We discuss three approaches (protection for Intel x86 executables, Perl scripts, and SQL queries), one from each of the above categories. Our goal is to demonstrate the generality and applicability of ISR as a protection mechanism. Our emulator-based prototype demonstrates the feasibility ISR for x86 executables and should be directly usable on a suitably modified processor. We demonstrate how to mitigate the significant performance impact of emulation-based ISR by using several heuristics to limit the scope of randomized (and interpreted) execution to sections of code that may be more susceptible to exploitation. The SQL prototype consists of an SQL query-randomizing proxy that protects against SQL injection attacks with no changes to database servers, minor changes to CGI scripts, and with negligible performance overhead. Similarly, the performance penalty of a randomized Perl interpreter is minimal. Where the performance impact of our proposed approach is acceptable (i.e., in an already-emulated environment, in the presence of programmable or specialized hardware, or in interpreted languages), it can serve as a broad protection mechanism and complement other security mechanisms.}
}
@inproceedings{Braden2016,
  title         = {{Leakage-Resilient Layout Randomization for Mobile Devices}},
  author        = {Braden, Kjell and Crane, Stephen and Davi, Lucas and Franz, Michael and Larsen, Per and Liebchen, Christopher and Sadeghi, Ahmad-Reza},
  year          = 2016,
  booktitle     = {Proceedings 2016 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  doi           = {10.14722/ndss.2016.23364},
  isbn          = {1-891562-41-X},
  abstract      = {--Attack techniques based on code reuse continue to enable real-world exploits bypassing all current mitigations. Code randomization defenses greatly improve resilience against code reuse. Unfortunately, sophisticated modern attacks such as JIT-ROP can circumvent randomization by discovering the actual code layout on the target and relocating the attack payload on the fly. Hence, effective code randomization additionally requires that the code layout cannot be leaked to adversaries. Previous approaches to leakage-resilient diversity have either relied on hardware features that are not available in all proces-sors, particularly resource-limited processors commonly found in mobile devices, or they have had high memory overheads. We introduce a code randomization technique that avoids these limitations and scales down to mobile and embedded devices: Leakage-Resilient Layout Randomization (LR 2). Whereas previous solutions have relied on virtualization, x86 segmentation, or virtual memory support, LR 2 merely requires the underlying processor to enforce a W\oplus{}X policy--a feature that is virtually ubiquitous in modern processors, including mobile and embedded variants. Our evaluation shows that LR 2 provides the same security as existing virtualization-based solutions while avoiding design decisions that would prevent deployment on less capable yet equally vulnerable systems. Although we enforce execute-only permissions in software, LR 2 is as efficient as the best-in-class virtualization-based solution.}
}
@inproceedings{Brennan2020,
  title         = {{{JVM Fuzzing}} for {{JIT-Induced Side-Channel Detection}}},
  author        = {Brennan, Tegan and Saha, Seemanta and Bultan, Tevfik},
  year          = 2020,
  month         = oct,
  booktitle     = {2020 {{IEEE}}/{{ACM}} 42nd {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  pages         = {1011--1023},
  issn          = {1558-1225},
  abstract      = {Timing side channels arise in software when a program's execution time can be correlated with security-sensitive program input. Recent results on software side-channel detection focus on analysis of program's source code. However, runtime behavior, in particular optimizations introduced during just-in-time (JIT) compilation, can impact or even introduce timing side channels in programs. In this paper, we present a technique for automatically detecting such JIT-induced timing side channels in Java programs. We first introduce patterns to detect partitions of secret input potentially separable by side channels. Then we present an automated approach for exploring behaviors of the Java Virtual Machine (JVM) to identify states where timing channels separating these partitions arise. We evaluate our technique on three datasets used in recent work on side-channel detection. We find that many code variants labeled ``safe'' with respect to side-channel vulnerabilities are in fact vulnerable to JIT-induced timing side channels. Our results directly contradict the conclusions of four separate state-of-the-art program analysis tools for side-channel detection and demonstrate that JIT-induced side channels are prevalent and can be detected automatically.}
}
@inproceedings{Bruschi2007,
  title         = {{Diversified process replic{\ae}; for defeating memory error exploits}},
  author        = {Bruschi, Danilo and Cavallaro, Lorenzo and Lanzi, Andrea},
  year          = 2007,
  month         = apr,
  booktitle     = {Conference Proceedings of the IEEE International Performance, Computing, and Communications Conference},
  pages         = {434--441},
  doi           = {10.1109/PCCC.2007.358924},
  isbn          = 1424411386,
  issn          = {1097-2641}
}
@inproceedings{Bulck2018,
  title         = {Foreshadow: {{Extracting}} the {{Keys}} to the {{Intel SGX Kingdom}} with {{Transient Out-of-Order Execution}}},
  shorttitle    = {Foreshadow},
  author        = {Bulck, Jo Van and Minkin, Marina and Weisse, Ofir and Genkin, Daniel and Kasikci, Baris and Piessens, Frank and Silberstein, Mark and Wenisch, Thomas F. and Yarom, Yuval and Strackx, Raoul},
  pages         = 991,
  isbn          = {978-1-939133-04-5},
  date          = 2018,
  eventtitle    = {27th {{USENIX Security Symposium}} ({{USENIX Security}} 18)}
}
@article{Burow2016,
  title         = {{Control-Flow Integrity}},
  author        = {Burow, Nathan and Carr, Scott A and Nash, Joseph and Larsen, Per and Franz, Michael and Brunthaler, Stefan and Payer, Mathias},
  year          = 2017,
  month         = apr,
  journal       = {ACM Computing Surveys},
  volume        = 50,
  number        = 1,
  pages         = {1--33},
  doi           = {10.1145/3054924},
  issn          = {0360-0300},
  abstract      = {Memory corruption errors in C/C ++ programs remain the most common source of security vulnerabilities in today's systems. Control-flow hijacking attacks exploit memory corruption vulnerabilities to divert program execution away from the intended control flow. Researchers have spent more than a decade studying and refining defenses based on Control-Flow Integrity (CFI), and this technique is now integrated into several production compilers. However, so far no study has systematically compared the various proposed CFI mechanisms, nor is there any protocol on how to compare such mechanisms. We compare a broad range of CFI mechanisms using a unified nomenclature based on (i) a qualitative discussion of the conceptual security guarantees, (ii) a quantitative security evaluation, and (iii) an empirical evaluation of their performance in the same test environment. For each mechanism, we evaluate (i) protected types of control-flow transfers, (ii) the precision of the protection for forward and backward edges. For open-source compiler-based implementations, we additionally evaluate (iii) the generated equivalence classes and target sets, and (iv) the runtime performance.}
}
@inproceedings{Burow2018a,
  title         = {{SoK: Shining Light on Shadow Stacks}},
  author        = {Burow, Nathan and Zhang, Xinping and Payer, Mathias},
  year          = 2019,
  month         = may,
  booktitle     = {2019 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  pages         = {985--999},
  doi           = {10.1109/SP.2019.00076},
  isbn          = {978-1-5386-6660-9},
  abstract      = {Control-Flow Hijacking attacks are the dominant attack vector against C/C++ programs. Control-Flow Integrity (CFI) solutions mitigate these attacks on the forward edge,i.e., indirect calls through function pointers and virtual calls. Protecting the backward edge is left to stack canaries, which are easily bypassed through information leaks. Shadow Stacks are a fully precise mechanism for protecting backwards edges, and should be deployed with CFI mitigations. We present a comprehensive analysis of all possible shadow stack mechanisms along three axes: performance, compatibility, and security. For performance comparisons we use SPEC CPU2006, while security and compatibility are qualitatively analyzed. Based on our study, we renew calls for a shadow stack design that leverages a dedicated register, resulting in low performance overhead, and minimal memory overhead, but sacrifices compatibility. We present case studies of our implementation of such a design, Shadesmar, on Phoronix and Apache to demonstrate the feasibility of dedicating a general purpose register to a security monitor on modern architectures, and the deployability of Shadesmar. Our comprehensive analysis, including detailed case studies for our novel design, allows compiler designers and practitioners to select the correct shadow stack design for different usage scenarios.},
  mendeley-tags = {read}
}
@inproceedings{Burow2018CFIXX,
  title         = {{CFIXX: Object Type Integrity for C++ Virtual Dispatch}},
  author        = {Burow, Nathan and McKee, Derrick and Carr, Scott A and Payer, Mathias},
  year          = 2018,
  booktitle     = {Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS)}
}
@techreport{Cadar2008,
  title         = {Data Randomization},
  author        = {Cadar, Cristian and Akritidis, Periklis and Costa, Manuel and Martin, Jean-Phillipe and Castro, Miguel},
  year          = 2008,
  month         = {01}
}
@inproceedings{Canella2019,
  title         = {{A Systematic Evaluation of Transient Execution Attacks and Defenses}},
  author        = {Canella, Claudio and Bulck, Jo Van and Schwarz, Michael and Lipp, Moritz and von Berg, Benjamin and Ortner, Philipp and Piessens, Frank and Evtyushkin, Dmitry and Gruss, Daniel},
  year          = 2019,
  month         = aug,
  booktitle     = {28th {USENIX} Security Symposium ({USENIX} Security 19)},
  publisher     = {{USENIX} Association},
  address       = {Santa Clara, CA},
  pages         = {249--266},
  isbn          = {978-1-939133-06-9}
}
@inproceedings{Carlini2015,
  title         = {Control-{{Flow Bending}}: {{On}} the {{Effectiveness}} of {{Control-Flow Integrity}}},
  shorttitle    = {Control-{{Flow Bending}}},
  author        = {Carlini, Nicholas and Barresi, Antonio and Payer, Mathias and Wagner, David and Gross, Thomas R.},
  booktitle     = {{USENIX Security Symposium}},
  pages         = {161--176},
  isbn          = {978-1-931971-23-2},
  date          = 2015,
  abstract      = {Control-Flow Integrity (CFI) is a defense which prevents control-flow hijacking attacks. While recent research has shown that coarse-grained CFI does not stop attacks, fine-grained CFI is believed to be secure. We argue that assessing the effectiveness of practical CFI implementations is non-trivial and that common evaluation metrics fail to do so. We then evaluate fullyprecise static CFI -- the most restrictive CFI policy that does not break functionality -- and reveal limitations in its security. Using a generalization of non-control-data attacks which we call Control-Flow Bending (CFB), we show how an attacker can leverage a memory corruption vulnerability to achieve Turing-complete computation on memory using just calls to the standard library. We use this attack technique to evaluate fully-precise static CFI on six real binaries and show that in five out of six cases, powerful attacks are still possible. Our results suggest that CFI may not be a reliable defense against memory corruption vulnerabilities. We further evaluate shadow stacks in combination with CFI and find that their presence for security is necessary: deploying shadow stacks removes arbitrary code execution capabilities of attackers in three of six cases.}
}
@inproceedings{Carr,
  title         = {{DataShield: Configurable Data Confidentiality and Integrity}},
  author        = {Carr, Scott A and Payer, Mathias},
  year          = 2017,
  booktitle     = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security - ASIA CCS '17},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {193--204},
  doi           = {10.1145/3052973.3052983},
  isbn          = 9781450349444
}
@inproceedings{castro2006,
  title         = {Securing Software by Enforcing Data-Flow Integrity},
  author        = {Castro, Miguel and Costa, Manuel and Harris, Tim},
  booktitle     = {Proceedings of the 7th {{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}} - {{Volume}} 7},
  location      = {USA},
  publisher     = {USENIX Association},
  series        = {{{OSDI}} '06},
  pages         = 11,
  date          = {2006-11-06},
  abstract      = {Software attacks often subvert the intended data-flow in a vulnerable program. For example, attackers exploit buffer overflows and format string vulnerabilities to write data to unintended locations. We present a simple technique that prevents these attacks by enforcing data-flow integrity. It computes a data-flow graph using static analysis, and it instruments the program to ensure that the flow of data at runtime is allowed by the data-flow graph. We describe an efficient implementation of data-flow integrity enforcement that uses static analysis to reduce instrumentation overhead. This implementation can be used in practice to detect a broad class of attacks and errors because it can be applied automatically to C and C++ programs without modifications, it does not have false positives, and it has low overhead.}
}
@inproceedings{checkoway2010,
  title         = {Return-Oriented Programming without Returns},
  author        = {Checkoway, Stephen and Davi, Lucas and Dmitrienko, Alexandra and Sadeghi, Ahmad-Reza and Shacham, Hovav and Winandy, Marcel},
  booktitle     = {Proceedings of the 17th {{ACM}} Conference on {{Computer}} and Communications Security - {{CCS}} '10},
  location      = {New York, New York, USA},
  publisher     = {ACM Press},
  pages         = 559,
  doi           = {10.1145/1866307.1866370},
  isbn          = {978-1-4503-0245-6},
  issn          = 15437221,
  date          = 2010,
  abstract      = {We show that on both the x86 and ARM architectures it is possible to mount return-oriented programming attacks without using return instructions. Our attacks instead make use of certain instruction sequences that behave like a return, which occur with sufficient frequency in large libraries on (x86) Linux and (ARM) Android to allow creation of Turing-complete gadget sets. Because they do not make use of return instructions, our new attacks have negative implications for several recently proposed classes of defense against return-oriented programming: those that detect the too-frequent use of returns in the instruction stream; those that detect violations of the last-in, first-out invariant normally maintained for the return-address stack; and those that modify compilers to produce code that avoids the return instruction.}
}
@incollection{Chen2015b,
  title         = {A practical approach for adaptive data structure layout randomization},
  author        = {Chen, Ping and Xu, Jun and Lin, Zhiqiang and Xu, Dongyan and Mao, Bing and Liu, Peng},
  year          = 2015,
  booktitle     = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  volume        = 9326,
  pages         = {69--89},
  doi           = {10.1007/978-3-319-24174-6_4},
  isbn          = {978-3-319-24173-9},
  note          = {ISSN: 16113349}
}
@inproceedings{Chen2015c,
  title         = {{StackArmor: Comprehensive Protection from Stack-based Memory Error Vulnerabilities for Binaries}},
  author        = {Chen, Xi and Slowinska, Asia and Andriesse, Dennis and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2015,
  doi           = {10.14722/ndss.2015.23248},
  isbn          = {189156238X},
  abstract      = {StackArmor is a comprehensive protection tech-nique for stack-based memory error vulnerabilities in binaries. It relies on binary analysis and rewriting strategies to drastically re-duce the uniquely high spatial and temporal memory predictabil-ity of traditional call stack organizations. Unlike prior solutions, StackArmor can protect against arbitrary stack-based attacks, requires no access to the source code, and offers a policy-driven protection strategy that allows end users to tune the security-performance tradeoff according to their needs. We present an implementation of StackArmor for x86 64 Linux and provide a detailed experimental analysis of our prototype on popular server programs and standard benchmarks (SPEC CPU2006). Our results demonstrate that StackArmor offers better security than prior binary-and source-level approaches, at the cost of only mod-est performance and memory overhead even with full protection.}
}
@inproceedings{chen2016,
  title         = {Understanding the Impact of Compiler Bugs in {{GCC}} and {{LLVM}}},
  author        = {Chen, Peng and Li, Yuekang and Su, Zhendong and Chen, Chao and Xue, Jingling},
  booktitle     = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  location      = {{Seattle, WA, USA}},
  publisher     = {{Association for Computing Machinery}},
  doi           = {10.1145/2950290.2950347},
  isbn          = 9781450342185,
  date          = {2016-11-13}
}
@article{Chen2016a,
  title         = {Coverage-Directed Differential Testing of {{JVM}} Implementations},
  author        = {Chen, Yuting and Su, Ting and Sun, Chengnian and Su, Zhendong and Zhao, Jianjun},
  year          = 2016,
  month         = aug,
  journal       = {ACM SIGPLAN Notices},
  publisher     = {Association for Computing Machinery (ACM)},
  volume        = 51,
  number        = 6,
  pages         = {85--99},
  doi           = {10.1145/2980983.2908095},
  issn          = {0362-1340},
  abstract      = {{$<$}p{$>$}Java virtual machine (JVM) is a core technology, whose reliability is critical. Testing JVM implementations requires painstaking effort in designing test classfiles (\textasteriskcentered.class) along with their test oracles. An alternative is to employ binary fuzzing to differentially test JVMs by blindly mutating seeding classfiles and then executing the resulting mutants on different JVM binaries for revealing inconsistent behaviors. However, this blind approach is not cost effective in practice because most of the mutants are invalid and redundant. This paper tackles this challenge by introducing classfuzz, a coverage-directed fuzzing approach that focuses on representative classfiles for differential testing of JVMs' startup processes. Our core insight is to (1) mutate seeding classfiles using a set of predefined mutation operators (mutators) and employ Markov Chain Monte Carlo (MCMC) sampling to guide mutator selection, and (2) execute the mutants on a reference JVM implementation and use coverage uniqueness as a discipline for accepting representative ones. The accepted classfiles are used as inputs to differentially test different JVM implementations and find defects. We have implemented classfuzz and conducted an extensive evaluation of it against existing fuzz testing algorithms. Our evaluation results show that classfuzz can enhance the ratio of discrepancy-triggering classfiles from 1.7\% to 11.9\%. We have also reported 62 JVM discrepancies, along with the test classfiles, to JVM developers. Many of our reported issues have already been confirmed as JVM defects, and some even match recent clarifications and changes to the Java SE 8 edition of the JVM specification.{$<$}/p{$>$}}
}
@inproceedings{Chen2017a,
  title         = {{CodeArmor: Virtualizing the Code Space to Counter Disclosure Attacks}},
  author        = {Chen, Xi and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2017,
  booktitle     = {Proceedings - 2nd IEEE European Symposium on Security and Privacy, EuroS and P 2017},
  pages         = {514--529},
  doi           = {10.1109/EuroSP.2017.17},
  isbn          = 9781509057610,
  abstract      = {--Code diversification is an effective strategy to pre-vent modern code-reuse exploits. Unfortunately, diversification techniques are inherently vulnerable to information disclosure. Recent diversification-aware ROP exploits have demonstrated that code disclosure attacks are a realistic threat, with an attacker able to read or execute arbitrary code memory and gather enough gadgets to bypass state-of-the-art code diversi-fication defenses. In this paper, we present CodeArmor, a binary-level system to harden code diversification against all the existing read-based and execution-based code disclosure attacks. To counter such attacks, CodeArmor virtualizes the code space to com-pletely decouple code pointer values from the concrete location of their targets in the memory address space. Using a com-bination of run-time randomization and pervasively deployed honey gadgets, code space virtualization probabilistically en-sures that only code references that can legitimately be issued by the program are effectively translated to the concrete code space. This strategy significantly reduces the attack surface, limiting the attacker to only code pointer gadgets that can be leaked from data memory. In addition, unlike existing leakage-resistant code diversification techniques that provide similar security guarantees, CodeArmor requires no access to source code, hypervisors, or special hardware support. Our experimental results show that CodeArmor provides a strong line of defense against existing and future attacks, at the cost of only low average performance overhead (6.9\% on SPEC and 14.5\% on popular server programs, and even lower--roughly halving such average overheads--when oper-ating aggressive inlining optimizations at the binary level).},
  mendeley-tags = {read}
}
@inproceedings{Chen2018a,
  title         = {Angora: {{Efficient Fuzzing}} by {{Principled Search}}},
  author        = {Chen, Peng and Chen, Hao},
  year          = 2018,
  month         = may,
  booktitle     = {2018 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  publisher     = {IEEE},
  pages         = {711--725},
  doi           = {10.1109/SP.2018.00046},
  isbn          = {978-1-5386-4353-2},
  abstract      = {Fuzzing is a popular technique for finding software bugs. However, the performance of the state-of-the-art fuzzers leaves a lot to be desired. Fuzzers based on symbolic execution produce quality inputs but run slow, while fuzzers based on random mutation run fast but have difficulty producing quality inputs. We propose Angora, a new mutation-based fuzzer that outperforms the state-of-the-art fuzzers by a wide margin. The main goal of Angora is to increase branch coverage by solving path constraints without symbolic execution. To solve path constraints efficiently, we introduce several key techniques: scalable byte-level taint tracking, context-sensitive branch count, search based on gradient descent, and input length exploration. On the LAVA-M data set, Angora found almost all the injected bugs, found more bugs than any other fuzzer that we compared with, and found eight times as many bugs as the second-best fuzzer in the program who. Angora also found 103 bugs that the LAVA authors injected but could not trigger. We also tested Angora on eight popular, mature open source programs. Angora found 6, 52, 29, 40 and 48 new bugs in file, jhead, nm, objdump and size, respectively. We measured the coverage of Angora and evaluated how its key techniques contribute to its impressive performance.}
}
@inproceedings{Chen2019jvm,
  title         = {Deep {{Differential Testing}} of {{JVM Implementations}}},
  author        = {Chen, Yuting and Su, Ting and Su, Zhendong},
  year          = 2019,
  month         = may,
  booktitle     = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  pages         = {1257--1268},
  doi           = {10.1109/ICSE.2019.00127},
  issn          = {1558-1225},
  abstract      = {The Java Virtual Machine (JVM) is the cornerstone of the widely-used Java platform. Thus, it is critical to ensure the reliability and robustness of popular JVM implementations. However, little research exists on validating production JVMs. One notable effort is classfuzz, which mutates Java bytecode syntactically to stress-test different JVMs. It is shown that classfuzz mainly produces illegal bytecode files and uncovers defects in JVMs' startup processes. It remains a challenge to effectively test JVMs' bytecode verifiers and execution engines to expose deeper bugs. This paper tackles this challenge by introducing classming, a novel, effective approach to performing deep, differential JVM testing. The key of classming is a technique, live bytecode mutation, to generate, from a seed bytecode file f, likely valid, executable (live) bytecode files: (1) capture the seed f's live bytecode, the sequence of its executed bytecode instructions; (2) repeatedly manipulate the control- and data-flow in f's live bytecode to generate semantically different mutants; and (3) selectively accept the generated mutants to steer the mutation process toward live, diverse mutants. The generated mutants are then employed to differentially test JVMs. We have evaluated classming on mainstream JVM implementations, including OpenJDK's HotSpot and IBM's J9, by mutating the DaCapo benchmarks. Our results show that classming is very effective in uncovering deep JVM differences. More than 1,800 of the generated classes exposed JVM differences, and more than 30 triggered JVM crashes. We analyzed and reported the JVM runtime differences and crashes, of which 14 have already been confirmed/fixed, including a highly critical security vulnerability in J9 that allowed untrusted code to disable the security manager and elevate its privileges (CVE-2017-1376).}
}
@inproceedings{chen2019a,
  title         = {{{EnFuzz}}: {{Ensemble Fuzzing}} with {{Seed Synchronization}} among {{Diverse Fuzzers}}},
  author        = {Chen, Yuanliang and Jiang, Yu and Ma, Fuchen and Liang, Jie and Wang, Mingzhe and Zhou, Chijin and Jiao, Xun and Su, Zhuo},
  booktitle     = {28th \{{{USENIX}}\} {{Security Symposium}}, \{{{USENIX}}\} {{Security}} 2019, {{Santa Clara}}, {{CA}}, {{USA}}, {{August}} 14-16, 2019},
  publisher     = {\{USENIX\} Association},
  pages         = {1967--1983},
  isbn          = {978-1-939133-06-9},
  editor        = {Heninger, Nadia and Traynor, Patrick},
  date          = 2019,
  abstract      = {Fuzzing is widely used for vulnerability detection. There are various kinds of fuzzers with different fuzzing strategies, and most of them perform well on their targets. However, in industrial practice, it is found that the performance of those well-designed fuzzing strategies is challenged by the complexity and diversity of real-world applications. In this paper, we systematically study an ensemble fuzzing approach. First, we define the diversity of base fuzzers in three heuristics: diversity of coverage information granularity, diversity of input generation strategy and diversity of seed selection and mutation strategy. Based on those heuristics, we choose several of the most recent base fuzzers that are as diverse as possible, and propose a globally asynchronous and locally synchronous (GALS) based seed synchronization mechanism to seamlessly ensemble those base fuzzers and obtain better performance. For evaluation, we implement EnFuzz based on several widely used fuzzers such as QSYM and FairFuzz, and then we test them on LAVA-M and Google's fuzzing-test-suite, which consists of 24 widely used real-world applications. This experiment indicates that, under the same constraints for resources , these base fuzzers perform differently on different applications, while EnFuzz always outperforms other fuzzers in terms of path coverage, branch coverage and bug discovery. Furthermore, EnFuzz found 60 new vulnerabilities in several well-fuzzed projects such as libpng and libjpeg, and 44 new CVEs were assigned.}
}
@article{Cheng2014,
  title         = {{{ROPecker}}: {{A Generic}} and {{Practical Approach For Defending Against ROP Attacks}}},
  shorttitle    = {{ROPecker}},
  author        = {Cheng, Yueqiang and Zhou, Zongwei and Yu, Miao and Ding, Xuhua and Deng, Robert H.},
  doi           = {10.14722/ndss.2014.23156},
  isbn          = {1-891562-35-5},
  date          = 2014,
  journaltitle  = {Proceedings 2014 Network and Distributed System Security Symposium},
  abstract      = {rop; return-oriented programming; cfi}
}
@online{Chromium,
  title         = {{Chromium}},
  year          = 2022,
  url           = {https://www.chromium.org/}
}
@inproceedings{cloosters2022,
  title         = {{{RiscyROP}}: {{Automated Return-Oriented Programming Attacks}} on {{RISC-V}} and {{ARM64}}},
  shorttitle    = {{RiscyROP}},
  author        = {Cloosters, Tobias and Paa\ss{}en, David and Wang, Jianqiang and Draissi, Oussama and Jauernig, Patrick and Stapf, Emmanuel and Davi, Lucas and Sadeghi, Ahmad-Reza},
  booktitle     = {Proceedings of the 25th {{International Symposium}} on {{Research}} in {{Attacks}}, {{Intrusions}} and {{Defenses}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{RAID}} '22},
  pages         = {30--42},
  doi           = {10.1145/3545948.3545997},
  isbn          = {978-1-4503-9704-9},
  date          = {2022-10-26},
  abstract      = {Return-oriented programming\&nbsp;(ROP) is a powerful run-time exploitation technique to attack vulnerable software. Modern RISC architectures like RISC-V and ARM64 pose new challenges for ROP execution due to the lack of a stack-based return instruction and strict instruction alignment. Further, the large number of caller-saved argument registers significantly reduces the gadget space available to the attacker. Consequently, existing ROP gadget tools for other processor architectures cannot be applied to these RISC architectures. Previous work on RISC-V provides only manual construction of ROP attacks against specially crafted programs, and no analysis of ROP attacks has been conducted for ARM64 yet. In this paper, we address these challenges and present RiscyROP, the first automated ROP gadget finding and chaining toolkit for RISC-V and ARM64. RiscyROP analyzes available gadgets utilizing symbolic execution, and automatically generates complex multi-stage chains to conduct arbitrary function calls. Our approach enables the first investigation of the gadget space on RISC-V and ARM64 real-world binaries. RiscyROP successfully builds ROP chains that enable an attacker to execute arbitrary function calls for the nginx web server as well as any binary that contains the libc library.}
}
@article{Cohen1993,
  title         = {{Operating system protection through program evolution}},
  author        = {Cohen, Frederick B.},
  year          = 1993,
  month         = oct,
  journal       = {Computers and Security},
  volume        = 12,
  number        = 6,
  pages         = {565--584},
  doi           = {10.1016/0167-4048(93)90054-9},
  issn          = {01674048},
  abstract      = {In this paper, we introduce the use of program evolution as a technique for defending against automated attacks on operating systems. {\textcopyright} 1993.}
}
@inproceedings{Corbato1965,
  title         = {{Introduction and overview of the multics system}},
  author        = {Corbat{\'{o}}, F. J. and Vyssotsky, V. A.},
  year          = 1965,
  month         = nov,
  booktitle     = {Proceedings of the November 30--December 1, 1965, fall joint computer conference, part I on XX - AFIPS '65 (Fall, part I)},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = 185,
  doi           = {10.1145/1463891.1463912},
  abstract      = {Multics (Multiplexed Information and Computing Service) is a comprehensive, general-purpose programming system which is being developed as a research project. The initial Multics system will be implemented on the GE 645 computer. One of the overall design goals is to create a computing system which is capable of meeting almost all of the present and near-future requirements of a large computer utility. Such systems must run continuously and reliably 7 days a week, 24 hours a day in a way similar to telephone or power systems, and must be capable of meeting wide service demands: from multiple man-machine interaction to the sequential processing of absentee-user jobs; from the use of the system with dedicated languages and subsystems to the programming of the system itself; and from centralized bulk card, tape, and printer facilities to remotely located terminals. Such information processing and communication systems are believed to be essential for the future growth of computer use in business, in industry, in government and in scientific laboratories as well as stimulating applications which would be otherwise undone.}
}
@inproceedings{Cox2006,
  title         = {N-Variant Systems: A Secretless Framework for Security through Diversity},
  author        = {Cox, Benjamin and Evans, David},
  year          = 2006,
  month         = jul,
  booktitle     = {15th USENIX Security Symposium (USENIX Security 06)},
  publisher     = {USENIX Association},
  address       = {Vancouver, B.C. Canada}
}
@inproceedings{Crane2013,
  title         = {{Booby trapping software}},
  author        = {Crane, Stephen and Larsen, Per and Brunthaler, Stefan and Franz, Michael},
  year          = 2013,
  booktitle     = {Proceedings of the 2013 workshop on New security paradigms workshop - NSPW '13},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {95--106},
  doi           = {10.1145/2535813.2535824},
  isbn          = 9781450325820,
  abstract      = {Cyber warfare is asymmetric in the current paradigm, with attackers having the high ground over defenders. This asymmetry stems from the situation that attackers have the initiative, while defenders concentrate on passive fortifications. Defenders are constantly patching the newest hole in their defenses and creating taller and thicker walls, without placing guards on those walls to watch for the enemy and react to attacks. Current passive cyber security defenses such as intrusion detection, anti-virus, and hardened software are not sufficient to repel attackers. In fact, in conventional warfare this passivity would be entirely nonsensical, given the available active strategies, such as counterattacks and deception. Based on this observation, we have identified the technique of booby trapping software. This extends the arsenal of weaponry available to defenders with an active technique for directly reacting to attacks. Ultimately, we believe this approach will restore some of the much sought after equilibrium between attackers and defenders in the digital domain. Copyright 2013 ACM.},
  language      = {en}
}
@inproceedings{Crane2015,
  title         = {{Readactor: Practical Code Randomization Resilient to Memory Disclosure}},
  shorttitle    = {Readactor},
  author        = {Crane, Stephen and Liebchen, Christopher and Homescu, Andrei and Davi, Lucas and Larsen, Per and Sadeghi, Ahmad-Reza and Brunthaler, Stefan and Franz, Michael},
  year          = 2015,
  month         = may,
  booktitle     = {2015 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  volume        = {2015-July},
  pages         = {763--780},
  doi           = {10.1109/SP.2015.52},
  isbn          = {978-1-4673-6949-7},
  issn          = 10816011,
  abstract      = {--Code-reuse attacks such as return-oriented pro-gramming (ROP) pose a severe threat to modern software. Designing practical and effective defenses against code-reuse attacks is highly challenging. One line of defense builds upon fine-grained code diversification to prevent the adversary from constructing a reliable code-reuse attack. However, all solutions proposed so far are either vulnerable to memory disclosure or are impractical for deployment on commodity systems. In this paper, we address the deficiencies of existing solutions and present the first practical, fine-grained code randomization defense, called Readactor, resilient to both static and dynamic ROP attacks. We distinguish between direct memory disclosure, where the attacker reads code pages, and indirect memory disclosure, where attackers use code pointers on data pages to infer the code layout without reading code pages. Unlike previous work, Readactor resists both types of memory disclosure. Moreover, our technique protects both statically and dynamically generated code. We use a new compiler-based code generation paradigm that uses hardware features provided by modern CPUs to enable execute-only memory and hide code pointers from leakage to the adversary. Finally, our extensive evaluation shows that our approach is practical--we protect the entire Google Chromium browser and its V8 JIT compiler--and efficient with an average SPEC CPU2006 performance overhead of only 6.4{\%}.}
}
@inproceedings{Crane2015b,
  title         = {{It's a TRaP}},
  author        = {Crane, Stephen and Franz, Michael and Volckaert, Stijn and Schuster, Felix and Liebchen, Christopher and Larsen, Per and Davi, Lucas and Sadeghi, Ahmad-Reza and Holz, Thorsten and {De Sutter}, Bjorn},
  year          = 2015,
  booktitle     = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {243--255},
  doi           = {10.1145/2810103.2813682},
  isbn          = 9781450338325,
  issn          = 15437221,
  abstract      = {Code-reuse attacks continue to evolve and remain a severe threat to modern software. Recent research has proposed a variety of defenses with differing security, efficiency, and practicality characteristics. Whereas the majority of these solutions focus on specific code-reuse attack variants such as return-oriented programming (ROP), other attack variants that reuse whole functions, such as the classic return-into-libc, have received much less attention. Mitigating function-level code reuse is highly challenging because one needs to distin-guish a legitimate call to a function from an illegitimate one. In fact, the recent counterfeit object-oriented programming (COOP) attack demonstrated that the majority of code-reuse defenses can be bypassed by reusing dynamically bound func-tions, i.e., functions that are accessed through global offset tables and virtual function tables, respectively. In this paper, we first significantly improve and simplify the COOP attack. Based on a strong adversarial model, we then present the design and implementation of a compre-hensive code-reuse defense which is resilient against reuse of dynamically-bound functions. In particular, we introduce two novel defense techniques: (i) a practical technique to randomize the layout of tables containing code pointers re-silient to memory disclosure and (ii) booby trap insertion to mitigate the threat of brute-force attacks iterating over the randomized tables. Booby traps serve the dual purpose of preventing fault-analysis side channels and ensuring that each table has sufficiently many possible permutations. Our detailed evaluation demonstrates that our approach is secure, effective, and practical. We prevent realistic, COOP-style attacks against the Chromium web browser and report an av-erage overhead of 1.1{\%} on the SPEC CPU2006 benchmarks.}
}
@inproceedings{dang2017a,
  title         = {Oscar: {{A Practical Page-Permissions-Based Scheme}} for {{Thwarting Dangling Pointers}}},
  shorttitle    = {Oscar},
  author        = {Dang, Thurston H. Y. and Maniatis, Petros and Wagner, David},
  pages         = {815--832},
  isbn          = {978-1-931971-40-9},
  date          = 2017,
  eventtitle    = {26th {{USENIX Security Symposium}} ({{USENIX Security}} 17)}
}
@inproceedings{Davi2014,
  title         = {Stitching the {{Gadgets}}: {{On}} the {{Ineffectiveness}} of {{Coarse-Grained Control-Flow Integrity Protection}}},
  author        = {Davi, Lucas and Sadeghi, Ahmad-Reza and Lehmann, Daniel and Monrose, Fabian},
  booktitle     = {23rd {{USENIX Security Symposium}} ({{USENIX Security}} 14)},
  pages         = {401--416},
  isbn          = {978-1-931971-15-7},
  date          = 2014,
  abstract      = {Return-oriented programming (ROP) offers a robust attack technique that has, not surprisingly, been extensively used to exploit bugs in modern software programs (e.g., web browsers and PDF readers). ROP attacks require no code injection, and have already been shown to be powerful enough to bypass fine-grained memory randomization (ASLR) defenses. To counter this ingenious attack strategy, several proposals for enforcement of (coarse-grained) control-flow integrity (CFI) have emerged. The key argument put forth by these works is that coarse-grained CFI policies are sufficient to prevent ROP attacks. As this reasoning has gained traction, ideas put forth in these proposals have even been incorporated into coarse-grained CFI defenses in widely adopted tools (e.g., Microsoft's EMET framework). In this paper, we provide the first comprehensive security analysis of various CFI solutions (covering kBouncer, ROPecker, CFI for COTS binaries, ROPGuard, and Microsoft EMET 4.1). A key contribution is in demonstrating that these techniques can be effectively undermined, even under weak adversarial assumptions. More specifically, we show that with bare minimum assumptions, turing-complete and real-world ROP attacks can still be launched even when the strictest of enforcement policies is in use. To do so, we introduce several new ROP attack primitives, and demonstrate the practicality of our approach by transforming existing real-world exploits into more stealthy attacks that bypass coarse-grained CFI defenses.}
}
@inproceedings{Davi2015,
  title         = {{Isomeron: Code Randomization Resilient to (Just-In-Time) Return-Oriented Programming}},
  shorttitle    = {Isomeron},
  author        = {Davi, Lucas and Liebchen, Christopher and Sadeghi, Ahmad-Reza and Snow, Kevin Z. and Monrose, Fabian},
  year          = 2015,
  booktitle     = {Proceedings 2015 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  doi           = {10.14722/ndss.2015.23262},
  isbn          = {1-891562-38-X},
  issn          = {1545-5971},
  abstract      = {--Until recently, it was widely believed that code randomization (such as fine-grained ASLR) can effectively mit-igate code reuse attacks. However, a recent attack strategy, dubbed just-in-time return oriented programming (JIT-ROP), circumvents code randomization by disclosing the (randomized) content of many memory pages at runtime. In order to remedy this situation, new and improved code randomization defenses have been proposed. The contribution of this paper is twofold: first, we conduct a security analysis of a recently proposed fine-grained ASLR scheme that aims at mitigating JIT-ROP based on hiding direct code references in branch instructions. In particular, we demon-strate its weaknesses by constructing a novel JIT-ROP attack that is solely based on exploiting code references residing on the stack and heap. Our attack stresses that designing code randomization schemes resilient to memory disclosure is highly challenging. Second, we present a new and hybrid defense approach, dubbed Isomeron, that combines code randomization with execution-path randomization to mitigate conventional ROP and JIT-ROP attacks. Our reference implementation of Isomeron neither requires source code nor a static analysis phase. We evaluated its efficiency based on SPEC benchmarks and discuss its effectiveness against various kinds of code reuse attacks.},
  language      = {en}
}
@online{DEP,
  title         = {{Data Execution Prevention}},
  author        = {Microsoft},
  year          = 2022,
  url           = {https://docs.microsoft.com/en-us/windows/win32/memory/data-execution-prevention}
}
@inproceedings{duta2023,
  title         = {Let {{Me Unwind That For You}}: {{Exceptions}} to {{Backward-Edge Protection}}},
  author        = {Duta, Victor and Freyer, Fabian and Pagani, Fabio and Muench, Marius and Giuffrida, Cristiano},
  booktitle     = {{NDSS}},
  date          = {2023-02}
}
@inproceedings{Erlingsson2006,
  title         = {{XFI}: Software Guards for System Address Spaces},
  author        = {{\'{U}}lfar Erlingsson and Martin Abadi and Michael Vrable and Mihai Budiu and George C. Necula},
  year          = 2006,
  month         = nov,
  booktitle     = {Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  publisher     = {USENIX Association},
  address       = {Seattle, WA}
}
@inproceedings{Evans2015,
  title         = {{Missing the Point(er): On the Effectiveness of Code Pointer Integrity}},
  shorttitle    = {Missing the Point(er)},
  author        = {Evans, Isaac and Fingeret, Sam and Gonzalez, Julian and Otgonbaatar, Ulziibayar and Tang, Tiffany and Shrobe, Howard and Sidiroglou-Douskos, Stelios and Rinard, Martin and Okhravi, Hamed},
  year          = 2015,
  month         = may,
  booktitle     = {2015 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  volume        = {2015-July},
  pages         = {781--796},
  doi           = {10.1109/SP.2015.53},
  isbn          = {978-1-4673-6949-7},
  issn          = 10816011,
  abstract      = {--Memory corruption attacks have been known for decades, but they are still a major vector of attack for compro-mising modern systems. Numerous defenses have been proposed against memory corruption attacks, but they all have their limitations and weaknesses. Stronger defenses such as complete memory safety incur a large overhead, while weaker ones such as practical control flow integrity have been shown to be ineffective. A recent technique called code pointer integrity (CPI) promises to balance security and performance by focusing memory safety on code pointers thus preventing most control-hijacking attacks while maintaining low overhead. CPI protects access to code pointers by storing them in a safe region that is protected by instruction level isolation. On x86-32, this isolation is enforced by hardware; on x86-64 and ARM, isolation is enforced by information hiding. We show that, for architectures that rely on information hiding, CPI's safe region can be leaked and then maliciously modified by using data pointer overwrites. We implement a proof-of-concept exploit against Nginx and successfully bypass CPI in 6 seconds with 13 observed crashes. We also present an attack that generates no crashes and is able to bypass CPI in 98 hours. Our attack demonstrates the importance of adequately protecting secrets in security mechanisms and the dangers of relying on difficulty of guessing without guaranteeing the absence of memory leaks},
  language      = {en}
}
@inproceedings{Evans2015a,
  title         = {Control {{Jujutsu}}: {{On}} the {{Weaknesses}} of {{Fine-Grained Control Flow Integrity}}},
  shorttitle    = {Control {{Jujutsu}}},
  author        = {Evans, Isaac and Long, Fan and Otgonbaatar, Ulziibayar and Shrobe, Howard and Rinard, Martin and Okhravi, Hamed and Sidiroglou-Douskos, Stelios},
  booktitle     = {Proceedings of the 22nd {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {Denver Colorado USA},
  publisher     = {ACM},
  pages         = {901--913},
  doi           = {10.1145/2810103.2813646},
  isbn          = {978-1-4503-3832-5},
  date          = {2015-10-12},
  eventtitle    = {{{CCS}}'15: {{The}} 22nd {{ACM Conference}} on {{Computer}} and {{Communications Security}}}
}
@inproceedings{fioraldi2021,
  title         = {The {{Use}} of {{Likely Invariants}} as {{Feedback}} for {{Fuzzers}}},
  author        = {Fioraldi, Andrea and D'Elia, Daniele Cono and Balzarotti, Davide},
  year          = 2021,
  booktitle     = {30th {{USENIX Security Symposium}} ({{USENIX Security}} 21)},
  pages         = {2829--2846},
  isbn          = {978-1-939133-24-3}
}
@inproceedings{Franz2010,
  title         = {{E unibus pluram}},
  shorttitle    = {E unibus pluram},
  author        = {Franz, Michael},
  year          = 2010,
  booktitle     = {Proceedings of the 2010 workshop on New security paradigms - NSPW '10},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = 7,
  doi           = {10.1145/1900546.1900550},
  isbn          = 9781450304153,
  abstract      = {We contend that the time has come to revisit the idea of software diversity for defense purposes. Four fundamental paradigm shifts that have occurred in the past decade now make it viable to distribute a unique version of every program to every user. We outline a practical approach for providing compiler-generated software diversity on a massive scale. It is based on an "App Store" containing a diversification engine (a "multicompiler") that automatically generates a unique, but functionally identical version of every program each time that a downloader requests it. All the different versions of the same program behave in exactly the same way from the perspective of the end-user, but they implement their functionality in subtly different ways. As a result, any specific attack will succeed only on a small fraction of targets. An attacker would require a large number of different attacks and would have no way of knowing a priori which specific attack will succeed on which specific target. Hence, the cost to the attacker is raised dramatically. Equally importantly, our approach makes it much more difficult for an attacker to generate attack vectors by way of reverse engineering of security patches. An attacker requires two pieces of information to extract a vulnerability from a bug fix: the version of the program that is vulnerable and the specific patch that fixes the vulnerability. In an environment in which software is diversified and every instance of every program is unique, we can set things up so that the attacker never obtains a matching pair of vulnerable program and its corresponding bug fix that could be used to identify the vulnerability. We propose a mechanism for incremental updating of diversified software that has this property.}
}
@inproceedings{frassetto2022,
  title         = {{{CFInsight}}: {{A Comprehensive Metric}} for {{CFI Policies}}},
  shorttitle    = {{CFInsight}},
  author        = {Frassetto, Tommaso and Jauernig, Patrick and Koisser, David and Sadeghi, Ahmad-Reza},
  booktitle     = {Proceedings 2022 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {San Diego, CA, USA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2022.23165},
  isbn          = {978-1-891562-74-7},
  date          = 2022,
  eventtitle    = {Network and {{Distributed System Security Symposium}}}
}
@inproceedings{fu2023a,
  title         = {Autofz: {{Automated Fuzzer Composition}} at {{Runtime}}},
  shorttitle    = {Autofz},
  author        = {Fu, Yu-Fu and Lee, Jaehyuk and Kim, Taesoo},
  pages         = {1901--1918},
  isbn          = {978-1-939133-37-3},
  date          = 2023,
  eventtitle    = {32nd {{USENIX Security Symposium}} ({{USENIX Security}} 23)}
}
@inproceedings{Gan2018,
  title         = {{{CollAFL}}: {{Path Sensitive Fuzzing}}},
  shorttitle    = {{CollAFL}},
  author        = {Gan, Shuitao and Zhang, Chao and Qin, Xiaojun and Tu, Xuwen and Li, Kang and Pei, Zhongyu and Chen, Zuoning},
  year          = 2018,
  month         = may,
  booktitle     = {2018 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  pages         = {679--696},
  doi           = {10.1109/SP.2018.00040},
  issn          = {2375-1207},
  abstract      = {Coverage-guided fuzzing is a widely used and effective solution to find software vulnerabilities. Tracking code coverage and utilizing it to guide fuzzing are crucial to coverage-guided fuzzers. However, tracking full and accurate path coverage is infeasible in practice due to the high instrumentation overhead. Popular fuzzers (e.g., AFL) often use coarse coverage information, e.g., edge hit counts stored in a compact bitmap, to achieve highly efficient greybox testing. Such inaccuracy and incompleteness in coverage introduce serious limitations to fuzzers. First, it causes path collisions, which prevent fuzzers from discovering potential paths that lead to new crashes. More importantly, it prevents fuzzers from making wise decisions on fuzzing strategies. In this paper, we propose a coverage sensitive fuzzing solution CollAFL. It mitigates path collisions by providing more accurate coverage information, while still preserving low instrumentation overhead. It also utilizes the coverage information to apply three new fuzzing strategies, promoting the speed of discovering new paths and vulnerabilities. We implemented a prototype of CollAFL based on the popular fuzzer AFL and evaluated it on 24 popular applications. The results showed that path collisions are common, i.e., up to 75\% of edges could collide with others in some applications, and CollAFL could reduce the edge collision ratio to nearly zero. Moreover, armed with the three fuzzing strategies, CollAFL outperforms AFL in terms of both code coverage and vulnerability discovery. On average, CollAFL covered 20\% more program paths, found 320\% more unique crashes and 260\% more bugs than AFL in 200 hours. In total, CollAFL found 157 new security bugs with 95 new CVEs assigned.}
}
@inproceedings{Gawlik2014,
  title         = {{Towards automated integrity protection of C++ virtual function tables in binary programs}},
  author        = {Gawlik, Robert and Holz, Thorsten},
  year          = 2014,
  booktitle     = {Proceedings of the 30th Annual Computer Security Applications Conference on - ACSAC '14},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {396--405},
  doi           = {10.1145/2664243.2664249},
  isbn          = 9781450330053,
  abstract      = {Web browsers are one of the most used, complex, and popular software systems nowadays. They are prone to dangling pointers that result in use-after-free vulnerabilites and this is the de-facto way to exploit them. From a technical point of view, an attacker uses a technique called vtable hijacking to exploit such bugs. More specifically, she crafts bogus virtual tables and lets a freed C++ object point to it in order to gain control over the program at virtual function call sites. In this paper, we present a novel approach towards mitigating and detecting such attacks against C++ binary code. We propose a static binary analysis technique to extract virtual function call site information in an automated way. Leveraging this information, we instrument the given binary executable and add runtime policy enforcements to thwart the illegal usage of these call sites. We implemented the proposed techniques in a prototype called T-VIP and successfully hardened three versions of Microsoft's Internet Explorer and Mozilla Firefox. An evaluation with several zero-day exploits demonstrates that our method prevents all of them. Performance benchmarks both on micro and macro level indicate that the overhead is reasonable with about 2.2{\%}, which is only slightly higher compared to recent compiler-based approaches that address this problem.},
  language      = {en}
}
@inproceedings{georgescu2024,
  title         = {Evolutionary {{Generative Fuzzing}} for {{Differential Testing}} of the {{Kotlin Compiler}}},
  author        = {Georgescu, C\u{a}lin and Olsthoorn, Mitchell and Derakhshanfar, Pouria and Akhin, Marat and Panichella, Annibale},
  booktitle     = {Companion {{Proceedings}} of the 32nd {{ACM International Conference}} on the {{Foundations}} of {{Software Engineering}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{FSE}} 2024},
  pages         = {197--207},
  doi           = {10.1145/3663529.3663864},
  isbn          = {979-8-4007-0658-5},
  date          = {2024-07-10},
  abstract      = {Compiler correctness is a cornerstone of reliable software development. However, systematic testing of compilers is infeasible, given the vast space of possible programs and the complexity of modern programming languages. In this context, differential testing offers a practical methodology as it addresses the oracle problem by comparing the output of alternative compilers given the same set of programs as input. In this paper, we investigate the effectiveness of differential testing in finding bugs within the Kotlin compilers developed at JetBrains. We propose a black-box generative approach that creates input programs for the K1 and K2 compilers. First, we build workable models of Kotlin semantic (semantic interface) and syntactic (enriched context-free grammar) language features, which are subsequently exploited to generate random code snippets. Second, we extend random sampling by introducing two genetic algorithms (GAs) that aim to generate more diverse input programs. Our case study shows that the proposed approach effectively detects bugs in K1 and K2; these bugs have been confirmed and (some) fixed by JetBrains developers. While we do not observe a significant difference w.r.t. the number of defects uncovered by the different search algorithms, random search and GAs are complementary as they find different categories of bugs. Finally, we provide insights into the relationships between the size, complexity, and fault detection capability of the generated input programs.}
}
@inproceedings{ghaffarinia2019,
  title         = {Binary {{Control-Flow Trimming}}},
  author        = {Ghaffarinia, Masoud and Hamlen, Kevin W.},
  booktitle     = {Proceedings of the 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {London United Kingdom},
  publisher     = {ACM},
  pages         = {1009--1022},
  doi           = {10.1145/3319535.3345665},
  isbn          = {978-1-4503-6747-9},
  date          = {2019-11-06},
  eventtitle    = {{{CCS}} '19: 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}}
}
@inproceedings{Giontaa2015,
  title         = {{HideM: Protecting the contents of userspace memory in the face of disclosure vulnerabilities}},
  author        = {Gionta, Jason and Enck, William and Ning, Peng},
  year          = 2015,
  booktitle     = {CODASPY 2015 - Proceedings of the 5th ACM Conference on Data and Application Security and Privacy},
  pages         = {325--336},
  doi           = {10.1145/2699026.2699107},
  isbn          = 9781450331913,
  abstract      = {Memory disclosure vulnerabilities have become a common component for enabling reliable exploitation of systems by leaking the contents of executable data. Previous research towards protecting executable data fromdisclosure has failed to gain popularity due to large performance penalties and required architectural changes. Other research has focused on protecting application data but fails to consider a vul- nerable application that leaks its own executable data. In this paper we presentHideM, a practical system for pro- tecting against memory disclosures in contemporary com- modity systems. HideM addresses limitations in existing ad- vanced security protections (e.g., fine-grained ASLR, CFI) wherein an adversary discloses executable data from mem- ory, reasons about protection weaknesses, and builds cor- responding exploits. HideM uses the split-TLB architec- ture, commonly found in CPUs, to enable fine-grained exe- cute and read permission on memory. HideM enforces fine- grained permission based on policy generated from binary structure thus enabling protection of Commercial-Off-The- Shelf (COTS) binaries. In our evaluation of HideM, we find application overhead ranges from a 6.5{\%} increase to a 2{\%} reduction in runtime and observe runtime memory overhead ranging from 0.04{\%} to 25{\%}. HideM requires adversaries to guess ROP gadget locations making exploitation unreliable. We find adversaries have less than a 16{\%} chance of correctly guessing a single gadget across all 28 evaluated applications. Thus, HideM is a practical system for protecting vulnerable applications which leak executable data.}
}
@inproceedings{Goktas2016,
  title         = {{Undermining Information Hiding (and What to Do about It)}},
  author        = {G{\"{o}}kta{\c s}, Enes and Gawlik, Robert and Kollenda, Benjamin and Athanasopoulos, Elias and Portokalidis, Georgios and Giuffrida, Cristiano and Bos, Herbert},
  year          = 2016,
  month         = aug,
  booktitle     = {25th {USENIX} Security Symposium ({USENIX} Security 16)},
  publisher     = {{USENIX} Association},
  address       = {Austin, TX},
  pages         = {105--119},
  isbn          = {978-1-931971-32-4},
  abstract      = {In the absence of hardware-supported segmentation, many state-of-the-art defenses resort to "hiding" sensitive information at a random location in a very large address space. This paper argues that information hiding is a weak isolation model and shows that attackers can find hidden information, such as CPI's SafeStacks, in seconds-by means of thread spraying. Thread spraying is a novel attack technique which forces the victim program to allocate many hidden areas. As a result, the attacker has a much better chance to locate these areas and compromise the defense. We demonstrate the technique by means of attacks on Firefox, Chrome, and MySQL. In addition, we found that it is hard to remove all sensitive information (such as pointers to the hidden region) from a program and show how residual sensitive information allows attackers to bypass defenses completely. We also show how we can harden information hiding techniques by means of an Authenticating Page Mapper (APM) which builds on a user-level page-fault handler to authenticate arbitrary memory reads/writes in the virtual address space. APM bootstraps protected applications with a minimum-sized safe area. Every time the program accesses this area, APM authenticates the access operation, and, if legitimate, expands the area on demand. We demonstrate that APM hardens information hiding significantly while increasing the overhead, on average, 0.3{\%} on baseline SPEC CPU 2006, 0.0{\%} on SPEC with SafeStack and 1.4{\%} on SPEC with CPI.}
}
@inproceedings{Goktas2016b,
  title         = {Out of Control: Overcoming Control-Flow Integrity},
  author        = {G{\"{o}}kta{\c s}, Enes and Athanasopoulos, Elias and Bos, Herbert and Portokalidis, Georgios},
  year          = 2016,
  booktitle     = {Proceedings of the 37th IEEE Symposium on Security and Privacy (S\&P)},
  pages         = {575--589}
}
@inproceedings{Goktas2018,
  title         = {Position-Independent Code Reuse: On the Effectiveness of ASLR in the Absence of Information Disclosure},
  author        = {G{\"{o}}kta{\c s}, Enes and Kollenda, Benjamin and Koppe, Philipp and Bosman, Erik and Portokalidis, Georgios and Holz, Thorsten and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2018,
  month         = apr,
  booktitle     = {2018 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  publisher     = {IEEE},
  pages         = {227--242},
  doi           = {10.1109/EuroSP.2018.00024},
  isbn          = {978-1-5386-4228-3}
}
@inproceedings{Goktas2020,
  title         = {{Speculative Probing}},
  author        = {G{\"{o}}kta{\c s}, Enes and Razavi, Kaveh and Portokalidis, Georgios and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2020,
  month         = oct,
  booktitle     = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  publisher     = {ACM},
  address       = {New York, NY, USA},
  pages         = {1871--1885},
  doi           = {10.1145/3372297.3417289},
  isbn          = {9781450370899}
}
@inproceedings{Gras2017,
  title         = {{{ASLR}} on the {{Line}}: {{Practical Cache Attacks}} on the {{MMU}}},
  author        = {Gras, Ben and Razavi, Kaveh and Bosman, Erik and Bos, Herbert and Giuffrida, Cristiano},
  booktitle     = {Proceedings 2017 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {Reston, VA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2017.23271},
  isbn          = {1-891562-46-0},
  date          = 2017,
  abstract      = {Address space layout randomization (ASLR) is an important first line of defense against memory corruption attacks and a building block for many modern countermeasures. Existing attacks against ASLR rely on software vulnerabilities and/or on repeated (and detectable) memory probing. In this paper, we show that neither is a hard requirement and that ASLR is fundamentally insecure on modern cache-based architectures, making ASLR and caching conflicting requirements (ASLR\oplus{}Cache, or simply AnC). To support this claim, we describe a new EVICT+TIME cache attack on the virtual address translation performed by the memory management unit (MMU) of modern processors. Our AnC attack relies on the property that the MMU's page-table walks result in caching page-table pages in the shared last-level cache (LLC). As a result, an attacker can derandomize virtual addresses of a victim's code and data by locating the cache lines that store the page-table entries used for address translation. Relying only on basic memory accesses allows AnC to be implemented in JavaScript without any specific instructions or software features. We show our JavaScript implementation can break code and heap ASLR in two major browsers running on the latest Linux operating system with 28 bits of entropy in 150 seconds. We further verify that the AnC attack is applicable to every modern architecture that we tried, including Intel, ARM and AMD. Mitigating this attack without naively disabling caches is hard, since it targets the low-level operations of the MMU. We conclude that ASLR is fundamentally flawed in sandboxed environments such as JavaScript and future defenses should not rely on randomized virtual addresses as a building block.}
}
@inproceedings{Gras2018,
  title         = {{Translation Leak-aside Buffer: Defeating Cache Side-channel Protections with {TLB} Attacks}},
  author        = {Gras, Ben and Razavi, Kaveh and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2018,
  month         = aug,
  booktitle     = {27th {USENIX} Security Symposium ({USENIX} Security 18)},
  publisher     = {{USENIX} Association},
  address       = {Baltimore, MD},
  pages         = {955--972},
  isbn          = {978-1-939133-04-5}
}
@inproceedings{Groce2012,
  title         = {Swarm Testing},
  author        = {Groce, Alex and Zhang, Chaoqiang and Eide, Eric and Chen, Yang and Regehr, John},
  year          = 2012,
  month         = jul,
  booktitle     = {Proceedings of the 2012 {{International Symposium}} on {{Software Testing}} and {{Analysis}}},
  publisher     = {ACM},
  address       = {Minneapolis MN USA},
  pages         = {78--88},
  doi           = {10.1145/2338965.2336763},
  isbn          = {978-1-4503-1454-1}
}
@inproceedings{Groce2013,
  title         = {Help, Help, i'm Being Suppressed! {{The}} Significance of Suppressors in Software Testing},
  author        = {Groce, Alex and Zhang, Chaoqiang and Alipour, Mohammad Amin and Eide, Eric and Chen, Yang and Regehr, John},
  year          = 2013,
  month         = nov,
  booktitle     = {2013 {{IEEE}} 24th {{International Symposium}} on {{Software Reliability Engineering}} ({{ISSRE}})},
  publisher     = {IEEE},
  address       = {Pasadena, CA, USA},
  pages         = {390--399},
  doi           = {10.1109/ISSRE.2013.6698892},
  isbn          = {978-1-4799-2366-3}
}
@inproceedings{Gross2023,
  title         = {{{FUZZILLI}}: {{Fuzzing}} for {{JavaScript JIT Compiler Vulnerabilities}}},
  shorttitle    = {{FUZZILLI}},
  author        = {Gro{\ss}, Samuel and Koch, Simon and Bernhard, Lukas and Holz, Thorsten and Johns, Martin},
  year          = 2023,
  booktitle     = {Proceedings 2023 {{Network}} and {{Distributed System Security Symposium}}},
  publisher     = {Internet Society},
  address       = {San Diego, CA, USA},
  doi           = {10.14722/ndss.2023.24290},
  isbn          = {978-1-891562-83-9}
}
@article{Grove2001a,
  title         = {{A framework for call graph construction algorithms}},
  author        = {Grove, David and Chambers, Craig},
  year          = 2001,
  month         = nov,
  journal       = {ACM Transactions on Programming Languages and Systems},
  volume        = 23,
  number        = 6,
  pages         = {685--746},
  doi           = {10.1145/506315.506316},
  issn          = {0164-0925},
  abstract      = {A large number of call graph construction algorithms for object-oriented and functional languages have been proposed, each embodying different tradeoffs between analysis cost and call graph precision. In this article we present a unifying framework for understanding call graph construction algorithms and an empirical comparison of a representative set of algorithms. We first present a general parameterized algorithm that encompasses many well-known and novel call graph construction algorithms. We have implemented this general algorithm in the Vortex compiler infrastructure, a mature, multilanguage, optimizing compiler. The Vortex implementation provides a "level playing field" for meaningful cross-algorithm performance comparisons. The costs and benefits of a number of call graph construction algorithms are empirically assessed by applying their Vortex implementation to a suite of sizeable (5,000 to 50,000 lines of code) Cecil and Java programs. For many of these applications, interprocedural analysis enabled substantial speed-ups over an already highly optimized baseline. Furthermore, a significant fraction of these speed-ups can be obtained through the use of a scalable, near-linear time call graph construction algorithm.}
}
@inproceedings{Gruss2015,
  title         = {Cache {{Template Attacks}}: {{Automating Attacks}} on {{Inclusive Last-Level Caches}}},
  shorttitle    = {Cache {{Template Attacks}}},
  author        = {Gruss, Daniel and Spreitzer, Raphael and Mangard, Stefan},
  pages         = {897--912},
  isbn          = {978-1-939133-11-3},
  date          = 2015,
  eventtitle    = {24th {{USENIX Security Symposium}} ({{USENIX Security}} 15)}
}
@incollection{Gruss2016,
  title         = {Flush+{{Flush}}: {{A Fast}} and {{Stealthy Cache Attack}}},
  shorttitle    = {Flush+{{Flush}}},
  author        = {Gruss, Daniel and Maurice, Cl\'{e}mentine and Wagner, Klaus and Mangard, Stefan},
  booktitle     = {Detection of {{Intrusions}} and {{Malware}}, and {{Vulnerability Assessment}}},
  location      = {Cham},
  publisher     = {Springer International Publishing},
  volume        = 9721,
  pages         = {279--299},
  doi           = {10.1007/978-3-319-40667-1_14},
  isbn          = {978-3-319-40666-4 978-3-319-40667-1},
  editor        = {Caballero, Juan and Zurutuza, Urko and Rodr\'{\i}guez, Ricardo J.},
  date          = 2016
}
@misc{heartbleed,
  title         = {{CVE}-2014-0160: {OpenSSL} {TLS} Heartbeat Extension Buffer Over-read ({Heartbleed})},
  author        = {{MITRE Corporation}},
  year          = 2014,
  note          = {Accessed: 2025-01-24},
  howpublished  = {\url{https://nvd.nist.gov/vuln/detail/CVE-2014-0160}}
}
@inproceedings{Herrera2022,
  title         = {Registered {{Report}}: {{Towards}} a {{Data-Flow-Guided Fuzzer}}},
  author        = {Herrera, Adrian and Payer, Mathias and Hosking, Antony L.},
  year          = 2022,
  month         = feb,
  booktitle     = {International {{Fuzzing Workshop}} 2022},
  pages         = 11,
  abstract      = {Coverage-guided greybox fuzzers rely on feedback derived from control-flow coverage to explore a target program and uncover bugs. This is despite control-flow feedback offering only a coarse-grained approximation of program behavior. Data flow intuitively more-accurately characterizes program behavior. Despite this advantage, fuzzers driven by data-flow coverage have received comparatively little attention, appearing mainly when heavyweight program analyses (e.g., taint analysis, symbolic execution) are used. Unfortunately, these more accurate analyses incur a high run-time penalty, impeding fuzzer throughput. Lightweight data-flow alternatives to control-flow fuzzing remain unexplored.}
}
@article{herrera2023,
  title         = {{{DatAFLow}}: {{Toward}} a {{Data-Flow-Guided Fuzzer}}},
  shorttitle    = {{DatAFLow}},
  author        = {Herrera, Adrian and Payer, Mathias and Hosking, Antony L.},
  pages         = 3587156,
  doi           = {10.1145/3587156},
  issn          = {1049-331X, 1557-7392},
  date          = {2023-03-10},
  journaltitle  = {ACM Transactions on Software Engineering and Methodology},
  shortjournal  = {ACM Trans. Softw. Eng. Methodol.},
  abstract      = {Coverage-guided greybox fuzzers rely on control-flow coverage feedback to explore a target program and uncover bugs. Compared to control-flow coverage, data-flow coverage offers a more fine-grained approximation of program behavior. Data-flow coverage captures behaviors not visible as control flow and should intuitively discover more (or different) bugs. Despite this advantage, fuzzers guided by data-flow coverage have received relatively little attention, appearing mainly in combination with heavyweight program analyses (e.g., taint analysis, symbolic execution). Unfortunately, these more accurate analyses incur a high run-time penalty, impeding fuzzer throughput. Lightweight data-flow alternatives to control-flow fuzzing remain unexplored. We present DatAFLow, a greybox fuzzer guided by lightweight data-flow profiling. We also establish a framework for reasoning about data-flow coverage, allowing the computational cost of exploration to be balanced with precision. Using this framework, we extensively evaluate DatAFLow across different precisions, comparing it against state-of-the-art fuzzers guided by control flow, taint analysis, and data flow. Our results suggest that the ubiquity of control-flow-guided fuzzers is well-founded. The high run-time costs of data-flow-guided fuzzing (\sim{} 10 \texttimes{} higher than control-flow-guided fuzzing) significantly reduces fuzzer iteration rates, adversely affecting bug discovery and coverage expansion. Despite this, DatAFLow uncovered bugs that state-of-the-art control-flow-guided fuzzers (notably, AFL++) failed to find. This was because data-flow coverage revealed states in the target not visible under control-flow coverage. Thus, we encourage the community to continue exploring lightweight data-flow profiling; specifically, to lower run-time costs and to combine this profiling with control-flow coverage to maximize bug-finding potential.}
}
@inproceedings{Hiser2012,
  title         = {{ILR: Where'd my gadgets go?}},
  shorttitle    = {ILR},
  author        = {Hiser, Jason and Nguyen-Tuong, Anh and Co, Michele and Hall, Matthew and Davidson, Jack W.},
  year          = 2012,
  month         = may,
  booktitle     = {Proceedings - IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  pages         = {571--585},
  doi           = {10.1109/SP.2012.39},
  isbn          = 9780769546810,
  issn          = 10816011,
  abstract      = {Through randomization of the memory space and the confinement of code to non-data pages, computer security researchers have made a wide range of attacks against program binaries more difficult. However, attacks have evolved to exploit weaknesses in these defenses. To thwart these attacks, we introduce a novel technique called Instruction Location Randomization (ILR). Conceptually, ILR randomizes the location of every instruction in a program, thwarting an attacker's ability to re-use program functionality (e.g., arc-injection attacks and return-oriented programming attacks). ILR operates on arbitrary executable programs, requires no compiler support, and requires no user interaction. Thus, it can be automatically applied post-deployment, allowing easy and frequent re-randomization. Our preliminary prototype, working on 32-bit x86 Linux ELF binaries, provides a high degree of entropy. Individual instructions are randomly placed within a 31-bit address space. Thus, attacks that rely on a priori knowledge of the location of code or derandomization are not feasible. We demonstrated ILR's defensive capabilities by defeating attacks against programs with vulnerabilities, including Adobe's PDF viewer, acroread, which had an in-the-wild vulnerability. Additionally, using an industry-standard CPU performance benchmark suite, we compared the run time of prototype ILR-protected executables to that of native executables. The average run-time overhead of ILR was 13{\%} with more than half the programs having effectively no overhead (15 out of 29), indicating that ILR is a realistic and cost-effective mitigation technique.}
}
@book{holland1992adaptation,
  title         = {Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control and Artificial Intelligence},
  author        = {Holland, John H.},
  year          = 1992,
  publisher     = {MIT Press},
  address       = {Cambridge, MA, USA},
  isbn          = {0262082136}
}
@inproceedings{Homescu2013a,
  title         = {{Librando}},
  author        = {Homescu, Andrei and Brunthaler, Stefan and Larsen, Per and Franz, Michael},
  year          = 2013,
  booktitle     = {Proceedings of the 2013 ACM SIGSAC conference on Computer {\&} communications security - CCS '13},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {993--1004},
  doi           = {10.1145/2508859.2516675},
  isbn          = 9781450324779,
  issn          = 15437221,
  abstract      = {Just-in-time compilers (JITs) are here to stay. Unfortunately, they also provide new capabilities to cyber attackers, namely the ability to supply input programs (in languages such as JavaScript) that will then be compiled to executable code. Once this code is placed and marked as executable, it can then be leveraged by the attacker. Randomization techniques such as constant blinding raise the cost to the attacker, but they significantly add to the burden of implementing a JIT. There are a great many JITs in use today, but not even all of the most commonly used ones randomize their outputs. We present librando, the first comprehensive technique to harden JIT compilers in a completely generic manner by randomizing their output transparently ex post facto. We implement this approach as a system-wide service that can simultaneously harden multiple running JITs. It hooks into the memory protections of the target OS and randomizes newly generated code on the fly when marked as executable. In order to provide ``black box'' JIT hardening, librando needs to be extremely conservative. For example, it completely preserves the contents of the calling stack, presenting each JIT with the illusion that it is executing its own generated code. Yet in spite of the heavy lifting that librando performs behind the scenes, the performance impact is surprisingly low. For Java (HotSpot), we measured slow- downs by a factor of 1.15\texttimes{}, and for compute-intensive JavaScript (V8) benchmarks, a slowdown of 3.5\texttimes{}. For many applications, this overhead}
}
@inproceedings{Homescu2013e,
  title         = {{Profile-guided automated software diversity}},
  author        = {Homescu, Andrei and Neisius, Steven and Larsen, Per and Brunthaler, Stefan and Franz, Michael},
  year          = 2013,
  month         = feb,
  booktitle     = {Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  publisher     = {IEEE},
  pages         = {1--11},
  doi           = {10.1109/CGO.2013.6494997},
  isbn          = {978-1-4673-5525-4},
  abstract      = {Code-reuse attacks are notoriously hard to defeat, and most current solutions to the problem focus on automated software diversity. This is a promising area of research, as diversity attacks the common denominator enabling code-reuse attacksthe software monoculture. Recent research in this area provides security, but at an unfortunate price: performance overhead. Leveraging previously collected profiling information, compilers can substantially improve subsequent code generation. Traditionally, profile-guided optimization focuses on hot program code, where a program spends most of its execution time. Optimizing rarely executed code does not significantly impact performance, so few optimizations focus on this code. We use profile-guided optimization to reduce the performance overhead of software diversity. The primary insight is that we are free to diversify cold code, but restrict our diversification efforts in hot code. Our work investigates the impact of profiling on an expensive diversification technique: NOP insertion. By differentiating between hot cold and cold code, we optimize NOP insertion overheads from a maximum of 25{\%} down to a negligible 1{\%}, while preserving the security properties of the original defense. Consequently, using our profile-guided diversification technique, even randomization techniques having a high performance overhead become practical.}
}
@inproceedings{Hough2024,
  title         = {Crossover in {{Parametric Fuzzing}}},
  author        = {Hough, Katherine and Bell, Jonathan},
  year          = 2024,
  month         = apr,
  booktitle     = {Proceedings of the {{IEEE}}/{{ACM}} 46th {{International Conference}} on {{Software Engineering}}},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {{{ICSE}} '24},
  pages         = {1--12},
  doi           = {10.1145/3597503.3639160},
  isbn          = 9798400702174,
  abstract      = {Parametric fuzzing combines evolutionary and generator-based fuzzing to create structured test inputs that exercise unique execution behaviors. Parametric fuzzers internally represent inputs as bit strings referred to as "parameter sequences". Interesting parameter sequences are saved by the fuzzer and perturbed to create new inputs without the need for type-specific operators. However, existing work on parametric fuzzing only uses mutation operators, which modify a single input; it does not incorporate crossover, an evolutionary operator that blends multiple inputs together. Crossover operators aim to combine advantageous traits from multiple inputs. However, the nature of parametric fuzzing limits the effectiveness of traditional crossover operators. In this paper, we propose linked crossover, an approach for using dynamic execution information to identify and exchange analogous portions of parameter sequences. We created an implementation of linked crossover for Java and evaluated linked crossover's ability to preserve advantageous traits. We also evaluated linked crossover's impact on fuzzer performance on seven real-world Java projects and found that linked crossover consistently performed as well as or better than three state-of-the-art parametric fuzzers and two other forms of crossover on both long and short fuzzing campaigns.}
}
@inproceedings{hsu2018,
  title         = {{{INSTRIM}}: {{Lightweight Instrumentation}} for {{Coverage-guided Fuzzing}}},
  shorttitle    = {{INSTRIM}},
  author        = {Hsu, Chin-Chia and Wu, Che-Yu and Hsiao, Hsu-Chun and Huang, Shih-Kun},
  booktitle     = {Proceedings 2018 {{Workshop}} on {{Binary Analysis Research}}},
  location      = {San Diego, CA},
  publisher     = {Internet Society},
  doi           = {10.14722/bar.2018.23014},
  isbn          = {978-1-891562-50-1},
  date          = 2018,
  eventtitle    = {Workshop on {{Binary Analysis Research}}}
}
@inproceedings{Hu2016,
  title         = {{Data-Oriented Programming: On the Expressiveness of Non-control Data Attacks}},
  author        = {Hu, Hong and Shinde, Shweta and Adrian, Sendroiu and Chua, Zheng Leong and Saxena, Prateek and Liang, Zhenkai},
  year          = 2016,
  month         = may,
  booktitle     = {Proceedings - 2016 IEEE Symposium on Security and Privacy, SP 2016},
  publisher     = {IEEE},
  pages         = {969--986},
  doi           = {10.1109/SP.2016.62},
  isbn          = 9781509008247
}
@inproceedings{huang2022a,
  title         = {The {{Taming}} of the {{Stack}}: {{Isolating Stack Data}} from {{Memory Errors}}},
  shorttitle    = {The {{Taming}} of the {{Stack}}},
  author        = {Huang, Kaiming and Huang, Yongzhe and Payer, Mathias and Qian, Zhiyun and Sampson, Jack and Tan, Gang and Jaeger, Trent},
  booktitle     = {Proceedings 2022 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {San Diego, CA, USA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2022.23060},
  isbn          = {978-1-891562-74-7},
  date          = 2022,
  eventtitle    = {Network and {{Distributed System Security Symposium}}}
}
@online{IntelAVX,
  title         = {{Intel Advanced Vector Extensions}},
  author        = {Intel},
  year          = 2022,
  url           = {https://www.intel.com/content/dam/develop/external/us/en/documents/36945}
}
@online{IntelCET,
  title         = {{Intel CET}},
  author        = {Intel},
  year          = 2022,
  url           = {https://software.intel.com/content/www/us/en/develop/articles/technical-look-control-flow-enforcement-technology.html}
}
@inproceedings{Ispoglou2018,
  title         = {Block Oriented Programming: Automating Data-Only Attacks},
  author        = {Ispoglou, Kyriakos K. and AlBassam, Bader and Jaeger, Trent and Payer, Mathias},
  year          = 2018,
  booktitle     = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS)},
  pages         = {2107--2122}
}
@incollection{Jackson2011,
  title         = {{Compiler-Generated Software Diversity}},
  author        = {Jackson, Todd and Salamat, Babak and Homescu, Andrei and Manivannan, Karthikeyan and Wagner, Gregor and Gal, Andreas and Brunthaler, Stefan and Wimmer, Christian and Franz, Michael},
  year          = 2011,
  booktitle     = {Moving Target Defense: Creating Asymmetric Uncertainty for Cyber Threats},
  publisher     = {Springer, New York, NY},
  pages         = {77--98},
  doi           = {10.1007/978-1-4614-0977-9_4},
  abstract      = {Present approaches to software security are to a large extent reactive: when vulnerabilities are discovered, developers scramble to fix the underlying error. The advantage is on the side of the attackers because they only have to find a single vulnerability to exploit all vulnerable systems, while defenders have to prevent the exploitation of all vulnerabilities. We argue that the compiler is at the heart of the solution for this problem: when the compiler is translating high-level source code to low-level machine code, it is able to automatically diversify the machine code, thus creating multiple functionally equivalent, but internally different variants of a program.We present two orthogonal compiler-based techniques.With multi-variant execution, a monitoring layer executes several diversified variants in lockstep while examining their behavior for differences that indicate attacks. With massive-scale software diversity, every user gets its own diversified variant, so that the attacker has no knowledge about the internal structure of that variant and therefore cannot construct an attack. Both techniques make it harder for an attacker to run a successful attack.We discuss variation techniques that the compiler can utilize to diversify software, and evaluate their effectiveness for our two execution models.}
}
@online{jacoco,
  title         = {JaCoCo},
  url           = {https://www.jacoco.com/jacoco}
}
@inproceedings{jaloyan2020,
  title         = {Return-{{Oriented Programming}} on {{RISC-V}}},
  author        = {Jaloyan, Georges-Axel and Markantonakis, Konstantinos and Akram, Raja Naeem and Robin, David and Mayes, Keith and Naccache, David},
  booktitle     = {Proceedings of the 15th {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{ASIA CCS}} '20},
  pages         = {471--480},
  doi           = {10.1145/3320269.3384738},
  isbn          = {978-1-4503-6750-9},
  date          = {2020-10-05},
  abstract      = {This paper provides the first analysis on the feasibility of Return-Oriented programming (ROP) on RISC-V, a new instruction set architecture targeting embedded systems. We show the existence of a new class of gadgets, using several Linear Code Sequences And Jumps (LCSAJ), undetected by current Galileo-based ROP gadget searching tools. We argue that this class of gadgets is rich enough on RISC-V to mount complex ROP attacks, bypassing traditional mitigation like DEP, ASLR, stack canaries, G-Free and some compiler-based backward-edge CFI, by jumping over any guard inserted by a compiler to protect indirect jump instructions. We provide examples of such gadgets, as well as a proof-of-concept ROP chain, using C code injection to leverage a privilege escalation attack on two standard Linux operating systems. Additionally, we discuss some of the required mitigations to prevent such attacks and provide a new ROP gadget finder algorithm that handles this new class of gadgets.}
}
@article{jang2014,
  title         = {{{SAFEDISPATCH}} : {{Securing C}} ++ {{Virtual Calls}} from {{Memory Corruption Attacks}}},
  author        = {Jang, Dongseok and Tatlock, Zachary and Lerner, Sorin},
  pages         = {23--26},
  doi           = {10.1109/SP.2013.44},
  isbn          = 1891562355,
  date          = 2014,
  journaltitle  = {20th Annual Network and Distributed System Security Symposium},
  abstract      = {Several defenses have increased the cost of traditional, low-level attacks that corrupt control data, e.g. return addresses saved on the stack, to compromise program execution. In response, creative adversaries have begun circumventing these defenses by exploiting programming errors to manipulate pointers to virtual tables, or vtables, of C++ objects. These attacks can hijack program control flow whenever a virtual method of a corrupted object is called, potentially allowing the attacker to gain complete control of the underlying system. In this paper we present SAFEDISPATCH, a novel defense to prevent such vtable hijacking by statically analyzing C++ programs and inserting sufficient runtime checks to ensure that control flow at virtual method call sites cannot be arbitrarily influenced by an attacker. We implemented SAFEDISPATCH as a Clang++/LLVM extension, used our enhanced compiler to build a vtable-safe version of the Google Chromium browser, and measured the performance overhead of our approach on popular browser benchmark suites. By carefully crafting a handful of optimizations, we were able to reduce average runtime overhead to just 2.1\%.},
  issue         = {February}
}
@misc{JavaFuzzer,
  title         = {{Java\textasteriskcentered Fuzzer for Android\textasteriskcentered}},
  url           = {https://github.com/android-art-intel/Fuzzer},
  urldate       = {2024-06-13},
  copyright     = {Apache-2.0},
  abstract      = {Java\textasteriskcentered Fuzzer for Android\textasteriskcentered}
}
@online{jazzer,
  title         = {Jazzer},
  author        = {Code Intelligence},
  url           = {https://github.com/CodeIntelligenceTesting/jazzer},
  date          = {2024-07-30}
}
@inproceedings{Jia2023,
  title         = {Detecting {{JVM JIT Compiler Bugs}} via {{Exploring Two-Dimensional Input Spaces}}},
  author        = {Jia, Haoxiang and Wen, Ming and Xie, Zifan and Guo, Xiaochen and Wu, Rongxin and Sun, Maolin and Chen, Kang and Jin, Hai},
  year          = 2023,
  month         = jul,
  booktitle     = {Proceedings of the 45th {{International Conference}} on {{Software Engineering}}},
  publisher     = {IEEE Press},
  address       = {Melbourne, Victoria, Australia},
  series        = {{{ICSE}} '23},
  pages         = {43--55},
  doi           = {10.1109/ICSE48619.2023.00016},
  isbn          = {978-1-66545-701-9},
  abstract      = {Java Virtual Machine (JVM) is the fundamental software system that supports the interpretation and execution of Java bytecode. To support the surging performance demands for the increasingly complex and large-scale Java programs, JustIn-Time (JIT) compiler was proposed to perform sophisticated runtime optimization. However, this inevitably induces various bugs, which are becoming more pervasive over the decades and can often cause significant consequences. To facilitate the design of effective and efficient testing techniques to detect JIT compiler bugs. This study first performs a preliminary study aiming to understand the characteristics of JIT compiler bugs and the corresponding triggering test cases. Inspired by the empirical findings, we propose JOpFuzzer, a new JVM testing approach with a specific focus on JIT compiler bugs. The main novelty of JOpFuzzer is embodied in three aspects. First, besides generating new seeds, JOpFuzzer also searches for diverse configurations along the new dimension of optimization options. Second, JOpFuzzer learns the correlations between various code features and different optimization options to guide the process of seed mutation and option exploration. Third, it leverages the profile data, which can reveal the program execution information, to guide the fuzzing process. Such novelties enable JOpFuzzer to effectively and efficiently explore the two-dimensional input spaces. Extensive evaluation shows that JOpFuzzer outperforms the state-of-the-art approaches in terms of the achieved code coverages. More importantly, it has detected 41 bugs in OpenJDK, and 25 of them have already been confirmed or fixed by the corresponding developers.}
}
@inproceedings{Kc2003,
  title         = {Countering Code-Injection Attacks with Instruction-Set Randomization},
  author        = {Kc, Gaurav S. and Keromytis, Angelos D. and Prevelakis, Vassilis},
  booktitle     = {Proceedings of the 10th {{ACM}} Conference on {{Computer}} and Communications Security},
  publisher     = {ACM},
  pages         = {272--280},
  doi           = {10.1145/948143.948146},
  isbn          = {1-58113-738-9},
  issn          = 15437221,
  date          = 2003,
  abstract      = {We describe a new, general approach for safeguarding systems against any type of code-injection attack. We apply Kerckhoff's principle, by creating process-specific randomized instruction sets (e.g., machine instructions) of the system executing potentially vulnerable software. An attacker who does not know the key to the randomization algorithm will inject code that is invalid for that randomized processor, causing a runtime exception. To determine the difficulty of integrating support for the proposed mechanism in the operating system, we modified the Linux kernel, the GNU binutils tools, and the bochs-x86 emulator. Although the performance penalty is significant, our prototype demonstrates the feasibility of the approach, and should be directly usable on a suitable-modified processor (e.g., the Transmeta Crusoe). Our approach is equally applicable against code-injecting attacks in scripting and interpreted languages, e.g., web-based SQL injection. We demonstrate this by modifying the Perl interpreter to permit randomized script execution. The performance penalty in this case is minimal. Where our proposed approach is feasible (i.e., in an emulated environment, in the presence of programmable or specialized hardware, or in interpreted languages), it can serve as a low-overhead protection mechanism, and can easily complement other mechanisms. Copyright 2003 ACM.}
}
@online{kelinci,
  title         = {Kelinci},
  author        = {Kersten, Rody},
  url           = {https://github.com/isstac/kelinci},
  date          = {2024-07-30}
}
@inproceedings{khandaker2019,
  title         = {Origin-Sensitive {{Control Flow Integrity}}},
  author        = {Khandaker, Mustakimur Rahman and Liu, Wenqing and Naser, Abu and Wang, Zhi and Yang, Jie},
  pages         = {195--211},
  isbn          = {978-1-939133-06-9},
  date          = 2019,
  eventtitle    = {28th {{USENIX Security Symposium}} ({{USENIX Security}} 19)}
}
@inproceedings{Kil2006,
  title         = {Address {{Space Layout Permutation}} ({{ASLP}}): {{Towards Fine-Grained Randomization}} of {{Commodity Software}}},
  shorttitle    = {Address {{Space Layout Permutation}} ({{ASLP}})},
  author        = {Kil, Chongkyung and Jun, Jinsuk and Bookholt, Christopher and Xu, Jun and Ning, Peng},
  booktitle     = {2006 22nd {{Annual Computer Security Applications Conference}} ({{ACSAC}}'06)},
  location      = {Miami Beach, FL, USA},
  publisher     = {IEEE},
  pages         = {339--348},
  doi           = {10.1109/ACSAC.2006.9},
  isbn          = {978-0-7695-2716-1},
  issn          = {1063-9527},
  date          = {2006-12},
  eventtitle    = {2006 22nd {{Annual Computer Security Applications Conference}} ({{ACSAC}}'06)}
}
@article{Kim2014,
  title         = {Flipping bits in memory without accessing them},
  author        = {Kim, Yoongu and Daly, Ross and Kim, Jeremie and Fallin, Chris and Lee, Ji Hye and Lee, Donghyuk and Wilkerson, Chris and Lai, Konrad and Mutlu, Onur},
  year          = 2014,
  month         = oct,
  journal       = {ACM SIGARCH Computer Architecture News},
  volume        = 42,
  number        = 3,
  pages         = {361--372},
  doi           = {10.1145/2678373.2665726},
  isbn          = 9781479943944,
  issn          = {0163-5964}
}
@inproceedings{Kim2023,
  title         = {{{DAFL}}: {{Directed Grey-box Fuzzing}} Guided by {{Data Dependency}}},
  shorttitle    = {\{\vphantom\}{{DAFL}}\vphantom\{\}},
  author        = {Kim, Tae Eun and Choi, Jaeseung and Heo, Kihong and Cha, Sang Kil},
  year          = 2023,
  booktitle     = {32nd {{USENIX Security Symposium}} ({{USENIX Security}} 23)},
  pages         = {4931--4948},
  isbn          = {978-1-939133-37-3}
}
@inproceedings{klees2018,
  title         = {Evaluating {{Fuzz Testing}}},
  author        = {Klees, George and Ruef, Andrew and Cooper, Benji and Wei, Shiyi and Hicks, Michael},
  booktitle     = {Proceedings of the 2018 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '18},
  pages         = {2123--2138},
  doi           = {10.1145/3243734.3243804},
  isbn          = {978-1-4503-5693-0},
  date          = {2018-10-15},
  abstract      = {Fuzz testing has enjoyed great success at discovering security critical bugs in real software. Recently, researchers have devoted significant effort to devising new fuzzing techniques, strategies, and algorithms. Such new ideas are primarily evaluated experimentally so an important question is: What experimental setup is needed to produce trustworthy results? We surveyed the recent research literature and assessed the experimental evaluations carried out by 32 fuzzing papers. We found problems in every evaluation we considered. We then performed our own extensive experimental evaluation using an existing fuzzer. Our results showed that the general problems we found in existing experimental evaluations can indeed translate to actual wrong or misleading assessments. We conclude with some guidelines that we hope will help improve experimental evaluations of fuzz testing algorithms, making reported results more robust.}
}
@inproceedings{Kocher2019,
  title         = {{Spectre Attacks: Exploiting Speculative Execution}},
  author        = {Kocher, Paul and Horn, Jann and Fogh, Anders and Genkin, Daniel and Gruss, Daniel and Haas, Werner and Hamburg, Mike and Lipp, Moritz and Mangard, Stefan and Prescher, Thomas and Schwarz, Michael and Yarom, Yuval},
  year          = 2019,
  month         = may,
  booktitle     = {2019 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  volume        = {2019-May},
  pages         = {1--19},
  doi           = {10.1109/SP.2019.00002},
  isbn          = {978-1-5386-6660-9},
  issn          = 10816011,
  abstract      = {Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.}
}
@inproceedings{koning2017,
  title         = {No {{Need}} to {{Hide}}: {{Protecting Safe Regions}} on {{Commodity Hardware}}},
  shorttitle    = {No {{Need}} to {{Hide}}},
  author        = {Koning, Koen and Chen, Xi and Bos, Herbert and Giuffrida, Cristiano and Athanasopoulos, Elias},
  booktitle     = {Proceedings of the {{Twelfth European Conference}} on {{Computer Systems}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSys}} '17},
  pages         = {437--452},
  doi           = {10.1145/3064176.3064217},
  isbn          = {978-1-4503-4938-3},
  date          = {2017-04-23},
  abstract      = {As modern 64-bit x86 processors no longer support the segmentation capabilities of their 32-bit predecessors, most research projects assume that strong in-process memory isolation is no longer an affordable option. Instead of strong, deterministic isolation, new defense systems therefore rely on the probabilistic pseudo-isolation provided by randomization to "hide" sensitive (or safe) regions. However, recent attacks have shown that such protection is insufficient; attackers can leak these safe regions in a variety of ways. In this paper, we revisit isolation for x86-64 and argue that hardware features enabling efficient deterministic isolation do exist. We first present a comprehensive study on commodity hardware features that can be repurposed to isolate safe regions in the same address space (e.g., Intel MPX and MPK). We then introduce MemSentry, a framework to harden modern defense systems with commodity hardware features instead of information hiding. Our results show that some hardware features are more effective than others in hardening such defenses in each scenario and that features originally conceived for other purposes (e.g., Intel MPX for bounds checking) are surprisingly efficient at isolating safe regions compared to their software equivalent (i.e., SFI).}
}
@inproceedings{Koo2018,
  title         = {{Compiler-Assisted Code Randomization}},
  author        = {Koo, Hyungjoon and Chen, Yaohui and Lu, Long and Kemerlis, Vasileios P and Polychronakis, Michalis},
  year          = 2018,
  month         = may,
  booktitle     = {2018 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  volume        = {2018-May},
  pages         = {461--477},
  doi           = {10.1109/SP.2018.00029},
  isbn          = {978-1-5386-4353-2},
  issn          = 10816011,
  abstract      = {Despite decades of research on software diversification, only address space layout randomization has seen widespread adoption. Code randomization, an effective defense against return-oriented programming exploits, has remained an academic exercise mainly due to i) the lack of a transparent and streamlined deployment model that does not disrupt existing software distribution norms, and ii) the inherent incompatibility of program variants with error reporting, whitelisting, patching, and other operations that rely on code uniformity. In this work we present compiler-assisted code randomization (CCR), a hybrid approach that relies on compiler-rewriter cooperation to enable fast and robust fine-grained code randomization on end-user systems, while maintaining compatibility with existing software distribution models. The main concept behind CCR is to augment binaries with a minimal set of transformation-assisting metadata, which i) facilitate rapid fine-grained code transformation at installation or load time, and ii) form the basis for reversing any applied code transformation when needed, to maintain compatibility with existing mechanisms that rely on referencing the original code. We have implemented a prototype of this approach by extending the LLVM compiler toolchain, and developing a simple binary rewriter that leverages the embedded metadata to generate randomized variants using basic block reordering. The results of our experimental evaluation demonstrate the feasibility and practicality of CCR, as on average it incurs a modest file size increase of 11.46{\%} and a negligible runtime overhead of 0.28{\%}, while it is compatible with link-time optimization and control flow integrity.}
}
@inproceedings{Kooa,
  title         = {Juggling the Gadgets: {{Binary-level}} Code Randomization Using Instruction Displacement},
  author        = {Koo, Hyungjoon and Polychronakis, Michalis},
  booktitle     = {{{ASIA CCS}} 2016 - {{Proceedings}} of the 11th {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  pages         = {23--34},
  doi           = {10.1145/2897845.2897863},
  isbn          = {978-1-4503-4233-9},
  date          = 2016,
  abstract      = {Code diversification is an effective mitigation against return-oriented programming attacks, which breaks the assumptions of attackers about the location and structure of useful instruction sequences, known as "gadgets." Although a wide range of code diversification techniques of varying levels of granularity exist, most of them rely on the availability of source code, debug symbols, or the assumption of fully precise code disassembly, limiting their practical applicability for the protection of closed-source third-party applications. In-place code randomization has been proposed as an alternative binary-compatible diversification technique that is tolerant of partial disassembly coverage, in the expense though of leaving some gadgets intact, at the disposal of attackers. Consequently, the possibility of constructing robust ROP payloads using only the remaining non-randomized gadgets is still open. In this paper we present instruction displacement, a code diversification technique based on static binary instrumentation that does not rely on complete code disassembly coverage. Instruction displacement aims to improve the randomization coverage and entropy of existing binary-level code diversification techniques by displacing any remaining non-randomized gadgets to random locations. The results of our experimental evaluation demonstrate that instruction displacement reduces the number of non-randomized gadgets in the extracted code regions from 15.04\% for standalone in-place code randomization, to 2.77\% for the combination of both techniques. At the same time, the additional indirection introduced due to displacement incurs a negligible runtime overhead of 0.36\% on average for the SPEC CPU2006 benchmarks.}
}
@article{krahmer2005,
  title         = {x86-64 buffer overflow exploits and the borrowed code chunks exploitation technique},
  author        = {Krahmer, Sebastian},
  year          = 2005
}
@inproceedings{kroes2017,
  title         = {Fast and {{Generic Metadata Management}} with {{Mid-Fat Pointers}}},
  author        = {Kroes, Taddeus and Koning, Koen and Giuffrida, Cristiano and Bos, Herbert and Van Der Kouwe, Erik},
  booktitle     = {Proceedings of the 10th {{European Workshop}} on {{Systems Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSec}}'17},
  pages         = {1--6},
  doi           = {10.1145/3065913.3065920},
  isbn          = {978-1-4503-4935-2},
  date          = {2017-04-23},
  abstract      = {Object metadata management schemes are a fundamental building block in many modern defenses and significantly affect the overall run-time overhead of a software hardening solution. To support fast metadata lookup, many metadata management schemes embed metadata tags directly inside pointers. However, existing schemes using such tagged pointers either provide poor compatibility or restrict the generality of the solution.In this paper, we propose mid-fat pointers to implement fast and generic metadata management while retaining most of the compatibility benefits of existing schemes. The key idea is to use spare bits in a regular 64-bit pointer to encode arbitrary metadata and piggyback on software fault isolation (SFI) already employed by many modern defenses to efficiently decode regular pointers at memory access time. Our experimental results demonstrate that we cut overhead in half compared to a defense running on top of SFI, more than compensating for SFI overhead. Moreover, we demonstrate good compatibility, which may be further improved by static analysis.}
}
@inproceedings{Kroes2018,
  title         = {Delta {{Pointers}}: {{Buffer Overflow Checks Without}} the {{Checks}}},
  author        = {Kroes, Taddeus and Koning, Koen and Van Der Kouwe, Erik and Bos, Herbert and Giuffrida, Cristiano},
  booktitle     = {Proceedings of the 13th {{EuroSys Conference}}, {{EuroSys}} 2018},
  volume        = {2018-January},
  doi           = {10.1145/3190508.3190553},
  isbn          = {978-1-4503-5584-1},
  date          = 2018,
  abstract      = {Despite decades of research, buffer overflows still rank among the most dangerous vulnerabilities in unsafe languages such as C and C++. Compared to other memory corruption vulnerabilities, buffer overflows are both common and typically easy to exploit. Yet, they have proven so challenging to detect in real-world programs that existing solutions either yield very poor performance, or introduce incompatibilities with the C/C++ language standard. We present Delta Pointers, a new solution for buffer overflow detection based on efficient pointer tagging. By carefully altering the pointer representation, without violating language specifications, Delta Pointers use existing hardware features to detect both contiguous and non-contiguous overflows on dereferences, without a single check incurring extra branch or memory access operations. By focusing on buffer overflows rather than other vulnerabilities (e.g., underflows), Delta Pointers offer a unique checkless design to provide high performance while still maintaining compatibility. We show that Delta Pointers are effective in detecting arbitrary buffer overflows and, at 35\% overhead on SPEC, offer much better performance than competing solutions.}
}
@inproceedings{Kuznetsov2014,
  title         = {{Code-Pointer Integrity}},
  author        = {Kuznetsov, Volodymyr and Szekeres, L{\'a}szl{\'o} and Payer, Mathias and Candea, George and Sekar, R. and Song, Dawn},
  year          = 2014,
  booktitle     = {Proceedings of the 11th {USENIX} Symposium on Operating Systems Design and Implementation},
  volume        = 14,
  pages         = {147--163},
  isbn          = 9781931971164,
  abstract      = {Systems code is often written in low-level languages like C/C++, which offer many benefits but also dele- gate memory management to programmers. This invites memory safety bugs that attackers can exploit to divert control flow and compromise the system. Deployed de- fense mechanisms (e.g., ASLR, DEP) are incomplete, and stronger defense mechanisms (e.g., CFI) often have high overhead and limited guarantees [19, 15, 9]. We introduce code-pointer integrity (CPI), a new de- sign point that guarantees the integrity of all code point- ers in a program (e.g., function pointers, saved return ad- dresses) and thereby prevents all control-flow hijack at- tacks, including return-oriented programming. We also introduce code-pointer separation (CPS), a relaxation of CPI with better performance properties. CPI and CPS offer substantially better security-to-overhead ratios than the state of the art, they are practical (we protect a complete FreeBSD system and over 100 packages like apache and postgresql), effective (prevent all attacks in the RIPE benchmark), and efficient: on SPEC CPU2006, CPS averages 1.2{\%} overhead for C and 1.9{\%} for C/C++, while CPI's overhead is 2.9{\%} for C and 8.4{\%} for C/C++. A prototype implementation of CPI and CPS can be obtained from http://levee.epfl.ch. 1},
  mendeley-tags = {c++ semantics,vulnerable by COOP}
}
@inproceedings{kwon2013,
  title         = {Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-Based Security},
  shorttitle    = {Low-Fat Pointers},
  author        = {Kwon, Albert and Dhawan, Udit and Smith, Jonathan M. and Knight, Thomas F. and DeHon, Andre},
  booktitle     = {Proceedings of the 2013 {{ACM SIGSAC}} Conference on {{Computer}} \& Communications Security},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '13},
  pages         = {721--732},
  doi           = {10.1145/2508859.2516713},
  isbn          = {978-1-4503-2477-9},
  date          = {2013-11-04},
  abstract      = {Referencing outside the bounds of an array or buffer is a common source of bugs and security vulnerabilities in today's software. We can enforce spatial safety and eliminate these violations by inseparably associating bounds with every pointer (fat pointer) and checking these bounds on every memory access. By further adding hardware-managed tags to the pointer, we make them unforgeable. This, in turn, allows the pointers to be used as capabilities to facilitate fine-grained access control and fast security domain crossing. Dedicated checking hardware runs in parallel with the processor's normal datapath so that the checks do not slow down processor operation (0\% runtime overhead). To achieve the safety of fat pointers without increasing program state, we compactly encode approximate base and bound pointers along with exact address pointers for a 46b address space into one 64-bit word with a worst-case memory overhead of 3\%. We develop gate-level implementations of the logic for updating and validating these compact fat pointers and show that the hardware requirements are low and the critical paths for common operations are smaller than processor ALU operations. Specifically, we show that the fat-pointer check and update operations can run in a 4 ns clock cycle on a Virtex 6 (40nm) implementation while only using 1100 6-LUTs or about the area of a double-precision, floating-point adder.}
}
@inproceedings{kwon2024,
  title         = {Translation {{Validation}} for {{JIT Compiler}} in the {{V8 JavaScript Engine}}},
  author        = {Kwon, Seungwan and Kwon, Jaeseong and Kang, Wooseok and Lee, Juneyoung and Heo, Kihong},
  booktitle     = {Proceedings of the {{IEEE}}/{{ACM}} 46th {{International Conference}} on {{Software Engineering}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{ICSE}} '24},
  pages         = {1--12},
  doi           = {10.1145/3597503.3639189},
  isbn          = {979-8-4007-0217-4},
  date          = {2024-04-12},
  abstract      = {We present TurboTV, a translation validator for the JavaScript (JS) just-in-time (JIT) compiler of V8. While JS engines have become a crucial part of various software systems, their emerging adaption of JIT compilation makes it increasingly challenging to ensure their correctness. We tackle this problem with an SMT-based translation validation (TV) that checks whether a specific compilation is semantically correct. We formally define the semantics of IR of TurboFan (JIT compiler of V8) as SMT encoding. For efficient validation, we design a staged strategy for JS JIT compilers. This allows us to decompose the whole correctness checking into simpler ones. Furthermore, we utilize fuzzing to achieve practical TV. We generate a large number of JS functions using a fuzzer to trigger various optimization passes of TurboFan and validate their compilation using TurboTV. Lastly, we demonstrate that TurboTV can also be used for cross-language TV. We show that TurboTV can validate the translation chain from LLVM IR to TurboFan IR, collaborating with an off-the-shelf TV tool for LLVM. We evaluated TurboTV on various sets of JS and LLVM programs. TurboTV effectively validated a large number of compilations of TurboFan with a low false positive rate and discovered a new miscompilation in LLVM.}
}
@inproceedings{Larsen2014,
  title         = {{SoK: Automated Software Diversity}},
  author        = {Larsen, Per and Homescu, Andrei and Brunthaler, Stefan and Franz, Michael},
  year          = 2014,
  month         = may,
  booktitle     = {2014 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  pages         = {276--291},
  doi           = {10.1109/SP.2014.25},
  isbn          = {978-1-4799-4686-0},
  issn          = 10816011,
  abstract      = {The idea of automatic software diversity is at least two decades old. The deficiencies of currently deployed defenses and the transition to online software distribution (the "App store" model) for traditional and mobile computers has revived the interest in automatic software diversity. Consequently, the literature on diversity grew by more than two dozen papers since 2008. Diversity offers several unique properties. Unlike other defenses, it introduces uncertainty in the target. Precise knowledge of the target software provides the underpinning for a wide range of attacks. This makes diversity a broad rather than narrowly focused defense mechanism. Second, diversity offers probabilistic protection similar to cryptography-attacks may succeed by chance so implementations must offer high entropy. Finally, the design space of diversifying program transformations is large. As a result, researchers have proposed multiple approaches to software diversity that vary with respect to threat models, security, performance, and practicality. In this paper, we systematically study the state-of-the-art in software diversity and highlight fundamental trade-offs between fully automated approaches. We also point to open areas and unresolved challenges. These include "hybrid solutions", error reporting, patching, and implementation disclosure attacks on diversified software.}
}
@book{Larsen2018,
  title         = {{The Continuing Arms Race: Code-Reuse Attacks and Defenses}},
  year          = 2018,
  month         = mar,
  publisher     = {ACM},
  doi           = {10.1145/3129743},
  isbn          = 9781970001839,
  editor        = {Larsen, Per and Sadeghi, Ahmad-Reza}
}
@inproceedings{Lattner2004,
  title         = {{LLVM: A compilation framework for lifelong program analysis \& transformation}},
  author        = {Lattner, Chris and Adve, Vikram},
  year          = 2004,
  booktitle     = {International Symposium on Code Generation and Optimization, 2004. CGO 2004.},
  publisher     = {IEEE},
  pages         = {75--86},
  doi           = {10.1109/CGO.2004.1281665},
  isbn          = {0-7695-2102-9},
  abstract      = {This paper describes LLVM (Low Level Virtual Machine), a compiler framework designed to support transparent, life-long program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.}
}
@inproceedings{lee2015,
  title         = {Preventing {{Use-after-free}} with {{Dangling Pointers Nullification}}},
  author        = {Lee, Byoungyoung and Song, Chengyu and Jang, Yeongjin and Wang, Tielei and Kim, Taesoo and Lu, Long and Lee, Wenke},
  booktitle     = {Proceedings 2015 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {San Diego, CA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2015.23238},
  isbn          = {978-1-891562-38-9},
  date          = 2015,
  eventtitle    = {Network and {{Distributed System Security Symposium}}}
}
@inproceedings{li2020,
  title         = {Finding {{Cracks}} in {{Shields}}: {{On}} the {{Security}} of {{Control Flow Integrity Mechanisms}}},
  shorttitle    = {Finding {{Cracks}} in {{Shields}}},
  author        = {Li, Yuan and Wang, Mingzhe and Zhang, Chao and Chen, Xingman and Yang, Songtao and Liu, Ying},
  booktitle     = {Proceedings of the 2020 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '20},
  pages         = {1821--1835},
  doi           = {10.1145/3372297.3417867},
  isbn          = {978-1-4503-7089-9},
  date          = {2020-11-02},
  abstract      = {Control-flow integrity (CFI) is a promising technique to mitigate control-flow hijacking attacks. In the past decade, dozens of CFI mechanisms have been proposed by researchers. Despite the claims made by themselves, the security promises of these mechanisms have not been carefully evaluated, and thus are questionable.In this paper, we present a solution to measure the gap between the practical security and the claimed theoretical security. First, we propose CScan to precisely measure runtime feasible targets of indirect control transfer (ICT) instructions protected by CFI, by enumerating all potential code addresses and testing whether ICTs are allowed to jump to them. Second, we propose CBench as a sanity check for verifying CFI solutions? effectiveness against typical attacks, by exploiting a comprehensive set of vulnerable programs protected by CFI and verifying the recognized feasible targets.We evaluated 12 most recent open-source CFI mechanisms and discovered 10 flaws in most CFI mechanisms or implementations. For some CFIs, their security policies or protected ICT sets do not match what they claimed. Some CFIs even expand the attack surface (e.g. introducing unintended targets). To facilitate a deeper understanding of CFI, we summarize the flaws into 7 common pitfalls which cover the whole lifetime of CFI mechanisms and reveal issues that affect CFI mechanisms in practical security.}
}
@inproceedings{li2022,
  title         = {{{PACMem}}: {{Enforcing Spatial}} and {{Temporal Memory Safety}} via {{ARM Pointer Authentication}}},
  shorttitle    = {{PACMem}},
  author        = {Li, Yuan and Tan, Wende and Lv, Zhizheng and Yang, Songtao and Payer, Mathias and Liu, Ying and Zhang, Chao},
  booktitle     = {Proceedings of the 2022 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '22},
  pages         = {1901--1915},
  doi           = {10.1145/3548606.3560598},
  isbn          = {978-1-4503-9450-5},
  date          = {2022-11-07},
  abstract      = {Memory safety is a key security property that stops memory corruption vulnerabilities. Different types of memory safety enforcement solutions have been proposed and adopted by sanitizers or mitigations to catch and stop such bugs, at the development or deployment phase. However, existing solutions either provide partial memory safety or have overwhelmingly high performance overheads. In this paper, we present a novel sanitizer PACMem to efficiently catch spatial and temporal memory safety bugs. PACMem removes the majority of the overheads by sealing metadata in pointers through the COTS hardware feature -- ARM PA (Pointer Authentication) and saving the overhead of pointer metadata tracking. We have developed a prototype of PACMem and systematically evaluated its security and performance on the Magma, Juliet, Nginx, and SPEC CPU2017 test suites. In our evaluation, PACMem shows no false positives together with negligible false negatives, while introducing stronger bug detection capabilities and lower performance overheads than state-of-the-art sanitizers, including HWASan, ASan, SoftBound+CETS, Memcheck, LowFat, and PTAuth. Compared to the widely deployed ASan, PACMem has no false positives and much fewer false negatives and reduces the runtime overheads by 15.80\% and the memory overheads by 71.58\%.}
}
@inproceedings{Li2023a,
  title         = {Validating {{JIT Compilers}} via {{Compilation Space Exploration}}},
  author        = {Li, Cong and Jiang, Yanyan and Xu, Chang and Su, Zhendong},
  year          = 2023,
  month         = oct,
  booktitle     = {Proceedings of the 29th {{Symposium}} on {{Operating Systems Principles}}},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {{{SOSP}} '23},
  pages         = {66--79},
  doi           = {10.1145/3600006.3613140},
  isbn          = 9798400702297,
  abstract      = {This paper introduces the novel concept of compilation space, which facilitates the thorough validation of just-in-time (JIT) compilers in modern language virtual machines (LVMs). The compilation space, even for a single program, consists of an extensive array of JIT compilation choices, which can be cross-validated for the correctness of JIT compilation. To thoroughly explore the compilation space in a lightweight and LVM-agnostic manner, we strategically mutate test programs with JIT-relevant, yet semantics-preserving code structures to trigger diverse JIT compilation choices. We realize our technique in Artemis, a tool for the Java virtual machine (JVM). Our evaluation has led to 85 bug reports for three widely used production JVMs, namely HotSpot, OpenJ9, and the Android Runtime. Among them, 53 have already been confirmed or fixed with many being critical. It is also worth mentioning that all the reported bugs concern JIT compilers, demonstrating the clear effectiveness and strong practicability of our technique. We expect that the generality and practicability of our approach will make it broadly applicable for understanding and validating JIT compilers.}
}
@inproceedings{Lin2009a,
  title         = {Polymorphing software by randomizing data structure layout},
  author        = {Lin, Zhiqiang and Riley, Ryan D. and Xu, Dongyan},
  year          = 2009,
  booktitle     = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
  publisher     = {Springer},
  volume        = {5587 LNCS},
  pages         = {107--126},
  doi           = {10.1007/978-3-642-02918-9_7},
  isbn          = {3-642-02917-5},
  note          = {ISSN: 03029743},
  abstract      = {This paper introduces a new software polymorphism technique that randomizes program data structure layout. This technique will generate different data structure layouts for a program and thus diversify the binary code compiled from the same program source code. This technique can mitigate attacks (e.g., kernel rootkit attacks) that require knowledge about data structure definitions. It is also able to disrupt the generation of data structure-based program signatures. We have implemented our data structure layout randomization technique in the open source compiler collection gcc-4.2.4 and applied it to a number of programs. Our evaluation results show that our technique is able to achieve software binary diversity. We also apply the technique to one operating system data structure in order to foil a number of kernel rootkit attacks. Meanwhile, programs produced by the technique were analyzed by a state-of-the-art data structure inference system and it was demonstrated that reliance on data structure signatures alone may lead to false negatives in malware detection.}
}
@inproceedings{Lipp2018,
  title         = {{Meltdown: Reading Kernel Memory from User Space}},
  author        = {Lipp, Moritz and Schwarz, Michael and Gruss, Daniel and Prescher, Thomas and Haas, Werner and Fogh, Anders and Horn, Jann and Mangard, Stefan and Kocher, Paul and Genkin, Daniel and Yarom, Yuval and Hamburg, Mike},
  year          = 2018,
  month         = aug,
  booktitle     = {27th {USENIX} Security Symposium ({USENIX} Security 18)},
  publisher     = {{USENIX} Association},
  address       = {Baltimore, MD},
  pages         = {973--990},
  isbn          = {978-1-939133-04-5}
}
@article{Livinskii2020,
  title         = {Random Testing for {{C}} and {{C}}++ Compilers with {{YARPGen}}},
  author        = {Livinskii, Vsevolod and Babokin, Dmitry and Regehr, John},
  year          = 2020,
  month         = nov,
  journal       = {Proceedings of the ACM on Programming Languages},
  volume        = 4,
  number        = {OOPSLA},
  pages         = {1--25},
  doi           = {10.1145/3428264},
  issn          = {2475-1421},
  abstract      = {Compilers should not crash and they should not miscompile applications. Random testing is an effective method for finding compiler bugs that have escaped other kinds of testing. This paper presents Yet Another Random Program Generator (YARPGen), a random test-case generator for C and C++ that we used to find and report more than 220 bugs in GCC, LLVM, and the Intel{\textregistered} C++ Compiler. Our research contributions include a method for generating expressive programs that avoid undefined behavior without using dynamic checks, and generation policies, a mechanism for increasing diversity of generated code and for triggering more optimizations. Generation policies decrease the testing time to find hard-to-trigger compiler bugs and, for the kinds of scalar optimizations YARPGen was designed to stress-test, increase the number of times these optimizations are applied by the compiler by an average of 20\% for LLVM and 40\% for GCC. We also created tools for automating most of the common tasks related to compiler fuzzing; these tools are also useful for fuzzers other than ours.}
}
@misc{log4shell,
  title         = {{CVE}-2021-44228: {Apache} {Log4j2} Remote Code Execution Vulnerability ({Log4Shell})},
  author        = {{MITRE Corporation}},
  year          = 2021,
  note          = {Accessed: 2025-01-24},
  howpublished  = {\url{https://nvd.nist.gov/vuln/detail/CVE-2021-44228}}
}
@inproceedings{Lu2015,
  title         = {{ASLR-Guard}},
  author        = {Lu, Kangjie and Song, Chengyu and Lee, Byoungyoung and Chung, Simon P. and Kim, Taesoo and Lee, Wenke},
  year          = 2015,
  booktitle     = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  volume        = {2015-Octob},
  pages         = {280--291},
  doi           = {10.1145/2810103.2813694},
  isbn          = 9781450338325,
  issn          = 15437221,
  abstract      = {A general prerequisite for a code reuse attack is that the attacker needs to locate code gadgets that perform the desired operations and then direct the control flow of a vulnerable application to those gadgets. Address Space Layout Randomization (ASLR) attempts to stop code reuse attacks by making the first part of the prerequisite unsatisfiable. However, research in recent years has shown that this protection is often defeated by commonly existing information leaks, which provides attackers clues about the whereabouts of cer-tain code gadgets. In this paper, we present ASLR-GUARD, a novel mechanism that completely prevents the leaks of code pointers, and render other information leaks (e.g., the ones of data pointers) use-less in deriving code address. The main idea behind ASLR-GUARD is to render leak of data pointer useless in deriving code address by separating code and data, provide a secure storage for code point-ers, and encode the code pointers when they are treated as data. ASLR-GUARD can either prevent code pointer leaks or render their leaks harmless. That is, ASLR-GUARD makes it impossible to over-write code pointers with values that point to or will hijack the control flow to a desired address when the code pointers are dereferenced. We have implemented a prototype of ASLR-GUARD, including a compilation toolchain and a C/C++ runtime. Our evaluation results show that (1) ASLR-GUARD supports normal operations correctly; (2) it completely stops code address leaks and can resist against re-cent sophisticated attacks; (3) it imposes almost no runtime overhead ({\textless} 1{\%}) for C/C++ programs in the SPEC benchmark. Therefore, ASLR-GUARD is very practical and can be applied to secure many applications.}
}
@inproceedings{lu2019,
  title         = {Where {{Does It Go}}? {{Refining Indirect-Call Targets}} with {{Multi-Layer Type Analysis}}},
  shorttitle    = {Where {{Does It Go}}?},
  author        = {Lu, Kangjie and Hu, Hong},
  booktitle     = {Proceedings of the 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CCS}} '19},
  pages         = {1867--1881},
  doi           = {10.1145/3319535.3354244},
  isbn          = {978-1-4503-6747-9},
  date          = {2019-11-06},
  abstract      = {System software commonly uses indirect calls to realize dynamic program behaviors. However, indirect-calls also bring challenges to constructing a precise control-flow graph that is a standard pre-requisite for many static program-analysis and system-hardening techniques. Unfortunately, identifying indirect-call targets is a hard problem. In particular, modern compilers do not recognize indirect-call targets by default. Existing approaches identify indirect-call targets based on type analysis that matches the types of function pointers and the ones of address-taken functions. Such approaches, however, suffer from a high false-positive rate as many irrelevant functions may share the same types. In this paper, we propose a new approach, namely Multi-Layer Type Analysis (MLTA), to effectively refine indirect-call targets for C/C++ programs. MLTA relies on an observation that function pointers are commonly stored into objects whose types have a multi-layer type hierarchy; before indirect calls, function pointers will be loaded from objects with the same type hierarchy "layer by layer". By matching the multi-layer types of function pointers and functions, MLTA can dramatically refine indirect-call targets. MLTA is effective because multi-layer types are more restrictive than single-layer types. It does not introduce false negatives by conservatively tracking targets propagation between multi-layer types, and the layered design allows MLTA to safely fall back whenever the analysis for a layer becomes infeasible. We have implemented MLTA in a system, namely TypeDive, based on LLVM and extensively evaluated it with the Linux kernel, the FreeBSD kernel, and the Firefox browser. Evaluation results show that TypeDive can eliminate 86\% to 98\% more indirect-call targets than existing approaches do, without introducing new false negatives. We also demonstrate that TypeDive not only improves the scalability of static analysis but also benefits semantic-bug detection. With TypeDive, we have found 35 new deep semantic bugs in the Linux kernel.}
}
@article{Luk2005,
  title         = {{Pin}},
  author        = {Luk, Chi-Keung and Cohn, Robert and Muth, Robert and Patil, Harish and Klauser, Artur and Lowney, Geoff and Wallace, Steven and Reddi, Vijay Janapa and Hazelwood, Kim},
  year          = 2005,
  month         = jun,
  journal       = {ACM SIGPLAN Notices},
  volume        = 40,
  number        = 6,
  pages         = {190--200},
  doi           = {10.1145/1064978.1065034},
  issn          = {0362-1340},
  abstract      = {Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation , and bug detection. To meet this need, we have developed a new instrumentation system called Pin. Our goals are to provide easy-to-use, portable, transparent, and efficient instrumenta-tion. Instrumentation tools (called Pintools) are written in C/C++ using Pin's rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be architecture independent whenever possible, making Pintools source compatible across different archi-tectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly transparent as the application and Pintool observe the application's original, unin-strumented behavior. Pin uses dynamic compilation to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register reallocation , liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instru-mentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin's versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium R V , and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 down-loads from its website.}
}
@inproceedings{luo2025,
  title         = {Retrofitting {{XoM}} for {{Stripped Binaries}} without {{Embedded Data Relocation}}},
  author        = {Luo, Chenke and Ming, Jiang and Xie, Mengfei and Peng, Guojun and Fu, Jianming},
  booktitle     = {Proceedings 2025 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {San Diego, CA, USA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2025.240825},
  isbn          = {979-8-9894372-8-3},
  date          = 2025,
  eventtitle    = {Network and {{Distributed System Security Symposium}}}
}
@misc{Ma2023,
  title         = {A {{Survey}} of {{Modern Compiler Fuzzing}}},
  author        = {Ma, Haoyang},
  year          = 2023,
  month         = jun,
  publisher     = {arXiv},
  number        = {arXiv:2306.06884},
  doi           = {10.48550/arXiv.2306.06884},
  url           = {http://arxiv.org/abs/2306.06884},
  urldate       = {2024-06-12},
  eprint        = {2306.06884},
  primaryclass  = {cs},
  abstract      = {Most software that runs on computers undergoes processing by compilers. Since compilers constitute the fundamental infrastructure of software development, their correctness is paramount. Over the years, researchers have invested in analyzing, understanding, and characterizing the bug features over mainstream compilers. These studies have demonstrated that compilers correctness requires greater research attention, and they also pave the way for compiler fuzzing. To improve compilers correctness, researchers have proposed numerous compiler fuzzing techniques. These techniques were initially developed for testing traditional compilers such as GCC/LLVM and have since been generalized to test various newly developed, domain-specific compilers, such as graphics shader compilers and deep learning (DL) compilers. In this survey, we provide a comprehensive summary of the research efforts for understanding and addressing compilers defects. Specifically, this survey mainly covers two aspects. First, it covers researchers investigation and expertise on compilers bugs, such as their symptoms and root causes. The compiler bug studies cover GCC/LLVM, JVM compilers, and DL compilers. In addition, it covers researchers efforts in designing fuzzing techniques, including constructing test programs and designing test oracles. Besides discussing the existing work, this survey outlines several open challenges and highlights research opportunities.},
  archiveprefix = {arxiv}
}
@inproceedings{Maisuradze2018,
  title         = {ret2spec},
  author        = {Maisuradze, Giorgi and Rossow, Christian},
  year          = 2018,
  month         = oct,
  booktitle     = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
  publisher     = {ACM},
  address       = {New York, NY, USA},
  pages         = {2109--2122},
  doi           = {10.1145/3243734.3243761},
  isbn          = 9781450356930,
  issn          = 15437221,
  abstract      = {Speculative execution is an optimization technique that has been part of CPUs for over a decade. It predicts the outcome and target of branch instructions to avoid stalling the execution pipeline. However, until recently, the security implications of speculative code execution have not been studied. In this paper, we investigate a special type of branch predictor that is responsible for predicting return addresses. To the best of our knowledge, we are the first to study return address predictors and their consequences for the security of modern software. In our work, we show how return stack buffers (RSBs), the core unit of return address predictors, can be used to trigger misspeculations. Based on this knowledge, we propose two new attack variants using RSBs that give attackers similar capabilities as the documented Spectre attacks. We show how local attackers can gain arbitrary speculative code execution across processes, e.g., to leak passwords another user enters on a shared system. Our evaluation showed that the recent Spectre countermeasures deployed in operating systems can also cover such RSB-based cross-process attacks. Yet we then demonstrate that attackers can trigger misspeculation in JIT environments in order to leak arbitrary memory content of browser processes. Reading outside the sandboxed memory region with JIT-compiled code is still possible with 80\% accuracy on average.},
  archiveprefix = {arXiv},
  arxivid       = {1807.10364},
  eprint        = {1807.10364}
}
@article{Manes2021,
  title         = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}: {{A Survey}}},
  shorttitle    = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}},
  author        = {Manes, Valentin J.M. and Han, HyungSeok and Han, Choongwoo and Cha, Sang Kil and Egele, Manuel and Schwartz, Edward J. and Woo, Maverick},
  year          = 2021,
  month         = nov,
  journal       = {IEEE Transactions on Software Engineering},
  volume        = 47,
  number        = 11,
  pages         = {2312--2331},
  doi           = {10.1109/TSE.2019.2946563},
  issn          = {0098-5589, 1939-3520, 2326-3881}
}
@inproceedings{Mantovani2022,
  title         = {Fuzzing with {{Data Dependency Information}}},
  author        = {Mantovani, Alessandro and Fioraldi, Andrea and Balzarotti, Davide},
  year          = 2022,
  month         = jun,
  booktitle     = {2022 {{IEEE}} 7th {{European Symposium}} on {{Security}} and {{Privacy}} ({{EuroS}}\&{{P}})},
  pages         = {286--302},
  doi           = {10.1109/EuroSP53844.2022.00026},
  abstract      = {Recent advances in fuzz testing have introduced several forms of feedback mechanisms, motivated by the fact that for a large range of programs and libraries, edgecoverage alone is insufficient to reveal complicated bugs. Inspired by this line of research, we examined existing program representations looking for a match between expressiveness of the structure and adaptability to the context of fuzz testing. In particular, we believe that data dependency graphs (DDGs) represent a good candidate for this task, as the set of information embedded by this data structure is potentially useful to find vulnerable constructs by stressing combinations of def-use pairs that would be difficult for a traditional fuzzer to trigger. Since some portions of the dependency graph overlap with the control flow of the program, it is possible to reduce the additional instrumentation to cover only ``interesting'' data-flow dependencies, those that help the fuzzer to visit the code in a distinct way compared to standard methodologies. To test these observations, in this paper we propose DDFuzz, a new approach that rewards the fuzzer not only with code coverage information, but also when new edges in the data dependency graph are hit. Our results show that the adoption of data dependency instrumentation in coverage-guided fuzzing is a promising solution that can help to discover bugs that would otherwise remain unexplored by standard coverage approaches. This is demonstrated by the 72 different vulnerabilities that our data-dependency driven approach can identify when executed on 38 target programs from three different datasets.}
}
@inproceedings{Mashtizadeh2015,
  title         = {{CCFI}},
  author        = {Mashtizadeh, Ali Jose and Bittau, Andrea and Boneh, Dan and Mazi{\`{e}}res, David},
  year          = 2015,
  booktitle     = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  volume        = {2015-Octob},
  pages         = {941--951},
  doi           = {10.1145/2810103.2813676},
  isbn          = 9781450338325,
  issn          = 15437221,
  abstract      = {Recent Pwn2Own competitions have demonstrated the continued effectiveness of control hijacking attacks despite deployed countermeasures including stack canaries and ASLR. A powerful defense called Control flow Integrity (CFI) offers a principled approach to preventing such attacks. However, prior CFI implementations use static analysis and must limit protection to remain practical. These limitations have enabled attacks against all known CFI systems, as demonstrated in recent work. This paper presents a cryptographic approach to control flow integrity (CCFI) that is both fine-grain and practical: using message authentication codes (MAC) to protect control flow elements such as return addresses, function pointers, and vtable pointers. MACs on these elements prevent even powerful attackers with random read/write access to memory from tampering with program control flow. We implemented CCFI in Clang/LLVM, taking advantage of recently available cryptographic CPU instructions. We evaluate our system on several large software packages (including nginx, Apache and memcache) as well as all their dependencies. The cost of protection ranges from a 3-18{\%} decrease in request rate.}
}
@inproceedings{mergendahl2022,
  title         = {Cross-{{Language Attacks}}},
  author        = {Mergendahl, Samuel and Burow, Nathan and Okhravi, Hamed},
  booktitle     = {Proceedings 2022 {{Network}} and {{Distributed System Security Symposium}}},
  location      = {San Diego, CA, USA},
  publisher     = {Internet Society},
  doi           = {10.14722/ndss.2022.24078},
  isbn          = {978-1-891562-74-7},
  date          = 2022,
  eventtitle    = {Network and {{Distributed System Security Symposium}}}
}
@online{MicrosoftCFG,
  title         = {{Microsoft Control Flow Guard}},
  author        = {Microsoft},
  year          = 2022,
  url           = {https://docs.microsoft.com/en-us/windows/win32/secbp/control-flow-guard}
}
@inproceedings{Milanova2005,
  title         = {Parameterized Object Sensitivity for Points-to Analysis for Java},
  author        = {Ana Milanova and Atanas Rountev and Barbara G. Ryder},
  year          = 2005,
  booktitle     = {Proceedings of the 2005 International Symposium on Software Testing and Analysis},
  publisher     = {ACM},
  series        = {ISSTA '05},
  pages         = {1--11}
}
@inproceedings{Mohan2015,
  title         = {{Opaque Control-Flow Integrity}},
  author        = {Mohan, Vishwath and Larsen, Per and Brunthaler, Stefan and Hamlen, Kevin W and Franz, Michael},
  year          = 2015,
  booktitle     = {Proceedings 2015 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  doi           = {10.14722/ndss.2015.23271},
  isbn          = {1-891562-38-X},
  abstract      = {A new binary software randomization and Control- Flow Integrity (CFI) enforcement system is presented, which is the first to efficiently resist code-reuse attacks launched by informed adversaries who possess full knowledge of the in- memory code layout of victim programs. The defense mitigates a recent wave of implementation disclosure attacks , by which adver- saries can exfiltrate in-memory code details in order to prepare code-reuse attacks (e.g., Return-Oriented Programming (ROP) attacks) that bypass fine-grained randomization defenses. Such implementation-aware attacks defeat traditional fine-grained ran- domization by undermining its assumption that the randomized locations of abusable code gadgets remain secret. Opaque CFI (O-CFI) overcomes this weakness through a novel combination of fine-grained code-randomization and coarse- grained control-flow integrity checking. It conceals the graph of hijackable control-flow edges even from attackers who can view the complete stack, heap, and binary code of the victim process. For maximal efficiency, the integrity checks are implemented using instructions that will soon be hardware-accelerated on commodity x86-x64 processors. The approach is highly practical since it does not require a modified compiler and can protect legacy binaries without access to source code. Experiments using our fully functional prototype implementation show that O-CFI provides significant probabilistic protection against ROP attacks launched by adversaries with complete code layout knowledge, and exhibits only 4.7{\%} mean performance overhead on current hardware (with further overhead reductions to follow on forth- coming Intel processors).}
}
@incollection{Morton2017,
  title         = {{Defeating Zombie Gadgets by Re-randomizing Code upon Disclosure}},
  author        = {Morton, Micah and Koo, Hyungjoon and Li, Forrest and Snow, Kevin Z and Polychronakis, Michalis and Monrose, Fabian},
  year          = 2017,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume        = {10379 LNCS},
  pages         = {143--160},
  doi           = {10.1007/978-3-319-62105-0_10},
  isbn          = 9783319621043,
  issn          = 16113349,
  abstract      = {Over the past few years, return-oriented programming (ROP) attacks have emerged as a prominent strategy for hijacking control of software. The full power and flexibility of ROP attacks was recently demonstrated using just-in-time ROP tactics (JIT-ROP), whereby an adversary repeatedly leverages a memory disclosure vulnerability to identify useful instruction sequences and compile them into a functional ROP payload at runtime. Since the advent of just-in-time code reuse attacks, numerous proposals have surfaced for mitigating them, the most practical of which involve the re-randomization of code at runtime or the destruction of gadgets upon their disclosure. Even so, several avenues exist for performing code inference, which allows JIT-ROP attacks to infer values at specific code locations without directly reading the memory contents of those bytes. This is done by reloading code of interest or implicitly determining the state of randomized code. These so-called ``zombie gadgets'' completely undermine defenses that rely on destroying code bytes once they are read. To mitigate these attacks, we present a low-overhead, binary-compatible defense which ensures an attacker is unable to execute gadgets that were identified through code reloading or code inference. We have implemented a prototype of the proposed defense for closed-source Windows binaries, and demonstrate that our approach effectively prevents zombie gadget attacks with negligible runtime overhead.}
}
@www{msrcreport2019,
  title         = {A proactive approach to more secure code},
  author        = {Microsoft Security Response Center},
  url           = {https://www.microsoft.com/en-us/msrc/blog/2019/07/a-proactive-approach-to-more-secure-code},
  urldate       = {2025-01-05},
  date          = {2019-07-16}
}
@article{Nagarakatte2009,
  title         = {{SoftBound}},
  author        = {Nagarakatte, Santosh and Zhao, Jianzhou and Martin, Milo M.K. and Zdancewic, Steve},
  publisher     = {Association for Computing Machinery (ACM)},
  volume        = 44,
  number        = 6,
  pages         = 245,
  doi           = {10.1145/1543135.1542504},
  issn          = {03621340},
  date          = {2009-05-28},
  journaltitle  = {ACM SIGPLAN Notices},
  abstract      = {The serious bugs and security vulnerabilities facilitated by C/C++'s lack of bounds checking are well known, yet C and C++ remain in widespread use. Unfortunately, C's arbitrary pointer arithmetic, conflation of pointers and arrays, and programmer-visible memory layout make retrofitting C/C++ with spatial safety guarantees ex- tremely challenging. Existing approaches suffer from incomplete- ness, have high runtime overhead, or require non-trivial changes to the C source code. Thus far, these deficiencies have prevented widespread adoption of such techniques. This paper proposes SoftBound, a compile-time transformation for enforcing spatial safety of C. Inspired by HardBound, a previ- ously proposed hardware-assisted approach, SoftBound similarly records base and bound information for every pointer as disjoint metadata. This decoupling enables SoftBound to provide spatial safety without requiring changes to C source code. Unlike Hard- Bound, SoftBound is a software-only approach and performs meta- data manipulation only when loading or storing pointer values. A formal proof shows that this is sufficient to provide spatial safety even in the presence of arbitrary casts. SoftBound's full checking mode provides complete spatial violation detection with 67\% run- time overhead on average. To further reduce overheads, SoftBound has a store-only checking mode that successfully detects all the se- curity vulnerabilities in a test suite at the cost of only 22\% runtime overhead on average.}
}
@inproceedings{Nagy2019,
  title         = {Full-{{Speed Fuzzing}}: {{Reducing Fuzzing Overhead}} through {{Coverage-Guided Tracing}}},
  shorttitle    = {Full-{{Speed Fuzzing}}},
  author        = {Nagy, Stefan and Hicks, Matthew},
  year          = 2019,
  month         = may,
  booktitle     = {2019 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  pages         = {787--802},
  doi           = {10.1109/SP.2019.00069},
  issn          = {2375-1207},
  abstract      = {Coverage-guided fuzzing is one of the most successful approaches for discovering software bugs and security vulnerabilities. Of its three main components: (1) test case generation, (2) code coverage tracing, and (3) crash triage, code coverage tracing is a dominant source of overhead. Coverage-guided fuzzers trace every test case's code coverage through either static or dynamic binary instrumentation, or more recently, using hardware support. Unfortunately, tracing all test cases incurs significant performance penalties--even when the overwhelming majority of test cases and their coverage information are discarded because they do not increase code coverage. To eliminate needless tracing by coverage-guided fuzzers, we introduce the notion of coverage-guided tracing. Coverage-guided tracing leverages two observations: (1) only a fraction of generated test cases increase coverage, and thus require tracing; and (2) coverage-increasing test cases become less frequent over time. Coverage-guided tracing encodes the current frontier of coverage in the target binary so that it self-reports when a test case produces new coverage--without tracing. This acts as a filter for tracing; restricting the expense of tracing to only coverage-increasing test cases. Thus, coverage-guided tracing trades increased time handling coverage-increasing test cases for decreased time handling non-coverage-increasing test cases. To show the potential of coverage-guided tracing, we create an implementation based on the static binary instrumentor Dyninst called UnTracer. We evaluate UnTracer using eight real-world binaries commonly used by the fuzzing community. Experiments show that after only an hour of fuzzing, UnTracer's average overhead is below 1\%, and after 24-hours of fuzzing, UnTracer approaches 0\% overhead, while tracing every test case with popular white- and black-box-binary tracers AFL-Clang, AFL-QEMU, and AFL-Dyninst incurs overheads of 36\%, 612\%, and 518\%, respectively. We further integrate UnTracer with the state-of-the-art hybrid fuzzer QSYM and show that in 24-hours of fuzzing, QSYM-UnTracer executes 79\% and 616\% more test cases than QSYM-Clang and QSYM-QEMU, respectively.}
}
@mastersthesis{Neustifter2010,
  title         = {{Efficient Profiling in the LLVM Compiler Infrastructure}},
  author        = {Neustifter, Andreas},
  year          = 2010,
  month         = apr,
  school        = {Vienna University of Technology}
}
@inproceedings{niu2014,
  title         = {Modular Control-Flow Integrity},
  author        = {Niu, Ben and Tan, Gang},
  booktitle     = {Proceedings of the 35th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{PLDI}} '14},
  pages         = {577--587},
  doi           = {10.1145/2594291.2594295},
  isbn          = {978-1-4503-2784-8},
  date          = {2014-06-09},
  abstract      = {Control-Flow Integrity (CFI) is a software-hardening technique. It inlines checks into a program so that its execution always follows a predetermined Control-Flow Graph (CFG). As a result, CFI is effective at preventing control-flow hijacking attacks. However, past fine-grained CFI implementations do not support separate compilation, which hinders its adoption.We present Modular Control-Flow Integrity (MCFI), a new CFI technique that supports separate compilation. MCFI allows modules to be independently instrumented and linked statically or dynamically. The combined module enforces a CFG that is a combination of the individual modules' CFGs. One challenge in supporting dynamic linking in multithreaded code is how to ensure a safe transition from the old CFG to the new CFG when libraries are dynamically linked. The key technique we use is to have the CFG represented in a runtime data structure and have reads and updates of the data structure wrapped in transactions to ensure thread safety. Our evaluation on SPECCPU2006 benchmarks shows that MCFI supports separate compilation, incurs low overhead of around 5\%, and enhances security.}
}
@inproceedings{Niu2015,
  title         = {Per-{{Input Control-Flow Integrity}}},
  author        = {Niu, Ben and Tan, Gang},
  booktitle     = {Proceedings of the 22nd {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  location      = {New York, NY, USA},
  publisher     = {ACM},
  pages         = {914--926},
  doi           = {10.1145/2810103.2813644},
  isbn          = {978-1-4503-3832-5},
  date          = {2015-10-12},
  abstract      = {Control-Flow Integrity (CFI) is an effective approach to mitigating control-flow hijacking attacks. Conventional CFI techniques statically extract a control-flow graph (CFG) from a program and instrument the program to enforce that CFG. The statically generated CFG includes all edges for all possible inputs; however, for a concrete input, the CFG may include many unnecessary edges. We present Per-Input Control-Flow Integrity (PICFI or \ensuremath{\pi}CFI), which is a new CFI technique that can enforce a CFG computed for each concrete input. \ensuremath{\pi}CFI starts executing a program with the empty CFG and lets the program itself lazily add edges to the enforced CFG if such edges are required for the concrete input. The edge addition is performed by \ensuremath{\pi}CFI-inserted instrumentation code. To prevent attackers from arbitrarily adding edges, \ensuremath{\pi}CFI uses a statically computed all-input CFG to constrain what edges can be added at runtime. To minimize performance overhead, operations for adding edges are designed to be idempotent, so they can be patched to no-ops after their first execution. As our evaluation shows, \ensuremath{\pi}CFI provides better security than conventional fine-grained CFI with comparable performance overhead.}
}
@inproceedings{Oikonomopoulos2016a,
  title         = {{Poking Holes in Information Hiding}},
  author        = {Oikonomopoulos, Angelos and Athanasopoulos, Elias and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2016,
  month         = aug,
  booktitle     = {25th {USENIX} Security Symposium ({USENIX} Security 16)},
  publisher     = {{USENIX} Association},
  address       = {Austin, TX},
  pages         = {121--138},
  isbn          = 9781931971324,
  abstract      = {ASLR is no longer a strong defense in itself, but it still serves as a foundation for sophisticated defenses that use randomization for pseudo-isolation. Crucially, these defenses hide sensitive information (such as shadow stacks and safe regions) at a random position in a very large address space. Previous attacks on randomization-based information hiding rely on complicated side channels and/or probing of the mapped memory regions. Assuming no weaknesses exist in the implementation of hidden regions, the attacks typically lead to many crashes or other visible side-effects. For this reason, many researchers still consider the pseudo-isolation offered by ASLR sufficiently strong in practice. We introduce powerful new primitives to show that this faith in ASLR-based information hiding is misplaced, and that attackers can break ASLR and find hidden regions on 32 bit and 64 bit Linux systems quickly with very few malicious inputs. Rather than building on memory accesses that probe the allocated memory areas, we determine the sizes of the unallocated holes in the address space by repeatedly allocating large chunks of memory. Given the sizes, an attacker can infer the location of the hidden region with few or no side-effects. We show that allocation oracles are pervasive and evaluate our primitives on real-world server applications.}
}
@inproceedings{Onarlioglu2010,
  title         = {{G-Free}: Defeating Return-Oriented Programming through Gadget-less Binaries},
  author        = {Onarlioglu, Kaan and Bilge, Leyla and Lanzi, Andrea and Balzarotti, Davide and Kirda, Engin},
  year          = 2010,
  booktitle     = {Proceedings of the 26th Annual Computer Security Applications Conference (ACSAC)},
  pages         = {49--58}
}
@online{openhub-chromium,
  title         = {The {{Chromium}} ({{Google Chrome}}) {{Open Source Project}} on {{Open Hub}}: {{Languages Page}}},
  author        = {{Open Hub}},
  year          = 2025,
  url           = {https://openhub.net/p/chrome/analyses/latest/languages\%5Fsummary},
  urldate       = {2026-01-27},
  note          = {Analysis of the Chromium codebase showing approximately 36 million lines of code}
}
@online{openhub-firefox,
  title         = {The {{Mozilla Firefox Open Source Project}} on {{Open Hub}}: {{Languages Page}}},
  author        = {{Open Hub}},
  year          = 2025,
  url           = {https://openhub.net/p/firefox/analyses/latest/languages\%5Fsummary},
  urldate       = {2026-01-27},
  note          = {Analysis of the Firefox codebase showing approximately 21 million lines of code}
}
@inproceedings{orthen2024,
  title         = {{{SoftBound}}+{{CETS Revisited}}: {{More Than}} a {{Decade Later}}},
  shorttitle    = {{{SoftBound}}+{{CETS Revisited}}},
  author        = {Orthen, Benjamin and Braunsdorf, Oliver and Zieris, Philipp and Horsch, Julian},
  booktitle     = {Proceedings of the 17th {{European Workshop}} on {{Systems Security}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSec}} '24},
  pages         = {22--28},
  doi           = {10.1145/3642974.3652285},
  isbn          = {979-8-4007-0542-7},
  date          = {2024-04-22},
  abstract      = {Memory safety issues, including buffer overflows and use-after-free errors, continue to pose significant security threats in C/C++ programs, necessitating robust defenses and detection mechanisms. Despite advancements in memory-safe languages like Rust, transitioning legacy codebases often remains impractical, highlighting the need for effective memory safety tools for existing C/C++ code. This paper revisits SoftBound+CETS, an influential combination of two software-only memory safety solutions for C programs, more than a decade after its initial introduction. We present an updated SoftBound+CETS prototype, now compatible with LLVM 12, offering enhanced C language compatibility, interoperability with uninstrumented code, and sub-object bounds checking. Our evaluation, utilizing the SPEC CPU 2017 benchmark suite and the Juliet Test Suite, demonstrates the prototype's improved effectiveness in detecting memory errors with a performance and memory overhead of less than 2x. This is comparable to the widely used but less capable sanitizer ASan. Our future work aims to further reduce overheads and expand compatibility with C++ code and newer LLVM versions. This research highlights the viability of SoftBound+CETS as a comprehensive and practical tool for improving memory safety in legacy C applications, providing a valuable asset for developers and researchers focused on software security.}
}
@inproceedings{osterlund2021,
  title         = {{{CollabFuzz}}: {{A Framework}} for {{Collaborative Fuzzing}}},
  shorttitle    = {{CollabFuzz}},
  author        = {{\"{O}}sterlund, Sebastian and Geretto, Elia and Jemmett, Andrea and G{\"{u}}ler, Emre and G{\"{o}}rz, Philipp and Holz, Thorsten and Giuffrida, Cristiano and Bos, Herbert},
  booktitle     = {Proceedings of the 14th {{European Workshop}} on {{Systems Security}}},
  location      = {Online United Kingdom},
  publisher     = {ACM},
  pages         = {1--7},
  doi           = {10.1145/3447852.3458720},
  isbn          = {978-1-4503-8337-0},
  date          = {2021-04-26},
  eventtitle    = {{{EuroSys}} '21: {{Sixteenth European Conference}} on {{Computer Systems}}}
}
@inproceedings{Padhye2019,
  title         = {Semantic Fuzzing with Zest},
  author        = {Padhye, Rohan and Lemieux, Caroline and Sen, Koushik and Papadakis, Mike and Le Traon, Yves},
  year          = 2019,
  month         = jul,
  booktitle     = {Proceedings of the 28th {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  publisher     = {ACM},
  address       = {Beijing China},
  pages         = {329--340},
  doi           = {10.1145/3293882.3330576},
  isbn          = {978-1-4503-6224-5}
}
@inproceedings{Padhye2019a,
  title         = {{{JQF}}: Coverage-Guided Property-Based Testing in {{Java}}},
  shorttitle    = {{JQF}},
  author        = {Padhye, Rohan and Lemieux, Caroline and Sen, Koushik},
  year          = 2019,
  month         = jul,
  booktitle     = {Proceedings of the 28th {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  publisher     = {ACM},
  address       = {Beijing China},
  pages         = {398--401},
  doi           = {10.1145/3293882.3339002},
  isbn          = {978-1-4503-6224-5}
}
@inproceedings{papadogiannakis2013,
  title         = {{{ASIST}}: Architectural Support for Instruction Set Randomization},
  shorttitle    = {{ASIST}},
  author        = {Papadogiannakis, Antonis and Loutsis, Laertis and Papaefstathiou, Vassilis and Ioannidis, Sotiris},
  booktitle     = {Proceedings of the 2013 {{ACM SIGSAC}} Conference on {{Computer}} \& Communications Security - {{CCS}} '13},
  location      = {Berlin, Germany},
  publisher     = {ACM Press},
  pages         = {981--992},
  doi           = {10.1145/2508859.2516670},
  isbn          = {978-1-4503-2477-9},
  date          = 2013,
  eventtitle    = {The 2013 {{ACM SIGSAC}} Conference}
}
@inproceedings{Pappas2012a,
  title         = {{Smashing the Gadgets: Hindering Return-Oriented Programming Using In-place Code Randomization}},
  author        = {Pappas, Vasilis and Polychronakis, Michalis and Keromytis, Angelos D.},
  year          = 2012,
  month         = may,
  booktitle     = {2012 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  pages         = {601--615},
  doi           = {10.1109/SP.2012.41},
  isbn          = {978-1-4673-1244-8},
  issn          = 10816011,
  abstract      = {The wide adoption of non-executable page protec- tions in recent versions of popular operating systems has given rise to attacks that employ return-oriented programming (ROP) to achieve arbitrary code execution without the injection of any code. Existing defenses against ROP exploits either require source code or symbolic debugging information, or impose a significant runtime overhead, which limits their applicability for the protection of third-party applications. In this paper we present in-place code randomization, a practical mitigation technique against ROP attacks that can be applied directly on third-party software. Our method uses various narrow-scope code transformations that can be applied statically, without changing the location of basic blocks, allowing the safe randomization of stripped binaries even with partial disassembly coverage. These transformations effectively eliminate about 10{\%}, and probabilistically break about 80{\%} of the useful instruction sequences found in a large set of PE files. Since no additional code is inserted, in-place code randomization does not incur any measurable runtime overhead, enabling it to be easily used in tandem with existing exploit mitigations such as address space layout randomization. Our evaluation using publicly available ROP exploits and two ROP code generation toolkits demonstrates that our technique prevents the exploitation of the tested vulnerableWindows 7 applications, including Adobe Reader, as well as the automated construction of alternative ROP payloads that aim to circumvent in-place code randomization using solely any remaining unaffected instruction sequences.}
}
@inproceedings{Pappas2013b,
  title         = {Transparent {ROP} Exploit Mitigation Using Indirect Branch Tracing},
  author        = {Vasilis Pappas and Michalis Polychronakis and Angelos D. Keromytis},
  year          = 2013,
  month         = aug,
  booktitle     = {22nd USENIX Security Symposium (USENIX Security 13)},
  publisher     = {USENIX Association},
  pages         = {447--462}
}
@misc{PaXTeam2003,
  title         = {Address Space Layout Randomization ({ASLR})},
  author        = {{PaX Team}},
  year          = 2003,
  note          = {Accessed: 2023-10-27},
  howpublished  = {\url{https://pax.grsecurity.net/docs/aslr.txt}}
}
@incollection{Payer2015,
  title         = {{Fine-Grained Control-Flow Integrity Through Binary Hardening}},
  author        = {Payer, Mathias and Barresi, Antonio and Gross, Thomas R.},
  year          = 2015,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher     = {Springer Verlag},
  volume        = 9148,
  pages         = {144--164},
  doi           = {10.1007/978-3-319-20550-2_8},
  isbn          = 9783319205496,
  issn          = 16113349,
  abstract      = {Applications written in low-level languages without type or memory safety are prone to memory corruption. Attackers gain code execution capabilities through memory corruption despite all currently deployed defenses. Control-Flow Integrity (CFI) is a promising security property that restricts indirect control-flow transfers to a static set of well-known locations. We present Lockdown, a modular, fine-grained CFI policy that protects binary-only applications and libraries without requiring sourcecode. Lockdown adaptively discovers the control-flow graph of a running process based on the executed code. The sandbox component of Lockdown restricts interactions between different shared objects to imported and exported functions by enforcing fine-grained CFI checks using information from a trusted dynamic loader. A shadow stack enforces precise integrity for function returns. Our prototype implementation shows that Lockdown results in low performance overhead and a security analysis discusses any remaining gadgets.}
}
@article{Pettis1990,
  title         = {{Profile guided code positioning}},
  author        = {Pettis, Karl and Hansen, Robert C.},
  year          = 1990,
  month         = jun,
  journal       = {ACM SIGPLAN Notices},
  volume        = 25,
  number        = 6,
  pages         = {16--27},
  doi           = {10.1145/93548.93550},
  issn          = {0362-1340},
  abstract      = {This paper presents the results of our investigation of code positioning techniques using execution profile data as input into the compilation process. The primary objective of the positioning is to reduce the overhead of the instruction memory hierarchy. After initial investigation in the literature, we decided to implement two prototypes for the Hewlett-Packard Precision Architecture 1990. The first, built on top of the linker, positions code based on whole procedures. This prototype has the ability to move procedures into an order that is determined by a ``closest is best'' strategy. The second prototype, built on top of an existing optimizer package, positions code based on basic blocks within procedures. Groups of basic blocks that would be better as straight-line sequences are identified as chains. These chains are then ordered according to branch heuristics. Code that is never executed during the data collection runs can be physically separated from the primary code of a procedure by a technique we devised called procedure splitting. The algorithms we implemented are described through examples in this paper. The performance improvements from our work are also summarized in various tables and charts. {\textcopyright} 1990, ACM. All rights reserved.}
}
@inproceedings{Pomonis2017,
  title         = {{kR\string^X: Comprehensive Kernel Protection against Just-In-Time Code Reuse}},
  author        = {Pomonis, Marios and Petsios, Theofilos and Keromytis, Angelos D. and Polychronakis, Michalis and Kemerlis, Vasileios P.},
  year          = 2017,
  booktitle     = {Proceedings of the Twelfth European Conference on Computer Systems},
  location      = {Belgrade, Serbia},
  publisher     = {Association for Computing Machinery},
  series        = {EuroSys '17},
  pages         = {420â€“436},
  doi           = {10.1145/3064176.3064216},
  isbn          = 9781450349383,
  numpages      = 17
}
@article{Pomonis2019,
  title         = {{kR\string^X: Comprehensive Kernel Protection against Just-In-Time Code Reuse}},
  author        = {Marios Pomonis and Theofilos Petsios and Angelos D. Keromytis and Michalis Polychronakis and Vasileios P. Kemerlis},
  year          = 2019,
  journal       = {ACM Transactions on Privacy and Security (TOPS)},
  volume        = 22,
  number        = 1,
  pages         = {1--28}
}
@inproceedings{Prakash2015,
  title         = {{vfGuard: Strict Protection for Virtual Function Calls in COTS C++ Binaries}},
  shorttitle    = {vfGuard},
  author        = {Prakash, Aravind and Hu, Xunchao and Yin, Heng},
  year          = 2015,
  booktitle     = {Proceedings 2015 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  doi           = {10.14722/ndss.2015.23297},
  isbn          = {1-891562-38-X},
  abstract      = {--Control-Flow Integrity (CFI) is an important se-curity property that needs to be enforced to prevent control-flow hijacking attacks. Recent attacks have demonstrated that existing CFI protections for COTS binaries are too permissive, and vulnerable to sophisticated code reusing attacks. Accounting for control flow restrictions imposed at higher levels of semantics is key to increasing CFI precision. In this paper, we aim to provide more stringent protection for virtual function calls in COTS C++ binaries by recovering C++ level semantics. To achieve this goal, we recover C++ semantics, including VTables and virtual callsites. With the extracted C++ semantics, we construct a sound CFI policy and further improve the policy precision by devising two filters, namely " Nested Call Filter " and " Calling Convention Filter " . We implement a prototype system called vfGuard, and evaluate its accuracy, precision, effectiveness, coverage and performance overhead against a test set including complex C++ binary modules used by Internet Explorer. Our experiments show a runtime overhead of 18.3{\%} per module. On SpiderMonkey, an open-source JavaScript engine used by Firefox, vfGuard generated 199 call targets per virtual callsite â€“ within the same order of magnitude as those generated from a source code based solution. The policies constructed by vfGuard are sound and of higher precision when compared to state-of-the-art binary-only CFI solutions.},
  language      = {en}
}
@www{projectzeroandroid2022,
  title         = {Memory Safe Languages in {{Android}} 13},
  author        = {Google Security Blog},
  url           = {https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html},
  urldate       = {2025-01-05},
  date          = {2022-12-01}
}
@www{projectzerointhewild2024,
  title         = {Zero Day In-the-Wild Exploitation in 2023},
  author        = {Project Zero},
  url           = {https://googleprojectzero.blogspot.com/2024/04/zero-day-in-the-wild-exploitation-in-2023.html},
  urldate       = {2025-01-05},
  date          = {2024-04-10}
}
@inproceedings{Rajasekaran2020,
  title         = {{CoDaRR}: {Continuous} {Data} {Space} {Randomization} against {Data}-{Only} {Attacks}},
  author        = {Rajasekaran, Prabhu and Crane, Stephen and Gens, David and Na, Yeoul and Volckaert, Stijn and Franz, Michael},
  year          = 2020,
  month         = oct,
  booktitle     = {Proceedings of the 15th {ACM} {Asia} {Conference} on {Computer} and {Communications} {Security}},
  publisher     = {ACM},
  address       = {New York, NY, USA},
  pages         = {494--505},
  doi           = {10.1145/3320269.3384757},
  isbn          = {978-1-4503-6750-9},
  abstract      = {The widespread deployment of exploit mitigations such as CFI and shadow stacks are making code-reuse attacks increasingly difficult. This has forced adversaries to consider data-only attacks against which the venerable ASLR remains the primary deployed defense. Data-Space Randomization (DSR) techniques raise the bar against data-only attacks by making it harder for adversaries to inject malicious data flows into vulnerable applications. DSR works by masking memory load and store instructions. Masks are chosen (i) to not interfere with intended data flows and (ii) such that masking likely interferes with unintended flows introduced by malicious program inputs. In this paper, we show two new attacks that bypass all existing static DSR approaches; one that directly discloses memory and another using speculative execution. We then present CoDaRR, the first dynamic DSR scheme resilient to disclosure attacks. CoDaRR continuously rerandomizes the masks used in loads and stores, and re-masks all memory objects to remain transparent w.r.t. program execution. Our evaluation confirms that CoDaRR successfully thwarts these attacks with limited run-time overhead in standard benchmarks as well as real-world applications.}
}
@article{regehr2012,
  title         = {Test-Case Reduction for {{C}} Compiler Bugs},
  author        = {Regehr, John and Chen, Yang and Cuoq, Pascal and Eide, Eric and Ellison, Chucky and Yang, Xuejun},
  volume        = 47,
  number        = 6,
  pages         = {335--346},
  doi           = {10.1145/2345156.2254104},
  issn          = {0362-1340},
  date          = {2012-06-11},
  journaltitle  = {SIGPLAN Not.},
  abstract      = {To report a compiler bug, one must often find a small test case that triggers the bug. The existing approach to automated test-case reduction, delta debugging, works by removing substrings of the original input; the result is a concatenation of substrings that delta cannot remove. We have found this approach less than ideal for reducing C programs because it typically yields test cases that are too large or even invalid (relying on undefined behavior). To obtain small and valid test cases consistently, we designed and implemented three new, domain-specific test-case reducers. The best of these is based on a novel framework in which a generic fixpoint computation invokes modular transformations that perform reduction operations. This reducer produces outputs that are, on average, more than 25 times smaller than those produced by our other reducers or by the existing reducer that is most commonly used by compiler developers. We conclude that effective program reduction requires more than straightforward delta debugging.}
}
@incollection{Rodes2013,
  title         = {{Defense against Stack-Based Attacks Using Speculative Stack Layout Transformation}},
  author        = {Rodes, Benjamin D. and Nguyen-Tuong, Anh and Hiser, Jason D. and Knight, John C. and Co, Michele and Davidson, Jack W.},
  year          = 2013,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher     = {Springer Verlag},
  volume        = {7687 LNCS},
  pages         = {308--313},
  doi           = {10.1007/978-3-642-35632-2_29},
  isbn          = 9783642356315,
  issn          = 16113349,
  abstract      = {This paper describes a novel technique to defend binaries against intra-frame stack-based attacks, including overflows into local variables, when source code is unavailable. The technique infers a specification of a function's stack layout, i.e., variable locations and boundaries, and then seeks to apply a combination of transformations, including variable reordering, random-sized padding between variables, and placement of canaries. To overcome the imprecision of static binary analysis, yet be as aggressive as possible in the transformations applied to the stack layout, the technique is speculative. A stack frame is aggressively transformed based on static analysis, and the validity of inferred stack layout is assessed through regression testing. If a transformation changes a program's semantics because of imprecision in the inference of the stack layout, a less aggressive layout is inferred until the transformed program passes the supplied regression tests. We present an overview of the technique and preliminary results of its feasibility and security effectiveness. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.}
}
@article{roemer2012,
  title         = {Return-{{Oriented Programming}}: {{Systems}}, {{Languages}}, and {{Applications}}},
  shorttitle    = {Return-{{Oriented Programming}}},
  author        = {Roemer, Ryan and Buchanan, Erik and Shacham, Hovav and Savage, Stefan},
  volume        = 15,
  number        = 1,
  pages         = {2:1--2:34},
  doi           = {10.1145/2133375.2133377},
  issn          = {1094-9224},
  date          = {2012-03-01},
  journaltitle  = {ACM Trans. Inf. Syst. Secur.},
  abstract      = {We introduce return-oriented programming, a technique by which an attacker can induce arbitrary behavior in a program whose control flow he has diverted, without injecting any code. A return-oriented program chains together short instruction sequences already present in a program's address space, each of which ends in a ``return'' instruction.Return-oriented programming defeats the W\oplus{}X protections recently deployed by Microsoft, Intel, and AMD; in this context, it can be seen as a generalization of traditional return-into-libc attacks. But the threat is more general. Return-oriented programming is readily exploitable on multiple architectures and systems. It also bypasses an entire category of security measures---those that seek to prevent malicious computation by preventing the execution of malicious code.To demonstrate the wide applicability of return-oriented programming, we construct a Turing-complete set of building blocks called gadgets using the standard C libraries of two very different architectures: Linux/x86 and Solaris/SPARC. To demonstrate the power of return-oriented programming, we present a high-level, general-purpose language for describing return-oriented exploits and a compiler that translates it to gadgets.}
}
@inproceedings{Rudd2017,
  title         = {{Address Oblivious Code Reuse: On the Effectiveness of Leakage-Resilient Diversity}},
  author        = {Rudd, Robert and Skowyra, Richard and Bigelow, David and Dedhia, Veer and Hobson, Thomas and Crane, Stephen and Liebchen, Christopher and Larsen, Per and Davi, Lucas and Franz, Michael and Sadeghi, Ahmad-Reza and Okhravi, Hamed},
  year          = 2017,
  booktitle     = {Proceedings 2017 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  doi           = {10.14722/ndss.2017.23477},
  isbn          = {1-891562-46-0},
  abstract      = {--Memory corruption vulnerabilities not only allow modification of control data and injection of malicious payloads; they also allow adversaries to reconnoiter a diversified program, customize a payload, and ultimately bypass code randomization defenses. In response, researchers have proposed and built various leakage-resilient defenses against code reuse. Leakage-resilient defenses use memory protection techniques to prevent adversaries from directly reading code as well as pointer indirection or encryption techniques to decouple code pointers from the ran-domized code layout, avoiding indirect leakage. In this paper, we show that although current code pointer protections do prevent leakage per se, they are fundamentally unable to stop code reuse. Specifically, we demonstrate a new class of attacks we call address-oblivious code reuse that bypasses state-of-the-art leakage-resilience techniques by profiling and reusing protected code pointers, without leaking the code layout. We show that an attacker can accurately identify protected code pointers of interest and mount code-reuse attacks at the abstraction level of pointers without requiring any knowledge of code addresses. We analyze the prevalence of opportunities for such attacks in popular code bases and build three real-world exploits against Nginx and Apache to demonstrate their practicality. We analyze recently proposed leakage resilient defenses and show that they are vulnerable to address oblivious code reuse. Our findings indicate that because of the prevalence of code pointers in realistic programs and the fundamental need to expose them to " read " operations (even indirectly), diversity defenses face a fundamental design challenge in mitigating such attacks.}
}
@inproceedings{sarafov2024,
  title         = {Understanding and {{Improving Coverage Tracking}} with {{AFL}}++ ({{Registered Report}})},
  author        = {Sarafov, Vasil and Markvica, David and Berlakovich, Felix and Bernad, Matthias and Brunthaler, Stefan},
  booktitle     = {Proceedings of the 3rd {{ACM International Fuzzing Workshop}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{FUZZING}} 2024},
  pages         = {80--89},
  doi           = {10.1145/3678722.3685537},
  isbn          = {979-8-4007-1112-1},
  date          = {2024-09-13},
  abstract      = {Coverage-based fuzzers track which program parts they visit when executing a specific input as a proxy measure to (1) guide the fuzzing process, and (2) explore the PUT's state space. One way to record coverage progress is to enumerate basic block pairs (e.g., edges in the control-flow graph) and use them to index into a hash table that holds counters. The counter is incremented every time a fuzzer's input exercises the corresponding edge. Traditionally the coverage map has been a compact bitmap that fits the L2 CPU cache to reduce runtime overhead and boost fuzzing throughput. In such a design where space is traded for speed, two sources of imprecision can arise: (1) collisions, and (2) arithmetic inaccuracies. Collisions refer to the situation when two different basic block pairs hash to the same entry. Imprecision arises since one pair is now counted together, but the fuzzer cannot tell one apart from the other. Arithmetic inaccuracies refer to errors in the counting strategy. For example, a monotonically incrementing counter inside the hash table can overflow. This indicates a situation where high-frequency control-flow exceeds the predefined, expected maximum counter size (e.g., in loops). Due to execution frequencies obeying exponential power laws, such overflows will affect a small number of hash table entries. Another arithmetic inaccuracy results from range-based counters that capture only predefined frequency intervals (e.g., logarithmic counters). In 2018, CollAFL examined how collisions impact precision, and presented a new hashing scheme to reduce the number of collisions. CollAFL did not address the problem of arithmetic inaccuracies. Furthermore, CollAFL considered only a single-core virtual machine, a limited set of benchmark programs, and did not explore hardware-specific effects (e.g., cache utilization for concurrent fuzzing processes). This registered report aims at providing new insights of how collisions and arithmetic inaccuracies affect coverage tracking for fuzzing. We propose experiments for multiple hardware architectures with different cache topologies, and a more diverse set of benchmark programs. Leveraging the evaluation data, our aim is to determine precise architecture-aware settings for AFL++. Furthermore, we plan to demonstrate an adaptive optimization strategy that optimizes the coverage map to collisions and counting strategies for a specific combination of the CPU architecture and PUT.}
}
@inproceedings{sarafov2025,
  title         = {{{TEPHRA}}: {{Principled Discovery}} of {{Fuzzer Limitations}}},
  author        = {Sarafov, Vasil and Markvica, David and Brunthaler, Stefan},
  year          = 2025,
  booktitle     = {Proceedings of the 40th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  location      = {Seoul, South Korea},
  publisher     = {Association for Computing Machinery},
  series        = {{{ASE}} '25},
  note          = {ACM SIGSOFT Distinguished Paper Award}
}
@inproceedings{schloegel2024,
  title         = {{{SoK}}: {{Prudent Evaluation Practices}} for {{Fuzzing}}},
  shorttitle    = {{SoK}},
  author        = {Schloegel, Moritz and Bars, Nils and Schiller, Nico and Bernhard, Lukas and Scharnowski, Tobias and Crump, Addison and Ale-Ebrahim, Arash and Bissantz, Nicolai and Muench, Marius and Holz, Thorsten},
  publisher     = {IEEE Computer Society},
  pages         = {136--136},
  doi           = {10.1109/SP54263.2024.00137},
  isbn          = {979-8-3503-3130-1},
  issn          = {2375-1207},
  date          = {2024-02-01},
  abstract      = {Fuzzing has proven to be a highly effective approach to uncover software bugs over the past decade. After AFL popularized the groundbreaking concept of lightweight coverage feedback, the field of fuzzing has seen a vast amount of scientific work proposing new techniques, improving methodological aspects of existing strategies, or porting existing methods to new domains. All such work must demonstrate its merit by showing its applicability to a problem, measuring its performance, and often showing its superiority over existing works in a thorough, empirical evaluation. Yet, fuzzing is highly sensitive to its target, environment, and circumstances, e.g., randomness in the testing process. After all, relying on randomness is one of the core principles of fuzzing, governing many aspects of a fuzzer's behavior. Combined with the often highly difficult to control environment, the reproducibility of experiments is a crucial concern and requires a prudent evaluation setup. To address these threats to validity, several works, most notably Evaluating Fuzz Testing by Klees et al., have outlined how a carefully designed evaluation setup should be implemented, but it remains unknown to what extent their recommendations have been adopted in practice. In this work, we systematically analyze the evaluation of 150 fuzzing papers published at the top venues between 2018 and 2023. We study how existing guidelines are implemented and observe potential shortcomings and pitfalls. We find a surprising disregard of the existing guidelines regarding statistical tests and systematic errors in fuzzing evaluations. For example, when investigating reported bugs, we find that the search for vulnerabilities in real-world software leads to authors requesting and receiving CVEs of questionable quality. Extending our literature analysis to the practical domain, we attempt to reproduce claims of eight fuzzing papers. These case studies allow us to assess the practical reproducibility of fuzzing research and identify archetypal pitfalls in the evaluation design. Unfortunately, our reproduced results reveal several deficiencies in the studied papers, and we are unable to fully support and reproduce the respective claims. To help the field of fuzzing move toward a scientifically reproducible evaluation strategy, we propose updated guidelines for conducting a fuzzing evaluation that future work should follow.},
  eventtitle    = {2024 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})}
}
@inproceedings{Schuster2015a,
  title         = {{Counterfeit Object-oriented Programming: On the Difficulty of Preventing Code Reuse Attacks in C++ Applications}},
  shorttitle    = {Counterfeit object-oriented programming},
  author        = {Schuster, Felix and Tendyck, Thomas and Liebchen, Christopher and Davi, Lucas and Sadeghi, Ahmad-Reza and Holz, Thorsten},
  year          = 2015,
  month         = may,
  booktitle     = {2015 IEEE Symposium on Security and Privacy},
  publisher     = {IEEE},
  volume        = {2015-July},
  pages         = {745--762},
  doi           = {10.1109/SP.2015.51},
  isbn          = {978-1-4673-6949-7},
  issn          = 10816011,
  abstract      = {Code reuse attacks such as return-oriented programming (ROP) have become prevalent techniques to exploit memory corruption vulnerabilities in software programs. A variety of corresponding defenses has been proposed, of which some have already been successfully bypassed -- and the arms race continues. In this paper, we perform a systematic assessment of recently proposed CFI solutions and other defenses against code reuse attacks in the context of C++. We demonstrate that many of these defenses that do not consider object-oriented C++ semantics precisely can be generically bypassed in practice. Our novel attack technique, denoted as counterfeit object-oriented programming (COOP), induces malicious program behavior by only invoking chains of existing C++ virtual functions in a program through corresponding existing call sites. COOP is Turing complete in realistic attack scenarios and we show its viability by developing sophisticated, real-world exploits for Internet Explorer 10 on Windows and Fire fox 36 on Linux. Moreover, we show that even recently proposed defenses (CPS, T-VIP, vfGuard, and VTint) that specifically target C++ are vulnerable to COOP. We observe that constructing defenses resilient to COOP that do not require access to source code seems to be challenging. We believe that our investigation and results are helpful contributions to the design and implementation of future defenses against control flow hijacking attacks.}
}
@inproceedings{schwarcz2024,
  title         = {{{LOOL}}: {{Low-Overhead}}, {{Optimization-Log-Guided Compiler Fuzzing}} ({{Registered Report}})},
  shorttitle    = {{LOOL}},
  author        = {Schwarcz, Florian and Berlakovich, Felix and Barany, Gerg\"{o} and M\"{o}ssenb\"{o}ck, Hanspeter},
  booktitle     = {Proceedings of the 3rd {{ACM International Fuzzing Workshop}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{FUZZING}} 2024},
  pages         = {42--51},
  doi           = {10.1145/3678722.3685533},
  isbn          = {979-8-4007-1112-1},
  date          = {2024-09-13},
  abstract      = {Compiler fuzzing with randomly generated input programs is a powerful technique for finding compiler crashes and miscompilation bugs. Existing fuzzers for compilers are often unguided and must be manually parameterized to cover different parts of the compiler under test. In this work we present LOOL, an approach for fuzzing a compiler with low overhead, guided by optimization log information produced by the compiler. The optimization log tracks program transformations performed by the compiler on the level of individual methods compiled. We argue that using the optimization log has less overhead than off-the-shelf code coverage tools. At the same time, the optimization log's per-method data gives more information than code coverage collected over a number of distinct compilations. The level of detail of the optimization log is also easy to tune for the use case of guiding a fuzzer. We are integrating the LOOL approach in an existing fuzzer for the GraalVM compiler. A genetic optimization algorithm uses optimization log information for tuning code generation parameters with the goal of covering optimizations that were previously rarely exercised. Initial experiments confirm that varying the generator's parameters is effective at finding new bugs. The genetic algorithm will automate the exploration of the parameter space to improve testing of currently insufficiently fuzzed parts of the compiler.}
}
@inproceedings{Schwarz2019a,
  title         = {{ZombieLoad: Cross-Privilege-Boundary Data Sampling}},
  author        = {Schwarz, Michael and Lipp, Moritz and Moghimi, Daniel and {Van Bulck}, Jo and Stecklina, Julian and Prescher, Thomas and Gruss, Daniel},
  year          = 2019,
  booktitle     = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {CCS '19},
  pages         = {753--768},
  doi           = {10.1145/3319535.3354252},
  isbn          = 9781450367479,
  abstract      = {In early 2018, Meltdown first showed how to read arbitrary kernel memory from user space by exploiting side-effects from transient instructions. While this attack has been mitigated through stronger isolation boundaries between user and kernel space, Meltdown inspired an entirely new class of fault-driven transient-execution attacks. Particularly, over the past year, Meltdown-type attacks have been extended to not only leak data from the L1 cache but also from various other microarchitectural structures, including the FPU register file and store buffer.In this paper, we present the ZombieLoad attack which uncovers a novel Meltdown-type effect in the processor's fill-buffer logic. Our analysis shows that faulting load instructions (i.e., loads that have to be re-issued) may transiently dereference unauthorized destinations previously brought into the fill buffer by the current or a sibling logical CPU. In contrast to concurrent attacks on the fill buffer, we are the first to report data leakage of recently loaded and stored stale values across logical cores even on Meltdown- and MDS-resistant processors. Hence, despite Intel's claims, we show that the hardware fixes in new CPUs are not sufficient. We demonstrate ZombieLoad's effectiveness in a multitude of practical attack scenarios across CPU privilege rings, OS processes, virtual machines, and SGX enclaves. We discuss both short and long-term mitigation approaches and arrive at the conclusion that disabling hyperthreading is the only possible workaround to prevent at least the most-powerful cross-hyperthread attack scenarios on current processors, as Intel's software fixes are incomplete.}
}
@incollection{Schwarz2019b,
  title         = {{NetSpectre: Read Arbitrary Memory over Network}},
  author        = {Schwarz, Michael and Schwarzl, Martin and Lipp, Moritz and Masters, Jon and Gruss, Daniel},
  year          = 2019,
  month         = sep,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher     = {Springer},
  volume        = {11735 LNCS},
  pages         = {279--299},
  doi           = {10.1007/978-3-030-29959-0_14},
  isbn          = 9783030299583,
  issn          = 16113349,
  abstract      = {All Spectre attacks so far required local code execution. We present the first fully remote Spectre attack. For this purpose, we demonstrate the first access-driven remote Evict+Reload cache attack over the network, leaking 15 bits per hour. We present a novel high-performance AVX-based covert channel that we use in our cache-free Spectre attack. We show that in particular remote Spectre attacks perform significantly better with the AVX-based covert channel, leaking 60 bits per hour from the target system. We demonstrate practical NetSpectre attacks on the Google cloud, remotely leaking data and remotely breaking ASLR.},
  archiveprefix = {arXiv},
  arxivid       = {1807.10535},
  eprint        = {1807.10535}
}
@inproceedings{Shacham2007,
  title         = {{The geometry of innocent flesh on the bone}},
  author        = {Shacham, Hovav},
  year          = 2007,
  booktitle     = {Proceedings of the 14th ACM conference on Computer and communications security - CCS '07},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  volume        = 22,
  number        = 4,
  pages         = 552,
  doi           = {10.1145/1315245.1315313},
  isbn          = 9781595937032,
  issn          = 15437221,
  abstract      = {We present new techniques that allow a return-into-libc attack to be mounted on x86 executables that calls no functions at all. Our attack combines a large number of short instruction sequences to build gadgets that allow arbitrary computation. We show how to discover such instruction sequences by means of static analysis. We make use, in an essential way, of the properties of the x86 instruction set.}
}
@incollection{SharirPnueli1981,
  title         = {Two Approaches to Interprocedural Data Flow Analysis},
  author        = {Micha Sharir and Amir Pnueli},
  year          = 1981,
  booktitle     = {Program Flow Analysis: Theory and Applications},
  publisher     = {Prentice Hall},
  pages         = {189--234},
  editor        = {Steven S. Muchnick and Neil D. Jones}
}
@online{Sloccount,
  title         = {{SLOCCount}},
  author        = {Wheeler, David A.},
  year          = 2022,
  url           = {https://dwheeler.com/sloccount/}
}
@inproceedings{Snow2013,
  title         = {Just-{{In-Time Code Reuse}}: {{On}} the {{Effectiveness}} of {{Fine-Grained Address Space Layout Randomization}}},
  shorttitle    = {Just-{{In-Time Code Reuse}}},
  author        = {Snow, Kevin Z. and Monrose, Fabian and Davi, Lucas and Dmitrienko, Alexandra and Liebchen, Christopher and Sadeghi, A.},
  booktitle     = {2013 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  publisher     = {IEEE},
  pages         = {574--588},
  doi           = {10.1109/SP.2013.45},
  isbn          = {978-0-7695-4977-4},
  issn          = 10816011,
  date          = {2013-05},
  abstract      = {Fine-grained address space layout randomization (ASLR) has recently been proposed as a method of efficiently mitigating runtime attacks. In this paper, we introduce the design and implementation of a framework based on a novel attack strategy, dubbed just-in-time code reuse, that undermines the benefits of fine-grained ASLR. Specifically, we derail the assumptions embodied in fine-grained ASLR by exploiting the ability to repeatedly abuse a memory disclosure to map an application's memory layout on-the-fly, dynamically discover API functions and gadgets, and JIT-compile a target program using those gadgets--all within a script environment at the time an exploit is launched. We demonstrate the power of our framework by using it in conjunction with a real-world exploit against Internet Explorer, and also provide extensive evaluations that demonstrate the practicality of just-in-time code reuse attacks. Our findings suggest that fine-grained ASLR may not be as promising as first thought.}
}
@inproceedings{Snow2016,
  title         = {{Return to the Zombie Gadgets: Undermining Destructive Code Reads via Code Inference Attacks}},
  author        = {Snow, Kevin Z. and Rogowski, Roman and Werner, Jan and Koo, Hyungjoon and Monrose, Fabian and Polychronakis, Michalis},
  year          = 2016,
  month         = may,
  booktitle     = {2016 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  pages         = {954--968},
  doi           = {10.1109/SP.2016.61},
  isbn          = {978-1-5090-0824-7},
  issn          = {0096-140X},
  abstract      = {The concept of destructive code reads is a new defensive strategy that prevents code reuse attacks by coupling finegrained address space layout randomization with a mitigation for online knowledge gathering that destroys potentially useful gadgets as they are disclosed by an adversary. The intuition is that by destroying code as it is read, an adversary is left with no usable gadgets to reuse in a control-flow hijacking attack. In this paper, we examine the security of this new mitigation. We show that while the concept initially appeared promising, there are several unforeseen attack tactics that render destructive code reads ineffective in practice. Specifically, we introduce techniques for leveraging constructive reloads, wherein multiple copies of native code are loaded into a process' address space (either side-by-side or one-afteranother). Constructive reloads allow the adversary to disclose one code copy, destroying it in the process, then use another code copy for their code reuse payload. For situations where constructive reloads are not viable, we show that an alternative, and equally powerful, strategy exists: leveraging code association via implicit reads, which allows an adversary to undo in-place code randomization by inferring the layout of code that follows already disclosed bytes. As a result, the implicitly learned code is not destroyed, and can be used in the adversary's code reuse attack. We demonstrate the effectiveness of our techniques with concrete instantiations of these attacks against popular applications. In light of our successes, we argue that the code inference strategies presented herein paint a cautionary tale for defensive approaches whose security blindly rests on the perceived inability to undo the application of in-place randomization}
}
@online{Soot,
  title         = {Soot},
  url           = {http://soot-oss.github.io/soot/},
  urldate       = {2025-11-18},
  abstract      = {Soot - A framework for analyzing and transforming Java and Android applications},
  organization  = {Soot}
}
@inproceedings{Sotirov2007,
  title         = {{Heap Feng Shui in JavaScript}},
  author        = {Sotirov, Alexander},
  year          = 2007,
  booktitle     = {Black Hat Europe}
}
@article{sparckjones1972,
  title         = {A {{Statistical Interpretation}} of {{Term Specificity}} and Its {{Applications}} in {{Retrieval}}},
  author        = {Sparck Jones, Karen},
  volume        = 28,
  number        = 1,
  pages         = {11--21},
  doi           = {10.1108/eb026526},
  issn          = {0022-0418},
  date          = {1972-01-01},
  journaltitle  = {Journal of Documentation},
  shortjournal  = {Journal of Documentation},
  abstract      = {The exhaustivity of document descriptions and the specificity of index terms are usually regarded as independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test collections showing in particular that frequently-occurring terms are required for good overall performance. It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms. Results for the test collections show that considerable improvements in performance are obtained with this very simple procedure.}
}
@online{Speedometer,
  title         = {Speedometer Benchmark},
  year          = 2022,
  url           = {https://browserbench.org/Speedometer2.0/}
}
@inproceedings{Stanley2013,
  title         = {Improved kernel security through memory layout randomization},
  author        = {Stanley, Dannie M. and Xu, Dongyan and Spafford, Eugene H.},
  year          = 2013,
  month         = dec,
  booktitle     = {2013 {IEEE} 32nd {International} {Performance} {Computing} and {Communications} {Conference} ({IPCCC})},
  publisher     = {IEEE},
  address       = {San Diego, CA, USA},
  pages         = {1--10},
  doi           = {10.1109/PCCC.2013.6742768},
  isbn          = {978-1-4799-3214-6 978-1-4799-3213-9}
}
@inproceedings{sui2016,
  title         = {{{SVF}}: Interprocedural Static Value-Flow Analysis in {{LLVM}}},
  shorttitle    = {{SVF}},
  author        = {Sui, Yulei and Xue, Jingling},
  booktitle     = {Proceedings of the 25th {{International Conference}} on {{Compiler Construction}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{CC}} '16},
  pages         = {265--266},
  doi           = {10.1145/2892208.2892235},
  isbn          = {978-1-4503-4241-4},
  date          = {2016-03-17},
  abstract      = {This paper presents SVF, a tool that enables scalable and precise interprocedural Static Value-Flow analysis for C programs by leveraging recent advances in sparse analysis. SVF, which is fully implemented in LLVM, allows value-flow construction and pointer analysis to be performed in an iterative manner, thereby providing increasingly improved precision for both. SVF accepts points- to information generated by any pointer analysis (e.g., Andersen's analysis) and constructs an interprocedural memory SSA form, in which the def-use chains of both top-level and address-taken variables are captured. Such value-flows can be subsequently exploited to support various forms of program analysis or enable more precise pointer analysis (e.g., flow-sensitive analysis) to be performed sparsely. By dividing a pointer analysis into three loosely coupled components: Graph, Rules and Solver, SVF provides an extensible interface for users to write their own solutions easily. SVF is publicly available at http://unsw-corg.github.io/SVF.}
}
@inproceedings{Sun2018,
  title         = {Perses: Syntax-Guided Program Reduction},
  shorttitle    = {Perses},
  author        = {Sun, Chengnian and Li, Yuanbo and Zhang, Qirun and Gu, Tianxiao and Su, Zhendong},
  year          = 2018,
  month         = may,
  booktitle     = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  series        = {{{ICSE}} '18},
  pages         = {361--371},
  doi           = {10.1145/3180155.3180236},
  isbn          = {978-1-4503-5638-1},
  abstract      = {Given a program P that exhibits a certain property {$\Psi$} (e.g., a C program that crashes GCC when it is being compiled), the goal of program reduction is to minimize P to a smaller variant P{$\prime$} that still exhibits the same property, i.e., {$\Psi$}(P{$\prime$}). Program reduction is important and widely demanded for testing and debugging. For example, all compiler/interpreter development projects need effective program reduction to minimize failure-inducing test programs to ease debugging. However, state-of-the-art program reduction techniques --- notably Delta Debugging (DD), Hierarchical Delta Debugging (HDD), and C-Reduce --- do not perform well in terms of speed (reduction time) and quality (size of reduced programs), or are highly customized for certain languages and thus lack generality. This paper presents Perses, a novel framework for effective, efficient, and general program reduction. The key insight is to exploit, in a general manner, the formal syntax of the programs under reduction and ensure that each reduction step considers only smaller, syntactically valid variants to avoid futile efforts on syntactically invalid variants. Our framework supports not only deletion (as for DD and HDD), but also general, effective program transformations. We have designed and implemented Perses, and evaluated it for two language settings: C and Java. Our evaluation results on 20 C programs triggering bugs in GCC and Clang demonstrate Perses's strong practicality compared to the state-of-the-art: (1) smaller size --- Perses's results are respectively 2\% and 45\% in size of those from DD and HDD; and (2) shorter reduction time --- Perses takes 23\% and 47\% time taken by DD and HDD respectively. Even when compared to the highly customized and optimized C-Reduce for C/C++, Perses takes only 38-60\% reduction time.}
}
@inproceedings{Szekeres,
  title         = {{{SoK}}: {{Eternal War}} in {{Memory}}},
  author        = {Szekeres, L{\'a}szl{\'o} and Payer, Mathias and {Tao Wei} and Song, Dawn},
  booktitle     = {2013 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  publisher     = {IEEE},
  pages         = {48--62},
  doi           = {10.1109/SP.2013.13},
  isbn          = {978-0-7695-4977-4},
  issn          = 10816011,
  date          = {2013-05},
  abstract      = {Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corrup- tion attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms imple- menting stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps de- signers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency.We identify some open research problems, and provide suggestions on improving the adoption of newer techniques.}
}
@inproceedings{Tang2015,
  title         = {{Heisenbyte}},
  author        = {Tang, Adrian and Sethumadhavan, Simha and Stolfo, Salvatore},
  year          = 2015,
  booktitle     = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security - CCS '15},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  volume        = {2015-Octob},
  pages         = {256--267},
  doi           = {10.1145/2810103.2813685},
  isbn          = 9781450338325,
  issn          = 15437221,
  abstract      = {Vulnerabilities that disclose executable memory pages en-able a new class of powerful code reuse attacks that build the attack payload at runtime. In this work, we present Heisenbyte, a system to protect against memory disclosure attacks. Central to Heisenbyte is the concept of destructive code reads â€“ code is garbled right after it is read. Gar-bling the code after reading it takes away from the attacker her ability to leverage memory disclosure bugs in both static code and dynamically generated just-in-time code. By lever-aging existing virtualization support, Heisenbyte's novel use of destructive code reads sidesteps the problem of incom-plete binary disassembly in binaries, and extends protection to close-sourced COTS binaries, which are two major limi-tations of prior solutions against memory disclosure vulner-abilities. Our experiments demonstrate that Heisenbyte can tolerate some degree of imperfect static analysis in disas-sembled binaries, while effectively thwarting dynamic code reuse exploits in both static and JIT code, at a modest 1.8{\%} average runtime overhead due to virtualization and 16.5{\%} average overhead due to the destructive code reads.}
}
@inproceedings{Tice2014,
  title         = {{Enforcing Forward-Edge Control-Flow Integrity in {GCC} \& {LLVM}}},
  author        = {Tice, Caroline and Roeder, Tom and Collingbourne, Peter and Checkoway, Stephen and Erlingsson, {\'{U}}lfar and Lozano, Luis and Pike, Geoff},
  year          = 2014,
  month         = aug,
  booktitle     = {23rd {USENIX} Security Symposium ({USENIX} Security 14)},
  publisher     = {{USENIX} Association},
  address       = {San Diego, CA},
  pages         = {941--955},
  isbn          = {978-1-931971-15-7},
  abstract      = {Constraining dynamic control transfers is a common tech-nique for mitigating software vulnerabilities. This de-fense has been widely and successfully used to protect return addresses and stack data; hence, current attacks instead typically corrupt vtable and function pointers to subvert a forward edge (an indirect jump or call) in the control-flow graph. Forward edges can be protected us-ing Control-Flow Integrity (CFI) but, to date, CFI im-plementations have been research prototypes, based on impractical assumptions or ad hoc, heuristic techniques. To be widely adoptable, CFI mechanisms must be inte-grated into production compilers and be compatible with software-engineering aspects such as incremental compi-lation and dynamic libraries. This paper presents implementations of fine-grained, forward-edge CFI enforcement and analysis for GCC and LLVM that meet the above requirements. An analysis and evaluation of the security, performance, and resource consumption of these mechanisms applied to the SPEC CPU2006 benchmarks and common benchmarks for the Chromium web browser show the practicality of our ap-proach: these fine-grained CFI mechanisms have signif-icantly lower overhead than recent academic CFI proto-types. Implementing CFI in industrial compiler frame-works has also led to insights into design tradeoffs and practical challenges, such as dynamic loading.}
}
@misc{tiobe2025,
  title         = {{TIOBE} Index for January 2025},
  author        = {{TIOBE Software BV}},
  year          = 2025,
  howpublished  = {\url{https://www.tiobe.com/tiobe-index/}}
}
@online{Turner2018,
  title         = {{Retpoline: a software construct for preventing branch-targetinjection.}},
  author        = {Turner, Paul},
  year          = 2018,
  url           = {https://support.google.com/faqs/answer/7625886}
}
@inproceedings{Vanbulck2020,
  title         = {{{LVI}}: {{Hijacking Transient Execution}} through {{Microarchitectural Load Value Injection}}},
  author        = {Van Bulck, Jo and Moghimi, Daniel and Schwarz, Michael and Lippi, Moritz and Minkin, Marina and Genkin, Daniel and Yarom, Yuval and Sunar, Berk and Gruss, Daniel and Piessens, Frank},
  booktitle     = {2020 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  publisher     = {IEEE},
  volume        = {2020-May},
  pages         = {54--72},
  doi           = {10.1109/SP40000.2020.00089},
  isbn          = {978-1-7281-3497-0},
  issn          = 10816011,
  date          = {2020-05},
  abstract      = {The recent Spectre attack first showed how to inject incorrect branch targets into a victim domain by poisoning microarchitectural branch prediction history. In this paper, we generalize injection-based methodologies to the memory hierarchy by directly injecting incorrect, attacker-controlled values into a victim's transient execution. We propose Load Value Injection (LVI) as an innovative technique to reversely exploit Meltdown-type microarchitectural data leakage. LVI abuses that faulting or assisted loads, executed by a legitimate victim program, may transiently use dummy values or poisoned data from various microarchitectural buffers, before eventually being re-issued by the processor. We show how LVI gadgets allow to expose victim secrets and hijack transient control flow. We practically demonstrate LVI in several proof-of-concept attacks against Intel SGX enclaves, and we discuss implications for traditional user process and kernel isolation. State-of-the-art Meltdown and Spectre defenses, including widespread silicon-level and microcode mitigations, are orthogonal to our novel LVI techniques. LVI drastically widens the spectrum of incorrect transient paths. Fully mitigating our attacks requires serializing the processor pipeline with lfence instructions after possibly every memory load. Additionally and even worse, due to implicit loads, certain instructions have to be blacklisted, including the ubiquitous x86 ret instruction. Intel plans compiler and assembler-based full mitigations that will allow at least SGX enclave programs to remain secure on LVI-vulnerable systems. Depending on the application and optimization strategy, we observe extensive overheads of factor 2 to 19 for prototype implementations of the full mitigation.}
}
@inproceedings{vanderkouwe2017,
  title         = {{{DangSan}}: {{Scalable Use-after-free Detection}}},
  shorttitle    = {{DangSan}},
  author        = {Van Der Kouwe, Erik and Nigade, Vinod and Giuffrida, Cristiano},
  booktitle     = {Proceedings of the {{Twelfth European Conference}} on {{Computer Systems}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{EuroSys}} '17},
  pages         = {405--419},
  doi           = {10.1145/3064176.3064211},
  isbn          = {978-1-4503-4938-3},
  date          = {2017-04-23},
  abstract      = {Use-after-free vulnerabilities due to dangling pointers are an important and growing threat to systems security. While various solutions exist to address this problem, none of them is sufficiently practical for real-world adoption. Some can be bypassed by attackers, others cannot support complex multithreaded applications prone to dangling pointers, and the remainder have prohibitively high overhead. One major source of overhead is the need to synchronize threads on every pointer write due to pointer tracking. In this paper, we present DangSan, a use-after-free detection system that scales efficiently to large numbers of pointer writes as well as to many concurrent threads. To significantly reduce the overhead of existing solutions, we observe that pointer tracking is write-intensive but requires very few reads. Moreover, there is no need for strong consistency guarantees as inconsistencies can be reconciled at read (i.e., object deallocation) time. Building on these intuitions, DangSan's design mimics that of log-structured file systems, which are ideally suited for similar workloads. Our results show that DangSan can run heavily multithreaded applications, while introducing only half the overhead of previous multithreaded use-after-free detectors.}
}
@inproceedings{vanderKouwe2019,
  title         = {{SoK: Benchmarking Flaws in Systems Security}},
  author        = {Van Der Kouwe, Erik and Heiser, Gernot and Andriesse, Dennis and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2019,
  month         = jun,
  booktitle     = {2019 IEEE European Symposium on Security and Privacy (EuroS{\&}P)},
  publisher     = {IEEE},
  pages         = {310--325},
  doi           = {10.1109/EuroSP.2019.00031},
  isbn          = {978-1-7281-1148-3}
}
@inproceedings{VanderVeen2015,
  title         = {{Practical context-sensitive CFI}},
  author        = {{Van Der Veen}, Victor and Andriesse, Dennis and G{\"{o}}kta{\c s}, Enes and Gras, Ben and Sambuc, Lionel and Slowinska, Asia and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2015,
  booktitle     = {Proceedings of the ACM Conference on Computer and Communications Security},
  volume        = {2015-Octob},
  pages         = {927--940},
  doi           = {10.1145/2810103.2813673},
  isbn          = 9781450338325,
  issn          = 15437221,
  abstract      = {Current Control-Flow Integrity (CFI) implementations track control edges individually, insensitive to the context of preceding edges. Recent work demonstrates that this leaves sufficient leeway for powerful ROP attacks. Context-sensitive CFI, which can provide enhanced security, is widely considered impractical for real-world adoption. Our work shows that Context-sensitive CFI (CCFI) for both the backward and forward edge can be implemented efficiently on commodity hardware. We present PathArmor, a binary-level CCFI implementation which tracks paths to sensitive program states, and defines the set of valid control edges within the state context to yield higher precision than existing CFI implementations. Even with simple context-sensitive policies, PathArmor yields significantly stronger CFI invariants than context-insensitive CFI, with similar performance.}
}
@inproceedings{VanderVeen2015b,
  title         = {{A Tough Call: Mitigating Advanced Code-Reuse Attacks at the Binary Level}},
  author        = {van der Veen, Victor and G{\"{o}}kta{\c s}, Enes and Contag, Moritz and Pawoloski, Andre and Chen, Xi and Rawat, Sanjay and Bos, Herbert and Holz, Thorsten and Athanasopoulos, Elias and Giuffrida, Cristiano},
  year          = 2016,
  month         = may,
  booktitle     = {2016 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  pages         = {934--953},
  doi           = {10.1109/SP.2016.60},
  isbn          = {978-1-5090-0824-7},
  abstract      = {Current binary-level Control-Flow Integrity (CFI) techniques are weak in determining the set of valid targets for indirect control flow transfers on the forward edge. In particular, the lack of source code forces existing techniques to resort to a conservative address-taken policy that over-approximates this set. In contrast, source-level solutions can accurately infer the targets of indirect callsites and thus detect malicious control-flow transfers more precisely. Given that source code is not always available, however, offering similar quality of protection at the binary level is important, but, unquestionably, more challenging than ever: recent work demonstrates powerful attacks, such as Counterfeit Object-oriented Programming (COOP), which made the community believe that protecting software against control-flow diversion attacks at the binary level is impossible. In this paper, we propose binary-level analysis techniques to significantly reduce the number of possible targets for indirect callsites. More specifically, we reconstruct a conservative approximation of target function prototypes by means of use-def analysis at possible callees. We then couple this with liveness analysis at each indirect callsite to derive a many-to-many relationship between callsites and target callees with a much higher precision compared to prior binary-level solutions. Experimental results on popular server programs and on SPEC CPU2006 show that TypeArmor, a prototype implementation of our approach, is efficient-with a runtime overhead of less than 3{\%}. Furthermore, we evaluate to what extent TypeArmor can mitigate COOP and other advanced attacks and show that our approach can significantly reduce the number of targets on the forward edge. Moreover, we show that TypeArmor breaks published COOP exploits, providing concrete evidence that strict binary-level CFI can still mitigate advanced attacks, despite the absence of source information or C++ semantics.}
}
@inproceedings{VanSchaik2019,
  title         = {{RIDL: Rogue In-Flight Data Load}},
  author        = {van Schaik, Stephan and Milburn, Alyssa and Osterlund, Sebastian and Frigo, Pietro and Maisuradze, Giorgi and Razavi, Kaveh and Bos, Herbert and Giuffrida, Cristiano},
  year          = 2019,
  month         = may,
  booktitle     = {2019 IEEE Symposium on Security and Privacy (SP)},
  publisher     = {IEEE},
  volume        = {2019-May},
  pages         = {88--105},
  doi           = {10.1109/SP.2019.00087},
  isbn          = {978-1-5386-6660-9},
  issn          = 10816011,
  abstract      = {We present Rogue In-flight Data Load (RIDL), a new class of speculative unprivileged and constrained attacks to leak arbitrary data across address spaces and privilege boundaries (e.g., process, kernel, SGX, and even CPU-internal operations). Our reverse engineering efforts show such vulnerabilities originate from a variety of micro-optimizations pervasive in commodity (Intel) processors, which cause the CPU to speculatively serve loads using extraneous CPU-internal in-flight data (e.g., in the line fill buffers). Contrary to other state-of-the-art speculative execution attacks, such as Spectre, Meltdown and Foreshadow, RIDL can leak this arbitrary in-flight data with no assumptions on the state of the caches or translation data structures controlled by privileged software. The implications are worrisome. First, RIDL attacks can be implemented even from linear execution with no invalid page faults, eliminating the need for exception suppression mechanisms and enabling system-wide attacks from arbitrary unprivileged code (including JavaScript in the browser). To exemplify such attacks, we build a number of practical exploits that leak sensitive information from victim processes, virtual machines, kernel, SGX and CPU-internal components. Second, and perhaps more importantly, RIDL bypasses all existing 'spot' mitigations in software (e.g., KPTI, PTE inversion) and hardware (e.g., speculative store bypass disable) and cannot easily be mitigated even by more heavyweight defenses (e.g., L1D flushing or disabling SMT). RIDL questions the sustainability of a per-variant, spot mitigation strategy and suggests more fundamental mitigations are needed to contain ever-emerging speculative execution attacks.}
}
@article{vargha2000,
  title         = {A {{Critique}} and {{Improvement}} of the "{{CL}}" {{Common Language Effect Size Statistics}} of {{McGraw}} and {{Wong}}},
  author        = {Vargha, Andr\'{a}s and Delaney, Harold D.},
  publisher     = {{American Educational Research Association, Sage Publications, Inc., American Statistical Association}},
  volume        = 25,
  number        = 2,
  pages         = {101--132},
  doi           = {10.2307/1165329},
  issn          = {1076-9986},
  date          = 2000,
  journaltitle  = {Journal of Educational and Behavioral Statistics},
  eprint        = 1165329,
  eprinttype    = {jstor},
  abstract      = {McGraw and Wong (1992) described an appealing index of effect size, called "CL", which measures the difference between two populations in terms of the probability that a score sampled at random from the first population will be greater than a score sampled at random from the second. McGraw and Wong introduced this "common language effect size statistic" for normal distributions and then proposed an approximate estimation for any continuous distribution. In addition, they generalized "CL" to the n-group case, the correlated samples case, and the discrete values case. In the current paper a different generalization of "CL" called the A measure of stochastic superiority, is proposed, which may be directly applied for any discrete or continuous variable that is at least ordinally scaled. Exact methods for point and interval estimation as well as the significance tests of the A = .5 hypothesis are provided. New generalizations of "CL" are provided for the multi-group and correlated samples cases.}
}
@inproceedings{Veggalam2016,
  title         = {{{IFuzzer}}: {{An Evolutionary Interpreter Fuzzer Using Genetic Programming}}},
  shorttitle    = {{IFuzzer}},
  author        = {Veggalam, Spandan and Rawat, Sanjay and Haller, Istvan and Bos, Herbert},
  year          = 2016,
  booktitle     = {Computer {{Security}} -- {{ESORICS}} 2016},
  publisher     = {Springer International Publishing},
  address       = {Cham},
  pages         = {581--601},
  doi           = {10.1007/978-3-319-45744-4_29},
  isbn          = {978-3-319-45744-4},
  editor        = {Askoxylakis, Ioannis and Ioannidis, Sotiris and Katsikas, Sokratis and Meadows, Catherine},
  abstract      = {We present an automated evolutionary fuzzing technique to find bugs in JavaScript interpreters. Fuzzing is an automated black box testing technique used for finding security vulnerabilities in the software by providing random data as input. However, in the case of an interpreter, fuzzing is challenging because the inputs are piece of codes that should be syntactically/semantically valid to pass the interpreter's elementary checks. On the other hand, the fuzzed input should also be uncommon enough to trigger exceptional behavior in the interpreter, such as crashes, memory leaks and failing assertions. In our approach, we use evolutionary computing techniques, specifically genetic programming, to guide the fuzzer in generating uncommon input code fragments that may trigger exceptional behavior in the interpreter. We implement a prototype named IFuzzer to evaluate our technique on real-world examples. IFuzzer uses the language grammar to generate valid inputs. We applied IFuzzer first on an older version of the JavaScript interpreter of Mozilla (to allow for a fair comparison to existing work) and found 40 bugs, of which 12 were exploitable. On subsequently targeting the latest builds of the interpreter, IFuzzer found 17 bugs, of which four were security bugs.}
}
@inproceedings{Volckaert2016,
  title         = {{Secure and Efficient Application Monitoring and Replication}},
  author        = {Volckaert, Stijn and Coppens, Bart and Voulimeneas, Alexios and Homescu, Andrei and Larsen, Per and Sutter, Bjorn De and Franz, Michael},
  year          = 2016,
  month         = jun,
  booktitle     = {2016 USENIX Annual Technical Conference (USENIX ATC 16)},
  publisher     = {USENIX Association},
  address       = {Denver, CO},
  pages         = {167--179},
  isbn          = {978-1-931971-30-0}
}
@incollection{Voulimeneas2020,
  title         = {{Distributed Heterogeneous N-Variant Execution}},
  author        = {Voulimeneas, Alexios and Song, Dokyung and Parzefall, Fabian and Na, Yeoul and Larsen, Per and Franz, Michael and Volckaert, Stijn},
  year          = 2020,
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher     = {Springer},
  volume        = {12223 LNCS},
  pages         = {217--237},
  doi           = {10.1007/978-3-030-52683-2{\_}11},
  isbn          = 9783030526825,
  issn          = 16113349
}
@inproceedings{Wahbe1993,
  title         = {{Efficient software-based fault isolation}},
  author        = {Wahbe, Robert and Lucco, Steven and Anderson, Thomas E and Graham, Susan L},
  year          = 1993,
  booktitle     = {Proceedings of the fourteenth ACM symposium on Operating systems principles - SOSP '93},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  series        = {SOSP '93},
  pages         = {203--216},
  doi           = {10.1145/168619.168635},
  isbn          = {0897916328},
  abstract      = {One way to provide fault isolation among cooperating software modules is to place each in its own address space. However, for tightly-coupled modules, this solution incurs prohibitive context switch overhead. In this paper, we present a software approach to implementing fault isolation within a single address space.Our approach has two parts. First, we load the code and data for a distrusted module into its own fault do main, a logically separate portion of the application's address space. Second, we modify the object code of a distrusted module to prevent it from writing or jumping to an address outside its fault domain. Both these software operations are portable and programming language independent.Our approach poses a tradeoff relative to hardware fault isolation: substantially faster communication between fault domains, at a cost of slightly increased execution time for distrusted modules. We demonstrate that for frequently communicating modules, implementing fault isolation in software rather than hardware can substantially improve end-to-end application performance.}
}
@inproceedings{wang2012,
  title         = {Undefined Behavior: What Happened to My Code?},
  shorttitle    = {Undefined Behavior},
  author        = {Wang, Xi and Chen, Haogang and Cheung, Alvin and Jia, Zhihao and Zeldovich, Nickolai and Kaashoek, M. Frans},
  booktitle     = {Proceedings of the {{Asia-Pacific Workshop}} on {{Systems}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{APSYS}} '12},
  pages         = {1--7},
  doi           = {10.1145/2349896.2349905},
  isbn          = {978-1-4503-1669-9},
  date          = {2012-07-23},
  abstract      = {System programming languages such as C grant compiler writers freedom to generate efficient code for a specific instruction set by defining certain language constructs as undefined behavior. Unfortunately, the rules for what is undefined behavior are subtle and programmers make mistakes that sometimes lead to security vulnerabilities. This position paper argues that the research community should help address the problems that arise from undefined behavior, and not dismiss them as esoteric C implementation issues. We show that these errors do happen in real-world systems, that the issues are tricky, and that current practices to address the issues are insufficient.}
}
@article{wang2018a,
  title         = {Layered Object-Oriented Programming: {{Advanced VTable}} Reuse Attacks on Binary-Level Defense},
  author        = {Wang, Chenyu and Chen, Bihuan and Liu, Yang and Wu, Hongjun},
  volume        = 14,
  number        = 3,
  doi           = {10.1109/TIFS.2018.2855648},
  issn          = 15566013,
  date          = 2018,
  journaltitle  = {IEEE Transactions on Information Forensics and Security},
  abstract      = {Vtable reuse attack, as a novel type of code reuse attacks, is introduced to bypass most binary-level control flow integrity enforcement and vtable integrity enforcement. So far, two binary-level defenses (TypeArmor and vfGuard) are proposed to defend against vtable reuse attacks. Both techniques use semantic information as the control flow integrity enforcement policy, i.e., TypeArmor and vfGuard utilize argument register count and dispatch offset at virtual callsite as the signature to check the validity of target functions, respectively. In this paper, we propose layered object-oriented programming (LOOP), an advanced vtable reuse attack, to show that the coarse-grained control flow integrity strategies are still vulnerable to vtable reuse attacks. In LOOP, we introduce argument expansion gadgets and transfer gadgets to, respectively, bypass TypeArmor and vfGuard. We generalize the characteristics of both gadgets and develop a tool to discover them at the binary level. We demonstrated that under the protection of TypeArmor and vfGuard, Firefox, Adobe Flash Player, and Internet Explorer are all vulnerable to LOOP attacks. Furthermore, we show the availability of argument expansion gadgets and transfer gadgets in common software or libraries.}
}
@inproceedings{Wang2019,
  title         = {Be {{Sensitive}} and {{Collaborative}}: {{Analyzing Impact}} of {{Coverage Metrics}} in {{Greybox Fuzzing}}},
  shorttitle    = {Be {{Sensitive}} and {{Collaborative}}},
  author        = {Wang, Jinghan and Duan, Yue and Song, Wei and Yin, Heng and Song, Chengyu},
  year          = 2019,
  booktitle     = {22nd {{International Symposium}} on {{Research}} in {{Attacks}}, {{Intrusions}} and {{Defenses}} ({{RAID}} 2019)},
  pages         = {1--15},
  isbn          = {978-1-939133-07-6}
}
@inproceedings{Wang2023,
  title         = {{{FuzzJIT}}: {{Oracle-Enhanced Fuzzing}} for {{JavaScript Engine JIT Compiler}}},
  author        = {Wang, Junjie and Zhang, Zhiyi and Liu, Shuang and Du, Xiaoning and Chen, Junjie},
  year          = 2023,
  booktitle     = {32nd {{USENIX Security Symposium}} ({{USENIX Security}} 23)},
  abstract      = {We present a novel fuzzing technique, FuzzJIT, for exposing JIT compiler bugs in JavaScript engines, based on our insight that JIT compilers shall only speed up the execution but never change the execution result of JavaScript code. FuzzJIT can activate the JIT compiler for every test case and acutely capture any execution discrepancy caused by JIT compilers. The key to success is the design of an input wrapping template, which proactively activates the JIT compiler and makes the generated samples oracle-aware themselves and the oracle is tested during execution spontaneously. We also design a set of mutation strategies to emphasize program elements promising in revealing JIT compiler bugs. FuzzJIT drills to JIT compilers and at the same time retains the high efficiency of fuzzing. We have implemented the design and applied the prototype to find new JIT compiler bugs in four mainstream JavaScript engines. In one month, ten, five, two, and 16 new bugs are exposed in JavaScriptCore, V8, SpiderMonkey, and ChakraCore, respectively, with three demonstrated exploitable.}
}
@inproceedings{Wartell2012,
  title         = {Binary Stirring},
  author        = {Wartell, Richard and Mohan, Vishwath and Hamlen, Kevin W and Lin, Zhiqiang},
  booktitle     = {Proceedings of the 2012 {{ACM}} Conference on {{Computer}} and Communications Security - {{CCS}} '12},
  location      = {New York, New York, USA},
  publisher     = {ACM Press},
  pages         = 157,
  doi           = {10.1145/2382196.2382216},
  isbn          = {978-1-4503-1651-4},
  date          = 2012,
  abstract      = {Unlike library code, whose instruction addresses can be randomized by address space layout randomization (ASLR), application binary code often has static instruction addresses. Attackers can exploit this limitation to craft robust shell codes for such applications, as demonstrated by a recent attack that reuses instruction gadgets from the static binary code of victim applications. This paper introduces binary stirring, a new technique that imbues x86 native code with the ability to self-randomize its instruction addresses each time it is launched. The input to STIR is only the application binary code without any source code, debug symbols, or relocation information. The output is a new binary whose basic block addresses are dynamically determined at load-time. Therefore, even if an attacker can find code gadgets in one instance of the binary, the instruction addresses in other instances are unpredictable. An array of binary transformation techniques enable STIR to transparently protect large, realistic applications that cannot be perfectly disassembled due to computed jumps, code-data interleaving, OS callbacks, dynamic linking and a variety of other difficult binary features. Evaluation of STIR for both Windows and Linux platforms shows that stirring introduces about 1.6\% overhead on average to application runtimes.}
}
@online{Webkit,
  title         = {{WebKit}},
  year          = 2022,
  url           = {https://webkit.org/}
}
@inproceedings{Werner2016,
  title         = {{No-Execute-After-Read}},
  author        = {Werner, Jan and Baltas, George and Dallara, Rob and Otterness, Nathan and Snow, Kevin Z and Monrose, Fabian and Polychronakis, Michalis},
  year          = 2016,
  booktitle     = {Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security - ASIA CCS '16},
  publisher     = {ACM Press},
  address       = {New York, New York, USA},
  pages         = {35--46},
  doi           = {10.1145/2897845.2897891},
  isbn          = 9781450342339,
  abstract      = {Memory disclosure vulnerabilities enable an adversary to successfully mount arbitrary code execution attacks against applications via so-called just-in-time code reuse attacks, even when those applications are fortified with fine-grained address space layout random-ization. This attack paradigm requires the adversary to first read the contents of randomized application code, then construct a code reuse payload using that knowledge. In this paper, we show that the recently proposed Execute-no-Read (XnR) technique fails to prevent just-in-time code reuse attacks. Next, we introduce the design and implementation of a novel memory permission primitive, dubbed No-Execute-After-Read (NEAR), that foregoes the problems of XnR and provides strong security guarantees against just-in-time attacks in commodity binaries. Specifically, NEAR allows all code to be disclosed, but prevents any disclosed code from subsequently being executed, thus thwarting just-in-time code reuse. At the same time, commodity binaries with mixed code and data regions still operate correctly, as legitimate data is still readable. To demonstrate the practicality and portability of our approach we implemented prototypes for both Linux and Android on the ARMv8 architecture, as well as a prototype that protects unmodified Mi-crosoft Windows executables and dynamically linked libraries. In addition, our evaluation on the SPEC2006 benchmark demonstrates that our prototype has negligible runtime overhead, making it suitable for practical deployment.}
}
@inproceedings{Wikner2022,
  title         = {{{RETBLEED}}: {{Arbitrary Speculative Code Execution}} with {{Return Instructions}}},
  shorttitle    = {{RETBLEED}},
  author        = {Wikner, Johannes and Razavi, Kaveh},
  pages         = {3825--3842},
  isbn          = {978-1-939133-31-1},
  date          = 2022,
  eventtitle    = {31st {{USENIX Security Symposium}} ({{USENIX Security}} 22)}
}
@inproceedings{WilliamsKing2016,
  title         = {{Shuffler: Fast and Deployable Continuous Code Re-Randomization}},
  author        = {Williams-King, David and Gobieski, Graham and Williams-King, Kent and Blake, James P and Yuan, Xinhao and Colp, Patrick and Zheng, Michelle and Kemerlis, Vasileios P and Yang, Junfeng and Aiello, William},
  year          = 2016,
  month         = nov,
  booktitle     = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
  publisher     = {{USENIX} Association},
  address       = {Savannah, GA},
  pages         = {367--382},
  isbn          = {978-1-931971-33-1},
  abstract      = {While code injection attacks have been virtually eliminated on modern systems, programs today remain vulnerable to code reuse attacks. Particularly pernicious are Just-In-Time ROP (JIT-ROP) techniques, where an attacker uses a memory disclosure vulnerability to discover code gadgets at runtime. We designed a code-reuse defense, called Shuffler, which continuously re-randomizes code locations on the order of milliseconds, introducing a real-time deadline on the attacker. This deadline makes it extremely difficult to form a complete exploit, particularly against server programs that often sit tens of milliseconds away from attacker machines. Shuffler focuses on being fast, self-hosting, and nonintrusive to the end user. Specifically, for speed, Shuffler randomizes code asynchronously in a separate thread and atomically switches from one code copy to the next. For security, Shuffler adopts an ``egalitarian'' principle and randomizes itself the same way it does the target. Lastly, to deploy Shuffler, no source, kernel, compiler, or hardware modifications are necessary. Evaluation shows that Shuffler defends against all known forms of code reuse, including ROP, direct JITROP, indirect JIT-ROP, and Blind ROP. We observed 14.9{\%} overhead on SPEC CPU when shuffling every 50 ms, and ran Shuffler on real-world applications such as Nginx. We showed that the shuffled Nginx scales up to 24 worker processes on 12 cores.},
  mendeley-tags = {read}
}
@inproceedings{WilsonLam1995,
  title         = {Efficient Context-Sensitive Pointer Analysis for C Programs},
  author        = {Robert P. Wilson and Monica S. Lam},
  year          = 1995,
  booktitle     = {Proceedings of the ACM SIGPLAN 1995 Conference on Programming Language Design and Implementation},
  publisher     = {ACM},
  series        = {PLDI '95},
  pages         = {1--12}
}
@article{wolff2026,
  title         = {Fuzzing: {{On Benchmarking Outcome}} as a {{Function}} of {{Benchmark Properties}}},
  shorttitle    = {Fuzzing},
  author        = {Wolff, Dylan and B\"{o}hme, Marcel and Roychoudhury, Abhik},
  volume        = 35,
  number        = 2,
  pages         = {49:1--49:26},
  doi           = {10.1145/3732936},
  issn          = {1049-331X},
  date          = {2026-01-21},
  journaltitle  = {ACM Trans. Softw. Eng. Methodol.},
  abstract      = {In a typical experimental design in fuzzing, we would run two or more fuzzers on an appropriate set of benchmark programs plus seed corpora and consider their ranking in terms of code coverage or bugs found as outcomes. However, the specific characteristics of the benchmark setup clearly can have some impact on the benchmark outcome. If the programs were larger, or these initial seeds were chosen differently, the same fuzzers may be ranked differently; the benchmark outcome would change. In this article, we explore two methodologies to quantify the impact of the specific properties on the benchmarking outcome. This allows us to report the benchmarking outcome counter-factually, e.g., ``If the benchmark had larger programs, this fuzzer would outperform all others.'' Our first methodology is the controlled experiment to identify a causal relationship between a single property in isolation and the benchmarking outcome. The controlled experiment requires manually altering the fuzzer or system under test to vary that property while holding all other variables constant. By repeating this controlled experiment for multiple fuzzer implementations, we can gain detailed insights into the different effects this property has on various fuzzers. However, due to the large number of properties and the difficulty of realistically manipulating one property exactly, control may not always be practical or possible. Hence, our second methodology is randomization and non-parametric regression to identify the strength of the relationship between arbitrary benchmark properties (i.e., covariates) and outcome. Together, these two fundamental aspects of experimental design, control and randomization, can provide a comprehensive picture of the impact of various properties of the current benchmark on the fuzzer ranking. These analyses can be used to guide fuzzer developers towards areas of improvement in their tools and allow researchers to make more nuanced claims about fuzzer effectiveness. We instantiate each approach on a subset of properties suspected of impacting the relative effectiveness of fuzzers and quantify the effects of these properties on the evaluation outcome. In doing so, we identify multiple properties, such as the coverage of the initial seed-corpus and the program execution speed, which can have a statistically significant effect on the relative effectiveness of fuzzers.}
}
@inproceedings{Wu2023,
  title         = {{{JITfuzz}}: {{Coverage-guided Fuzzing}} for {{JVM Just-in-Time Compilers}}},
  shorttitle    = {{JITfuzz}},
  author        = {Wu, Mingyuan and Lu, Minghai and Cui, Heming and Chen, Junjie and Zhang, Yuqun and Zhang, Lingming},
  year          = 2023,
  month         = may,
  booktitle     = {2023 {{IEEE}}/{{ACM}} 45th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  publisher     = {IEEE},
  address       = {Melbourne, Australia},
  pages         = {56--68},
  doi           = {10.1109/ICSE48619.2023.00017},
  isbn          = {978-1-66545-701-9},
  copyright     = {https://doi.org/10.15223/policy-029}
}
@inproceedings{wuerthinger2013,
  title         = {One VM to Rule Them All},
  author        = {Wuerthinger, Thomas and Woess, Andreas and Stadler, Lukas and Duboscq, Gilles and Simon, Doug and Wimmer, Christian and Wolczko, Mario},
  year          = 2013,
  booktitle     = {Proceedings of the ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming \& Software (Onward!)}
}
@inproceedings{wurthinger2013,
  title         = {One {{VM}} to Rule Them All},
  author        = {W\"{u}rthinger, Thomas and Wimmer, Christian and W\"{o}\ss{}, Andreas and Stadler, Lukas and Duboscq, Gilles and Humer, Christian and Richards, Gregor and Simon, Doug and Wolczko, Mario},
  booktitle     = {Proceedings of the 2013 {{ACM}} International Symposium on {{New}} Ideas, New Paradigms, and Reflections on Programming \& Software},
  location      = {Indianapolis Indiana USA},
  publisher     = {ACM},
  pages         = {187--204},
  doi           = {10.1145/2509578.2509581},
  isbn          = {978-1-4503-2472-4},
  date          = {2013-10-29},
  eventtitle    = {{{SPLASH}} '13: {{Conference}} on {{Systems}}, {{Programming}}, and {{Applications}}: {{Software}} for {{Humanity}}}
}
@inproceedings{Xu2023,
  title         = {Silent {{Bugs Matter}}: {{A Study}} of {{Compiler-Introduced}} {{Security Bugs}}},
  shorttitle    = {Silent {{Bugs Matter}}},
  author        = {Xu, Jianhao and Lu, Kangjie and Du, Zhengjie and Ding, Zhu and Li, Linke and Wu, Qiushi and Payer, Mathias and Mao, Bing},
  year          = 2023,
  booktitle     = {32nd {{USENIX Security Symposium}} ({{USENIX Security}} 23)},
  pages         = {3655--3672},
  isbn          = {978-1-939133-37-3}
}
@inproceedings{xu2023a,
  title         = {{{WarpAttack}}: {{Bypassing CFI}} through {{Compiler-Introduced Double-Fetches}}},
  shorttitle    = {{WarpAttack}},
  author        = {Xu, Jianhao and Bartolomeo, Luca Di and Toffalini, Flavio and Mao, Bing and Payer, Mathias},
  booktitle     = {2023 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  pages         = {1271--1288},
  doi           = {10.1109/SP46215.2023.10179433},
  issn          = {2375-1207},
  date          = {2023-05},
  abstract      = {Code-reuse attacks are dangerous threats that attracted the attention of the security community for years. These attacks aim at corrupting important control-flow transfers for taking control of a process without injecting code. Nowadays, the combinations of multiple mitigations (e.g., ASLR, DEP, and CFI) drastically reduced this attack surface, making running code-reuse exploits more challenging.Unfortunately, security mitigations are combined with compiler optimizations, that do not distinguish between security-related and application code. Blindly deploying code optimizations over code-reuse mitigations may undermine their security guarantees. For instance, compilers may introduce double-fetch vulnerabilities that lead to concurrency issues such as Time-Of-Check to Time-Of-Use (TOCTTOU) attacks.In this work, we propose a new attack vector, called WarpAttack, that exploits compiler-introduced double-fetch optimizations to mount TOCTTOU attacks and bypass code-reuse mitigations. We study the mechanism underlying this attack and present a practical proof-of-concept exploit against the last version of Firefox. Additionally, we propose a lightweight analysis to locate vulnerable double-fetch code (with 3\% false positives) and conduct research over six popular applications, five operating systems, and four architectures (32 and 64 bits) to study the diffusion of this threat. Moreover, we study the implication of our attack against six CFI implementations. Finally, we investigate possible research lines for addressing this threat and propose practical solutions to be deployed in existing projects.},
  eventtitle    = {2023 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})}
}
@inproceedings{yang2011,
  title         = {Finding and Understanding Bugs in {{C}} Compilers},
  author        = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
  booktitle     = {Proceedings of the {ACM} {SIGPLAN} 2011 Conference on Programming Language Design and Implementation},
  location      = {{San Jose, CA, USA}},
  publisher     = {{Association for Computing Machinery}},
  doi           = {10.1145/1993498.1993532},
  isbn          = 9781450306637,
  date          = {2011-06-01}
}
@inproceedings{yasin2014,
  title         = {A {{Top-Down}} Method for Performance Analysis and Counters Architecture},
  author        = {Yasin, Ahmad},
  booktitle     = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})},
  pages         = {35--44},
  doi           = {10.1109/ISPASS.2014.6844459},
  date          = {2014-03},
  abstract      = {Optimizing an application's performance for a given microarchitecture has become painfully difficult. Increasing microarchitecture complexity, workload diversity, and the unmanageable volume of data produced by performance tools increase the optimization challenges. At the same time resource and time constraints get tougher with recently emerged segments. This further calls for accurate and prompt analysis methods. The insights from this method guide a proposal for a novel performance counters architecture that can determine the true bottlenecks of a general out-of-order processor. Unlike other approaches, our analysis method is low-cost and already featured in in-production systems - it requires just eight simple new performance events to be added to a traditional PMU. It is comprehensive - no restriction to predefined set of performance issues. It accounts for granular bottlenecks in super-scalar cores, missed by earlier approaches.},
  eventtitle    = {2014 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} and {{Software}} ({{ISPASS}})}
}
@misc{Zalewski2014,
  title         = {American {{Fuzzy Lop}} --- Technical Details},
  author        = {Zalewski, Micha\l{}},
  year          = 2014,
  url           = {https://lcamtuf.coredump.cx/afl/technical\%5Fdetails.txt},
  urldate       = {2024-06-18}
}
@misc{Zalewski2016,
  title         = {{AFL Whitepaper}},
  author        = {Zalewski, Micha\l{}},
  year          = 2016,
  url           = {https://lcamtuf.coredump.cx/afl/technical\%5Fdetails.txt},
  urldate       = {2024-06-18}
}
@inproceedings{zang2023,
  title         = {Compiler {{Testing}} Using {{Template Java Programs}}},
  author        = {Zang, Zhiqiang and Wiatrek, Nathan and Gligoric, Milos and Shi, August},
  booktitle     = {Proceedings of the 37th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  location      = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  series        = {{{ASE}} '22},
  pages         = {1--13},
  doi           = {10.1145/3551349.3556958},
  isbn          = {978-1-4503-9475-8},
  date          = {2023-01-05},
  abstract      = {We present JAttack, a framework that enables template-based testing for compilers. Using JAttack, a developer writes a template program that describes a set of programs to be generated and given as test inputs to a compiler. Such a framework enables developers to incorporate their domain knowledge on testing compilers, giving a basic program structure that allows for exploring complex programs that can trigger sophisticated compiler optimizations. A developer writes a template program in the host language (Java) that contains holes to be filled by JAttack. Each hole, written using a domain-specific language, constructs a node within an extended abstract syntax tree (eAST). An eAST node defines the search space for the hole, i.e., a set of expressions and values. JAttack generates programs by executing templates and filling each hole by randomly choosing expressions and values (available within the search space defined by the hole). Additionally, we introduce several optimizations to reduce JAttack's generation cost. While JAttack could be used to test various compiler features, we demonstrate its capabilities in helping test just-in-time (JIT) Java compilers, whose optimizations occur at runtime after a sufficient number of executions. Using JAttack, we have found six critical bugs that were confirmed by Oracle developers. Four of them were previously unknown, including two unknown CVEs (Common Vulnerabilities and Exposures). JAttack shows the power of combining developers' domain knowledge (via templates) with random testing to detect bugs in JIT compilers.}
}
@inproceedings{zhang2013,
  title         = {Control {{Flow Integrity}} for {{COTS}} {{Binaries}}},
  author        = {Zhang, Mingwei and Sekar, R.},
  booktitle     = {22nd {{USENIX}} {{Security Symposium}} ({{USENIX}} {{Security}} 13)},
  location      = {Washington, D.C.},
  publisher     = {\{USENIX\} Association},
  pages         = {337--352},
  isbn          = {978-1-931971-03-4},
  date          = {2013-08},
  abstract      = {Control-Flow Integrity (CFI) has been recognized as an important low-level security property. Its enforcement can defeat most injected and existing code attacks, including those based on Return-Oriented Programming (ROP). Previous implementations of CFI have required compiler support or the presence of relocation or debug information in the binary. In contrast, we present a technique for applying CFI to stripped binaries on x86/Linux. Ours is the first work to apply CFI to complex shared libraries such as glibc. Through experimental evaluation, we demonstrate that our CFI implementation is effective against control-flow hijack attacks, and eliminates the vast majority of ROP gadgets. To achieve this result, we have developed robust techniques for disassembly, static analysis, and transformation of large binaries. Our techniques have been tested on over 300MB of binaries (executables and shared libraries).}
}
@inproceedings{Zhang2015,
  title         = {{VTint: Protecting Virtual Function Tables' Integrity}},
  shorttitle    = {VTint},
  author        = {Zhang, Chao and Song, Chengyu and Chen, Kevin Zhijie and Chen, Zhaofeng and Song, Dawn},
  year          = 2015,
  booktitle     = {Proceedings 2015 Network and Distributed System Security Symposium},
  publisher     = {Internet Society},
  address       = {Reston, VA},
  number        = {February},
  pages         = {8--11},
  doi           = {10.14722/ndss.2015.23099},
  isbn          = {1-891562-38-X},
  abstract      = {--In the recent past, a number of approaches have been proposed to protect certain types of control data in a program, such as return addresses saved on the stack, rendering most traditional control flow hijacking attacks ineffective. Attack-ers, however, can bypass these defenses by launching advanced attacks that corrupt other data, e.g., pointers indirectly used to access code. One of the most popular targets is virtual table pointers (vfptr), which point to virtual function tables (vtable) consisting of virtual function pointers. Attackers can exploit vul-nerabilities, such as use-after-free and heap overflow, to overwrite the vtable or vfptr, causing further virtual function calls to be hijacked (vtable hijacking). In this paper we propose a lightweight defense solution VTint to protect binary executables against vtable hijacking attacks. It uses binary rewriting to instrument security checks before virtual function dispatches to validate vtables' integrity. Experiments show that it only introduces a low performance overhead (less than 2{\%}), and it can effectively protect real-world vtable hijacking attacks.},
  language      = {en},
  mendeley-tags = {c++ semantics,vulnerable by COOP}
}
@inproceedings{Zhang2018,
  title         = {{eXecutable-Only-Memory-Switch (XOM-Switch): Hiding Your Code From Advanced Code Reuse Attacks in One Shot}},
  author        = {Zhang, Mingwei and Sahita, Ravi},
  year          = 2018,
  booktitle     = {Black Hat Asia Briefings (Black Hat Asia)}
}
@inproceedings{Zhao2022,
  title         = {History-{{Driven Test Program Synthesis}} for {{JVM Testing}}},
  author        = {Zhao, Yingquan and Wang, Zan and Chen, Junjie and Liu, Mengdi and Wu, Mingyuan and Zhang, Yuqun and Zhang, Lingming},
  year          = 2022,
  month         = may,
  booktitle     = {2022 {{IEEE}}/{{ACM}} 44th {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  pages         = {1133--1144},
  doi           = {10.1145/3510003.3510059},
  issn          = {1558-1225},
  abstract      = {Java Virtual Machine (JVM) provides the runtime environment for Java programs, which allows Java to be ``write once, run anywhere''. JVM plays a decisive role in the correctness of all Java programs running on it. Therefore, ensuring the correctness and robustness of JVM implementations is essential for Java programs. To date, various techniques have been proposed to expose JVM bugs via generating potential bug-revealing test programs. However, the diversity and effectiveness of test programs generated by existing research are far from enough since they mainly focus on minor syntactic/semantic mutations. In this paper, we propose JavaTailor, the first history-driven test program synthesis technique, which synthesizes diverse test programs by weaving the ingredients extracted from JVM historical bug-revealing test programs into seed programs for covering more JVM behaviors/paths. More specifically, JavaTailor first extracts five types of code ingredients from the historical bug-revealing test programs. Then, to synthesize diverse test programs, it iteratively inserts the extracted ingredients into the seed programs and strengthens their interactions via introducing extra data dependencies between them. Finally, JavaTailor employs these synthesized test programs to differentially test JVMs. Our experimental results on popular JVM implementations (i.e., HotSpot and OpenJ9) show that JavaTailor outperforms the state-of-the-art technique in generating more diverse and effective test programs, e.g., test programs generated by JavaTailor can achieve higher JVM code coverage and detect many more unique inconsistencies than the state-of-the-art technique. Furthermore, JavaTailor has detected 10 previously unknown bugs, 6 of which have been confirmed/fixed by developers.}
}
