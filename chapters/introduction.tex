%! root = thesis.tex

\chapter{\label{ch:1-intro}Introduction}

\minitoc

\section{Motivation}

The construction of modern software relies on an ever-growing ecosystem of technologies and towers of abstraction.
Contemporary systems integrate dozens of third-party libraries, span multiple programming languages, and depend on countless layers of middleware and hardware interfaces.
A modern web browser, for example, now consists of over 30 million lines of code. \todo{Add reference, e.g., Chromium line count}
While this ecosystem enables developers to build software systems of unprecedented functionality, the increasing complexity also creates new challenges.

Despite this rise in complexity, the core expectations of software have remained unchanged: it is supposed to be secure, reliable, and efficient.
Yet, as systems grow, these qualities become harder to maintain and are often in tension with one another.
Each new abstraction layer hides detail but introduces uncertainty; each performance optimization risks new corner cases; each extension of functionality opens new attack surfaces.
Catastrophic security breaches like Heartbleed (a simple buffer over-read in a core library) \todo{Cite Heartbleed}, Spectre (exploiting CPU-level speculation) \todo{Cite Spectre}, or Log4Shell (a failure in input sanitization), each with global consequences, show that these problems are not just hypotheticals.

Likewise, reliability failures such as silent miscompilations have plagued even widespread production compilers like GCC and LLVM~\cite{yang2011}.
\citeauthor{yang2011} showed that the \propername{Csmith} fuzzer alone uncovered more than 325 previously unknown bugs in GCC and LLVM, including release-blocking miscompilations~\cite{yang2011}.
Subsequent longitudinal analyses of hundreds of LLVM and GCC bug reports find that miscompilations continue to account for a large fraction of confirmed issues and often remain latent for months before being diagnosed~\cite{chen2016}.
These data points underline that both the software we deploy and the toolchains we depend on remain fragile in practice.

Security and reliability form two sides of the broader struggle for software \emph{trustworthiness}: the ability to rely on software to uphold its specification under both benign and adversarial conditions.

\subsection{Security}
The tradeoff between abstraction and performance explains, in part, why languages like C or \cpp still form the foundation of critical infrastructure.
The potential for high performance\footnote{Not every program written in C or \cpp is automatically fast.} and direct control of machine internals make C and \cpp a popular choice for operating systems, browsers, and embedded systems.
However, C and \cpp are also notorious for their lack of automatic memory management (memory unsafety) and, more broadly, for the pitfalls of undefined behavior.

These pitfalls regularly lead to dangerous vulnerabilities.
These vulnerabilities—which include stack and heap-based buffer overflows, use-after-free errors, and format string bugs—are the vector for a majority of remote code execution exploits.
Industry telemetry highlights the breadth of the problem.
Microsoft’s Security Response Center reports that roughly 70\% of critical vulnerabilities it handled over the past decade were due to memory-safety errors, despite major investments in defensive coding practices~\cite{msrcreport2019}.
Google’s annual Android security review reaches similar conclusions, attributing more than three quarters of high-severity platform bugs between 2019 and 2022 to memory-safety violations, many rooted in native code dependencies\cite{projectzeroandroid2022}.
Google's Project Zero also notes that the majority of the 2023 zero-days they investigated ultimately stemmed from memory corruption~\cite{projectzerointhewild2024}.

Although the rising popularity of memory-safe, yet performant languages like Rust mitigates this issue, C and \cpp remain dominant, consistently ranking in the top tiers of language popularity indices. \todo{Cite TIOBE index}
Furthermore, even new, memory-safe code is often integrated into legacy systems.
A vulnerability in an underlying C library, for example, can be exploited to undermine the guarantees of a Rust or Swift application that links against it. \todo{Cite paper on Rust/C FFI vulnerabilities}
Given the billions of lines of C and \cpp code in production, memory and spatial safety vulnerabilities will remain a critical threat for the foreseeable future.

One dominant class of exploits targeting these vulnerabilities is code-reuse attacks.
Attackers hijack a program's control flow and subsequently reuse existing code \enquote{gadgets} already present in the target process.
This approach allows attackers to bypass defenses like \wox, which, thanks to widespread hardware support, have become a de facto standard.

Over the years, different ways of defending against this type of attack have emerged.
One prominent defense category is randomization or more broadly software diversity.
Software diversity embraces the possibility of memory corruptions and control-flow diversion and instead aims to restrict an attacker's maneuverability.
By introducing controlled randomness into code or data layouts, software diversity disrupts attackers’ assumptions.
For example, without knowing the exact location of functions or gadgets, an attacker can no longer use them in a code-reuse attack.
Unfortunately, closing all information channels an attacker could use to undermine the guarantees provided by randomization is difficult in practice.
Recent work shows that even when code is perfectly hidden, predictable data structures such as the stack, global objects, or allocator metadata, can leak enough information for a successful attack~\cite{Rudd2017}.
The consequence is that although, judging by the publication counts, the security community's interest in code-reuse mitigations has declined, unsolved problems remain.

\subsection{Reliability}
Traditional software assurance techniques like static analysis, manual testing, and formal verification struggle to keep pace with the trend of ever-increasing complexity.
Formal verification can, in principle, prove correctness properties, but its cost and scalability remain prohibitive for large, evolving systems.
Meanwhile, the tools we use to build everything else—modern compilers, linkers, and virtual machines—have themselves grown complexity.
Each new optimization pass, hardware backend, or language front-end enlarges the space of subtle interactions that manual review or unit tests rarely exercise, so bugs continue to slip through release pipelines.
These observations are particularly true for \glspl{JIT}.
\glspl{JIT} are typically part of a language VM and compile user-provided, potentially malicious code, which is supposed to be sandboxed.
As such, the correctness of \glspl{JIT} has a security dimension as well.


Fuzzing has become an important compiler testing tool to counter this trend. \todo{Cite \propername{Csmith}/differential testing}
However, fuzzing a complex \gls{JIT} effectively presents a unique challenge.
Most compiler fuzzers operate \enquote{blindly}, generating random test programs without a deep understanding of the compiler's internal state.
Standard feedback metrics, such as code coverage of the compiler's source, are often a poor proxy for the semantic richness of the compilation process.
A fuzzer might achieve high code coverage while completely failing to exercise the complex interactions between different optimization passes that are a common source of bugs.
To find these deeper bugs, the fuzzer needs a better guide—one that is aware of the compiler's internal transformation and optimization logic.
Two generated programs can produce identical edge coverage yet drive entirely different optimization histories—one might lower a loop into vector form while the other never leaves SSA canonicalization.
Without feedback that reflects those semantics, fuzzers treat the runs as equivalent and fail to reward exploration of the rare pass combinations where the most pernicious bugs hide.

\subsection{The Compiler's Role Beyond Optimization}
In this thesis we argue that compilers are uniquely positioned to drive improvements in both areas.
Every non-trivial program passes through a compiler before it runs, either ahead of time or just in time\footnote{Interpreted programs are an exception, but the interpreter itself has passed through a c compiler as well.}.
This \enquote{choke point} turns the compiler into a linchpin for software trustworthiness: a single transformation deployed in the toolchain can harden millions of downstream binaries.

Compilers possess semantic insight that no runtime monitor or post-hoc analysis can easily replicate.
The semantic insight encompasses both programming language semantics and details about the target backend.
For example, compilers know the exact type hierarchy of compiled \cpp programs and the exact geometry of their stack frames.
While this information can be partially reconstructed from binaries, the reconstruction is notoriously challenging because compilation is a lossy process.
Similarly, compilers have detailed knowledge about the compilation process itself, such as which transformations were applied and which invariants justified those transformations.

In this thesis we show ways to tap these information sources for security hardening and improved fuzzing.

\section{Contributions}
In the first part, we present \rtwoc, a novel, compiler-driven software diversity defense that addresses the challenge of predictability.
It combines fine-grained code randomization with targeted randomization of program data structures.
By diversifying not just the code but also the data layouts that recent attacks rely on for reconnaissance, \rtwoc renders such attacks ineffective while incurring a moderate performance overhead.

In the second part, we present \lool, a compiler-assisted fuzzing framework that provides a smarter guide for discovering compiler bugs.
Instead of relying on simple code coverage, this \enquote{optimization-aware} method leverages the compiler’s own internal transformation records as a feedback signal.
A genetic algorithm uses this feedback to systematically steer testcase generation towards rare and complex optimization interactions that are otherwise missed by traditional fuzzers.

Together, these contributions address two fundamental aspects of trustworthy software: resisting deliberate exploitation and uncovering latent faults.
Both are achieved by repurposing the compiler from a pure performance tool into a powerful instrument for building and verifying trustworthy software.
